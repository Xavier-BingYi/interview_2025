undefined
我們上一次跟同學介紹到CacheWriter的機制就是WriteBack、WriteThrough還有WriteBuffer我們這邊提到的一個就是說，當我們發生WriteMiss的時候，它的運作的機制大概會怎麼樣。我們這邊想到的，當然就是說WriteMiss當然就是指說，我們要寫入資料，我們把資料寫入 cache 的時候發現，這筆資料並沒有在 cache 裡面沒有在 cache 裡面。第一個想到的當然就是說，我們就是把資料把它搬到 cache

裡面來搬進來之後，我們把資料再把它，就是再把它寫到 cache就是看到搬到 cache 的什麼地方，我們再把這筆資料寫到 cache 相關的位置。所以，我們第一個想到的當然就是，用這樣子的方式來做實際上，在這裡我們有兩個機制，它是這邊是寫說，它是 for write-through 跟write-back它有兩種不同的機制，一個叫Write-no-allocate什麼是Write-no-allocate呢它指的，就是說根據我們剛剛的描述，我們第一個動作，我們會先把資料從 memory

抓到 cache 然後再寫到cache，但是就這個write-through 來看的話，它說我們可以直接，我們直接就把資料寫到memory，我們並不需要再把資料把它抓到cache。 裡面來再寫到 cache所以它等於是它不抓資料抓到 cache它就直接把它寫入 memory因為這邊寫 write-through最主要就是因為我們知道說 write-through它是你每一次 write它也一定會寫到Memory它會把Cache跟Memory做Synchronization的一個動作在這裡同學可能會覺得很奇怪說為什麼

我們不要把Block把它Fetch到Cache我們就直接寫到Memory裡面去呢同學可以想想看我們其實有一種Operation在那個Operation裡面我們實際上並不需要把所有的資料全部把它抓到 cache 裡面來因為我們抓到 cache 裡面來是 suppose 說我們往後這些資料它還會很快的被 access 到舉一個例子而言我們在 program 裡面program 裡面我們最常見一開始 program 的時候在 main program 或者是 function開始的時候我們會做一些 initialization比如說我們就是對一個 array

for i 等於 0 到 1000那我們就是去把 ai 都設為 0這個 ai 設為 0 我們知道說這個只是一個起始的一個動作而已它只是一個算是一個 reset把它全部都清為 0可是實際上並不是表示說這個 a1 a0 a1 到 a999都是我們之後馬上就要用到的這個 data所以類似像這一種 initialization我們一開始是要把一個領把它寫到這個資料裡面去但是實際上我們只是做一個 reset。.

reset 完之後你 program 繼續 run它什麼時候會用到這個 AI實際上我們並不知道所以類似像這樣子的一個情況我們如果是用這一種所謂的 write, know, locate這樣機制的話，它實際上是就是說是符合我們這樣子的一個情況是有幫助的。它並不需要就直接抓到Cache裡面來另外一個當然就是這個WriteBackWriteBack它是整個Block全部被踢出這個Cache之後它才會把這個資料整個

就是如果這個block它是dirty的話它會把它寫到這個memory所以類似像這個的話我們當然就是要fetch block我們把這整個block從memory先讀到這個cache裡面來我們再做一個write所以這種是屬於這個write allocate它有做fetch的動作這個write not allocate它是沒有做fetch。我們這邊看一個intensityFastMath它是一個embedded MIPS processor它有12個stage的publine它在每一

個cycle可以有instruction access跟data access所以我們知道說它是separate然後它的cache有獨立的i cache跟d cachei不是apple的iiCache跟dCache它的每一個Cache不管是Instruction Cache或者是Data Cache它每一個都是16KB所以它的Size是16KB它怎麼去分這16KB呢它總共分成256個Block每一個Block是16個Word所以16個Word一個Word的話是是4個byte所以它是64個byte那它這個data cache它可能是ride through或者是ride back所以根據它的這個rung這個spec 2,000它的這個benchmark它的miss rateinstruction cache大概是只有0.

4%同學可以看到這不是說它的這個hit rate只有80% 90%這個都這個都不夠高所以它的miss rate只有0. 4%那 data cache的話，它這個比較沒有辦法像這個instruction一樣，因為instruction基本上你是只有branch的時候你才有可能會猜錯不然你如果是sequential的話，它就是一直往下抓所以這個data cache它的miss rate比較高，11. 4%那平均的話，大概是3.

所以這個是我們Intensity fast math它的cache的一個機制所以根據我們剛剛的描述它每一個block就是有16個word所以有16個word我們這邊word offset就是4個bit，4個bit我們同學可以看到這邊是一個block，它一個row就是一個block，那一個block後面的data它有16個word所以我們這一邊前面還有提到它是256個block，所以這邊index是8個bit所以這邊是4加2是6，

6加8是4然後32扣掉是4剩下是8所以這邊18個bit是techbit所以我們先從index這邊我們可以知道它到底是access哪一個block這個block取出來之後我們就還要再比對說這個tag是不是我們要的這個tag這個tag是不是跟我們的tag是不是一樣所以這邊的tag它會跟我們這邊的tag field來做一個comparison當然要看這個valid它是valid bit是enable然後這個comparison它也是equal所以這樣子就會hit

另外這邊有16個word我們是要從這16個word裡面抓哪一個word我們就是要從這邊word offset這邊4個bit做一個16選1的多次重點這邊16個word選1個word出來這就是我們要的data這個架構其實也就是我們前面跟同學介紹的Direct Map它的block size是16個word接著我們來看一下就是說如果我們考慮到Memory還有

Memory跟Cache之間的Bus它們在傳送資料的速度的話我們知道說CPU的速度是最快然後Cache可以搭配CPUMemory的話它的Access就比CPU還要慢Memory Bus的話我們從Memory讀出資料然後接著還要透過Bus把這個資料送到Cache這個Bus基本上它的速度是很慢的所以我們會有一個Bus ClockBus Clock它的工作頻率基本上是跟CPU的Clock比較起來是相對的

非常的慢還有另外一個就是說我們的這個Bus它在傳送資料基本上它是fixed width所以我們等一下用這個fixed width的這個Bus來分析一下說從Memory Access然後透過Bus送到Cache這樣子的話大概需要多少個時間我們這邊有個例子就是說我們一個Cache的這個Block的一個Read當然就是說它已經 miss所以 miss 它必須要到 memory 去讀一個 block把它讀到 cache

裡面來我們假設因為你要叫 memory 做 read你一定要先送一個 address你送一個 address你的 address transfer假設它是一個 bus cycle接著就是說它要做一個 DRAM 的 access它需要 15 個 bus cycle然後資料讀出來之後再從這個Memory透過Bus然後送到Cache它需要送的這個Data Transfer它需要一個Bus Cycle所以我們來看三種不同的機制它大概分別需要多少個時間第一個它就是說它這個Block是四個Word所以你每次要

讀的話就是讀四個word從memory讀四個word然後透過bus把這四個word送到 cache它講說這個是one word wide所以這個DRAM是one word wide它應該就是指說我們在做一個memory的access的時候它大概就是一次讀一個word然後它的miss penalty的話首先我們來看第一個它要先把 edges 送過去edges 送過去它只要送一次就可以因為我們知道說這四個 word它不是不連續的

它是連續的所以你送一個起始的位置它後面連續四個連續的位置全部都可以讀出來所以你要一個 bus cycle 來送 edges接著它說一個 theorem 的 access我們說這個是一個 read一個 read access 它需要 15 個buzz cycle但是它一次要讀四個word它一次只能讀一個word所以你總共要讀四次所以你這邊要4乘以15你這樣子到這邊就是把四個word的資料把它讀出來接著我們要做transfertransfer它的buzz的width它也是one word所以你要分四次送所以你這邊也是要一個buzz cycle

一個data transfer就是一個bus cycle送一個word所以你要送四次所以你這樣子一乘之後我們就知道說你一個miss它的penalty就是需要65個bus cycle所以這個就是我們用這樣子的一個機制所得到的這個penalty這個penalty就是我們可以算出來說它的bandwidthbandwidth就是6565cycle分支16個byte大概就是平均每個cycle可以有0.

25個byte的data rate所以這個是我們第一個看到的機制這個機制它的圖我們在課本裡面可以看得到它就是這種one word wide的一個memory organization我們可以看到它的memory一次就是access一個wordBus它也是一次transfer就是一個word所以它不管是access或是transfer它都要透過四次接著我們來看第二個機制第二個它是Forward-wide memory organization這個Forward-wide我們看中間的這張圖我們一看我們大概就知道說它這邊的意思大概就是你一次access四個word它就可以

一次就 access 四個 word它不需要做四次的 access我們這邊看起來 bus 也比較寬我們就看圖說故事這邊 bus 也相對的比這邊寬很多所以其實它就是在告訴我們說你一次 data transfer大概就是可以 transfer 四個 word所以你不管是 access transfer它都是一次就四個 word 就 complete如果是這樣子的一個 scheme 的話我們可以來看到說它的 miss penalty它就是送一次 address transfer然後再做一次 data access

加 15然後再做一個 4 個 word 的 data transfer這個也是一個 bus 的 cycle所以我們這樣加起來就是 17 個 bus cycle它的 bandwidth 大約是 7 分之 16所以跟剛剛比較起來當然相對的就比較高剛剛是多少呢 剛剛只有0. 25我們現在Promote到0. 94這個當然是Bandwidth是最高的但是相對的代價也比較高Hardware的代價也比較高所以我們可以看到說你要提供這樣子的一個

就是High Performance的一個Bus當然你的Bus的Hardware絕對會比這種Bus的Cost成本還要大的高我們再來看第三種這個大概就是屬於折衷的它是所謂的Interleaved Memory Organization我們可以看到它的特徵是什麼呢它的Bus的Structure跟第一種機制是一樣的所以它的Bus就是它的transfer一次就是送一個word可是它memory它不是像它這樣子它是用bank所以它是有四個bank四個bank是什麼

意思呢四個bank這邊for bank它是bank0到bank30到3這四個bank它可以同時做data access所以我們如果是需要四個word的話我們需要四個word四個word的data我們access當然是分佈在這四個bank它是independent bank所以我們可以同時做access所以這樣子的話同學大家就可以猜得出來說它的memory比如說我如果是i i加1 i加2 i加3所以它的送一個adges過來的話相對的就是這四個bank同時可以

access到不同的data不同的data實際上組合出來的就是我們在這樣子的一個sequential organization裡面它是一個連續四個world它分布在這四個bank所以我們這樣子的一個data access它需要幾個它需要幾次我們如果來算次的話其實它需要一次一次就是15個bus cycle所以我們這邊以這第三種機制來看的話它的 address 的 transfer 一樣是一個做一次然後它的 data access 一樣只需要一次就四個 band一個 band 把一個 word你四個 word 把出來之後實際上你是 sequentially 的 data transfertransfer 這個 data transfer 到 cache

所以我們這邊data transfer是需要4次這樣子的一個design的philosophy最主要當然就是說我們的penalty最重的是這一個既然最重的這一個我們就是不要讓它乘以4我們就是讓它我們去optimize這個penalty最高的這一個部分至於這個bus的部分它相對的跟它比較起來就非常的輕所以我們也沒有必要花費精神去做這種high performance的bus所以我們就可以看到說這樣子來算的話它的bandwidth只有0.

80. 8跟前面0. 25比較起來它快了3倍多跟這個0. 94就只有差一點點所以這個是第三種interlib memory organization接著課本介紹了這些Advanced DRAM Organization我們這邊很快的看過同學大家只要知道有這些名詞就可以那detail的同學可以自己去查一下我們知道說像DRAM這種設計它是非常的structured它基本上就是一個cell array它都是這種memory cell

分布就是像一個 array 一樣所以它有 row 它有 column它難的當然是難在它的一個 single cell你要怎麼去設計然後你整個一個這麼大的而且是密度非常高的這種 memory cell你要能夠如何提高良率然後讓它的 timing 它的 speed 可以變得比較快所以這個都是它困難的地方我們這邊提到的說像這種DRAM memory它可以access一整個row因為它本身就是一個一個array的一個structure所以你有row access你有column的access另外它這邊有提到一種叫burst modeburst mode它是說你可以

從一個row裡面可以用很快的一個速度所以它說可以reduce latency提供這種連續的Word反正是一個很規矩的structure自然而然有一些方式可以提供類似像這種Burst Mode這個是一般的DRAM實際上比較快的DRAM我們都聽過就DDR QDRDDR就是Double Data Rate DRAM所以它等於是Rise and Falling的Clock Edge它可以做Transfer所以它可以把它Data Rate把它Double另外一個Quad Data Rate就是4倍它可以4倍它除了Rise and Falling它還可以Separate Input Output所以它的Data Rate又是2倍所以它這邊QDR是4倍

目前都看得到都看得到這一類的DRAM這邊有一個圖表就是DRAM的Generation我想現在DRAM介紹最詳細的應該就是韓國韓國Samsung他們現在是DRAM的霸主他們現在聽說好像市佔率已經快要逼近五成全世界DRAM的市佔率已經快要逼近五成我們台灣的低韌廠現在好像我們台灣的前三大的低韜廠好像已經降到1%有一家好像已經降到1%還是已經1%的小數點下面去了那個大概已經沒救了還有我們這邊的圖表這個大概就是它的低韌的速度

一個是row的access time紅色的是row access time藍色的是column access timen同學可以看到它的速度就是一直降一直降即使再怎麼降其實bottleneck還是在memorynmemory還是不夠快所以這也是為什麼最近有一些產業的變化如果看新聞的話大概知道說TSMC本來可能會有一隻大燕子飛過來如果明年可以吃到Apple的話就有一隻很大的可能不是燕子可能是老鷹結果Apple沒有吃到Apple的A6 Processorn它下一代Next GenerationiPhone還有iPad的Processor A6

就是沒有吃到就被Samsung搶去了這個實在是很詭異的一件事情當然並不詭異只是說你從Mrs. Muddle來看的話Samsung現在跟Apple在那邊告得一塌糊塗。世界各地在那邊互告他們實際上已經是正面衝突的敵人。但是Apple還是要去找Samsung請他幫他代工做A6TSMC。它為什麼沒有拿下這一塊呢？其實最主要還是在Memory的部分，因為這個就是傳言很多實際上是怎麼樣

不是很清楚。但是我覺得可能是後者的可能性比較高，因為有人有說這個Samsung，它DRAM應該是世界霸主。當然它那個不是DRAM，它那個綁iPad的那一個反正就是它的Processor搭配它的Memory，它的Memory的價錢非常有彈性，因為都是自己家的產品，所以它的價錢比較有彈性。

另外一種說法我是個人覺得應該是後面的這種說法。第二個說法是說因為Samsung它掌握Processor還有Memory的技術同學大家都聽過3D IC這個是現在

最新的就是說大家在記憶電路上面這個製程，它一直縮一直縮縮到後來已經快要縮不下去了。雖然這個engineer非常厲害他還是有辦法繼續縮，但是就是真的實在不知道大概有人說可能10奈米就差不多就停了。但是又有人說可能又有新的技術可以再繼續往下縮。

Anyway你的shrinking的速度已經沒有像以前那麼的快所以我們如果還要再

把IC做得更複雜的話大概就是要做立體的同學。如果對第一章還有印象的話IC本來就是立體IC它本來就是像三明治那時候跟同學介紹像三明治這樣堆疊可是實際上這邊的立體指的是指什麼呢？它指的是什麼呢？它指的是指這個帶我們前面跟同學提到的帶帶我們看到的晶片的封裝就是它裡面核心最脆弱的就是一個帶

所有的電路都是生產在一個好像指甲這麼小的一個帶上面那是很脆弱所以他要用比較堅固的封裝的技術把它包在一起。

他把它包起來你現在既然沒有辦法把更多的電晶體塞到一個帶裡面另外一個方法大家想到的就是怎麼樣就是把很多個帶把它堆疊在一起很多的帶堆疊在一起，這個並沒有那麼簡單，同學說這還不簡單。你用釘子，

用什麼支架把它支撐？可是問題是釘子怎麼做，因為那個都很細。釘子在帶跟帶3D疊在一起的，因為帶跟帶之間絕對不可能是independent它一定有訊號要在那邊送來送去所以你帶跟帶之間要有signal transfer所以你必須要好像我們在同一個帶裡面不同的金屬層必須要用VIR把它貫穿一樣。現在這個技術就

並不是那麼的成熟，所以3D IC這部分的發展就是現在有人很用心的在做像現在同學手上的手機裡面都有3D IC的技術，它CDI系的技術目前應用在Memory，因為Memory它就是需要面積小然後密度高你要把它塞很多塞很多的Memory在同一個Area裡面，因為我們知道說手機的Area就是這麼大手機的Area這麼大，你把它擺原件擺進去你一個原件很大其他原件就擺不進去所以Memory你如果說把它平的擺的話，

它可能就四倍的面積。你把它堆疊在一起，它的面積就四分之一。所以現在用到的就是3D IC，Samsung他們掌握了這種Processor跟Memory的技術，所以他們應該也有辦法把這個CPU跟Memory透過3D IC的技術把它堆疊在一起所以它不需要CPU封裝成一顆CPUMemory封裝成另外一個Memory你都封裝完了它基本上有兩個封裝它的

兩個封裝的IC就非常佔面積它應該是有辦法把這個CPU Memory透過3DIC的技術把它在帶的技術上面把它堆疊在一起然後再把它封裝在一起所以這個就是Samsung他們的優勢所以同學可以看到說TSMC他們現在已經成立就是成立一家新公司他們說他們要自己做封測封裝測試他為什麼要自己做封

裝測試呢因為他如果要做3D IC的話他必須這些所有的技術全部都是要自主掌握在一起他才有主導權所以同學可以看到這一類的新聞大概可以知道說產業的趨勢大概就是朝這樣子再進行我們這邊看到的接下來我們就來看Cache的這個Performance因為我們前面有提到的就是說Cache Hit它的這個CPU它就可以順利的再繼續往前執行如果說Mist的話就必須要Store必須要做Memory的Access所以我們可能要分析一下說Cache的這個Performance我們看CPU Time的話

CPU time它包含了哪一些部分這個當然就是既然現在裡面已經有Cache我們自然要把Cache運作的部分把它放到CPU time裡面來第一個就是Program Execution Cycle Program Execution Cycle這邊指的當然就是指說它的Normal Execution它完全不需要Store我們Suppose它所有的每一個Instruction它都沒有Storecache都是 hit hit hit所以這樣子完完全全就是在執行指令的時間第二個部分就是當我們 cache 發生 miss 的時候我們就必須要 storestore 去做 memory 的 access所以這個最主要就是來自 cache misscache miss 要怎麼算呢我們就說

這邊是簡單的一個model它說memory store cycle它等於什麼呢它就是等於說你這個program你到底裡面有多少個memory的access然後乘上你的miss rate乘上這個miss rate你的這麼多個memory access再乘以你的miss rate基本上你就知道說你大概發生幾次miss你發生幾次miss再乘以你的 miss penalty 就是這樣子所以這邊就是再乘以 miss penalty 這樣得出來這個就是我們的 memory store cycle所以這個就是我們從這樣子

的觀念來推導當然這個我們也可以替換成這個我們用 instruction 來看如果是用 instruction 來看的話當然就是說，我們的program裡面到底有多少個instruction，你平均一個instruction大概會發生幾次miss，這是miss的次數這樣子一乘的話我們就會得到說它總共發生多少個miss再乘以這個miss penalty是一樣的所以大概我們如果簡單的估計的話大概就可以這樣子來估所以我們來看一個cash performance的一個分析的例子我們說

這邊有一個instruction cache它的miss rate是2%data cache的miss rate是4%miss penalty是100個cycle。我們的base cpi就idea cache每次都hit hit hit我們說idea base cpi是2兩個cycle。我們說我們的load跟store就是我們要去做這個memory的access不管是read或是write我們就全部都算在一起它是占所有instruction裡面的36%所以我們說這個miss平均一個instruction它的miss所需要多花的cycle到底需要多少我們來看第一個instruction cache它的miss rate是2%所以就是0.

02再乘以100因為它一次penalty就是100個cycle它的機率是0. 02 一乘的話是兩個cycledata cache miss rate是0. 04所以它的一個miss的話就是0. 04再乘以100可是問題是它並不是每一個instruction都是會去做data access它會做data access的機率是36%所以我們還要再乘以0. 36所以data cache的部分就是0. 36乘以0. 04再乘以100所以這樣子total來看的話我們有instruction cache的miss有data cache的miss我們再加上一個base CPI所以這樣total加總起來是5.

44所以idea cache的話CPU可以run faster2. 72倍比實際上還要快2. 72倍這些MOD完完全全都是來自於就是這部分是instruction cache這部分是data cache的部分所以我們要算average的access time我們來看就是說像這個Hit Time就是說Hit Time這個是對Performance來講它是非常重要為什麼會非常重要呢？同學可以發現我們剛剛的那一個例子裡面我們的這個Hit Rate高不高非常的高 對不對Hit Rate這邊它的

Instruction cache它的Hit rate是98%Data cache的Hit rate是96%所以這麼高的Hit rate表示說絕大部分它到Cache裡面它都可以抓到它要的資料既然是這樣子我們已經讓我們的Hit rate這麼的高所以有一項就非常的重要什麼呢？ Hit time對不對Hit time因為百分之九十幾剛剛看95%以上的機率不管是instruction cache、data cache它都是到cache一抓就到那你一抓就到你的hit time到底是多少所以這個就是非常重要我們的average memory access time縮寫是AMAT它就是hit time再加上miss rate乘以miss penalty

這個就是我們平均的 memory 的 excess time當然絕大部分的機會它都是使用到這個時間所以我們如果可以 optimize 這個 hit time當然我們得到的 performance 的 gain我們收穫就會比較大所以這個是一個但是這邊我們要知道的是average memory excess time就是 hit time 再加上 miss penalty就是miss rate乘以miss penalty这样子就会得到所谓的平均的memory access time

所以这边有一个例子我们来看说CPU它有1ns它的class cycle是1ns它的hit time是1个cycle;miss penalty是20个cycle;cache的miss rate是5%。所以，它的average Memory Access Time AMAT就是它的hit time再加上miss rate乘以miss penalty這樣一乘就是兩個cycle，就是兩個narrow second，所以這個就是平均一個instruction它的Memory Access Time就是兩個clock cycle。我們前面的部分大概就很簡單的把Cache的一些觀念介紹過；我們後面會跟同學介紹另外比較general就是associativity的Cache的一個structure首先我們來看一下這個Performance的summer，就是說即使我們現在CPU的Performance，

但是增加的很快當然這幾年其實增加的已經不快了它已經是code的數目變成是槽code的數目在增加CPU，它的calculate它已經大概就是停在那個地方。我們上一次有跟同學提過，好像是已經有突破8GHz還是10GHz，那個數據我已經不太記得的CPU；這個部分也做了蠻多年了當我們把CPU的performance一直提升的時候其實有一件事情就變得很重要什麼重要呢我們可以來想想看就是說假設假設我們的

miss penaltymiss penalty我們假設是用時間來算就是說你cache miss的時候你到memory去access的時間我們假設D4都是10個neurosecond其實它沒有變慢可是問題是我們的clock假設是從以前的1GHz然後變成2GHz1GHz變成2GHz基本上它的cycle time就已經是減半對不對那它cycle time減半的話那你的時間同樣比如說同樣都是10個neurosecond

我們可以知道的就是說它的miss penalty它所需要的cycle的number數目就怎麼樣就加倍這個加倍就不得了因為我們在算說你一個指令需要幾個class cycle你一個指令需要幾個class cycle就你的miss penalty你的cycle number是加倍那個加倍數目相對就很受不了所以這種都是比較的 都是相對的所以我們這種miss penalty它就會變得非常的重要以我們剛剛的一個例子來看它的比重很明顯的就增加了所以我們的

CPU速度越來越快的話相對的變成浪費在memory store的部分它時間所佔的比重它就會增加這些都是因為我們的CPU的Performance我們的Clock Rate提高了，所以使得它雖然Memory，它速度也是變快可是它變快的速度沒有像CPU來得那麼的快所以兩個都變快，但是這個快得比較快然後這個Memory快得比較慢所以你轉換出來的這種Cycle Number

它還是變多，所以這樣子的話它變得就非常的重要表示什麼呢我們在evaluate我們的system performance的時候我們不能夠一直就是在算我們的CPU到底多快多快多快那個是沒有用的，你CPU做得再多快結果你沒有把你的cache把它做得很好跟我們的CPU搭配得很好你最後出來整個你整個average你的CPI就是會被你

的这个miss penalty把它拉下来，所以我们一定要去evaluate我们的这个cash的behavior所以我们为什么会有最后那个project我们就是要写那个cashcash的一个simulator让同学去模拟一下这个cash的这个机制今天就是下课的时候我们助教会跟同学介绍那个最后一个project就是cache的simulator接著我們就來跟同學介紹associative cache其實我們前面介紹的direct map它也是屬於associative cache其中的一種當然它就是一個tamping的兩個極端in general的話它不是fully associative

它也不是Direct Map它是一個N-way Set Associative的一個Cache什麼是Associative呢它就是說同學都知道說我們有一些機制我們可以做譬如說你如果有十個Element我們如果要知道說這十個Element裡面哪一個是我要的Data我們一個方法就是什麼呢就是Sequential scan對不對Sequential scan我們就可以找到說這

哪一個是我要的另外一種方法我們把10個element就是同時in parallel做comparison就是做一個parallel comparison我們就10個同時去做10個comparison你一比對完之後我們馬上就會知道說我要的資料是這10筆裡面的哪一個這個速度當然是很明顯它是遠跨於我們前面提到的sequentially的一個scansequential scan 一個一

個一個看你10個沒有關係你如果1000個的話那當然你這時間就會浪費很多可是相對你說10個我們paracomparison我才10個comparator那沒有什麼可是你如果是1000個那你要paracomparison你要1,000個comparator這眉頭可能會皺了一下你如果說10,000筆資料你要10,000個comparator這個大概下不了手所以我們說這個就是兩個極端一個是sequential的scan另外一個是fully parallel comparison這個都是一個是最快 一個是最慢一個hardware cost是最高另外一個是最少

這一種像我們提到的那種fully的paracomperson它這種觀念concept就是所謂的這個fully associative的一個cache我們前面提到的direct map同學如果還記得的話就是我們一個memory它對應到cache裡面去只有一個location只對應到一個cached entry 對不對同學應該還記得就是你一個特定的Memory它的一個Location你Map到Cache它一定就是Map到一個Unique的一

個Entry它不會說可以Map到A也可以Map到B它一定是只有Map到一個Unique的一個Cache Entry這個就是我們前面提到的Direct Map所以Memory數目比較多Cache數目比較少所以它是一個多對一的一種Mapping這一種就是Multiple就是Multiple或者是N位的這種Set associative它的意思就是說我的MemoryMap到這個Cache裡面它不是只能夠擺在一個位置它可以擺在好多個位置所以這個N位它就可以

擺在N個位置它有N個地方可以擺它可以N個地方可以擺那Fully呢如果是Fully associative它是什麼意思呢它是 cache 的每一個地方都可以擺它是 cache 裡面的每一個地方都可以擺如果說 cache 的每一個地方都可以擺它還需要做 index 去找那個 block 嗎它不需要它就是直接全部做 comparison去比對說我到底在哪裡就這樣子所以這個是

Fully associative所以它講說它允許一個given的blockTo go in any cache entry你cache裡面的任何一個entry它都可以擺 它都可以放所以當然它也必須要怎麼樣呢我們剛剛提到的它必須要所有的entry要同時search就是同時做比對比對完之後它馬上就知道說我要的到底是在哪一個entry它就可以identify那一個entry把

它找出來如果說是n位的set associative它這個就比較有彈性比較中道它是說它一個set裡面有n個有n個可能的entry可以讓你擺所以當我們利用index我們利用這個Memory address的index我們對應到某一個set的時候它只是告訴你說你可以擺在這一區裡面但是這一區有N個位置可以擺那你就看看哪一個地方是空的你就把它擺進去這個就是N位set associative所以它這邊就提到說N位的set associative它指的就是每一個set有N個entry一個set有N個entry

我們的 block number 就是決定就是我剛提到的block number它就是對應到哪一個 setblock number 它現在是對應到哪一個 set用的方法跟我們的 direct map 的方式是一樣同學 direct map 裡面是 block number這個 n 位的 set associative 是 set number所以方法一樣 只是在這裡面我們把 block number用 set number 取代掉所以我們的 block address modularity set numberset number 得到的我們就知道這個 block address 它對應到哪一個 set但是我們到這裡只知道它對應到某一個 set我們不知道它在 set 裡面的哪一個位置因為每一個 set 有 n 個位置

有角度 ways 它不知道擺哪裡所以這個時候我們就在這個 set 裡面的這 angle entry同時做 search同時比較我們就知道說這 angle entry 裡面的哪一個是我要的所以這個就是先透過 block address然後用 modular operation然後去找到到底在哪一個 set然後再用 parallel comparison在這個set裡面同時做N個comparison它就可以知道到底是哪一個這樣

子的話它只需要N個comparison它不需要就是你cash有多少個entry就需要多少個comparison所以相對的就比較沒有那麼的貴它的cost我們可以降它的cost所以這邊有一個例子這個例子它就是左邊是 direct map然後中間是 set associative然後右邊是 fully associative那這邊我們同學可以看到說這個 direct map這邊它對應到這個位置它一個 block 就是一個位置這邊就是一個 block

它這裡面它就是比對說這個tag是不是它的tag如果是它的tag的話那就對了然後這邊setAssociate它這個是two way同學可以看到這是set0 set1 set2 set3每一個set有兩個entry所以我一個block對應到set0我可以擺這裡我也可以擺這裡每一個地方都可以擺那到底是這裡還是這裡呢所以我們就要把

這個set裡面的這兩個entry同時做searchparasearch然後一比對我就知道說它是擺這裡如果是fullyassociative的話它基本上已經沒有所謂的set number這個東西了它就是只有一個set你也不需要做Modular因為你怎麼Modular它本身就是只有一個大Set而已所以不用Modular你就是所有的Cache裡面所有的Entry就是Paracomperson然後SearchSearch你就可以知道說它是在這個地方所以這就是我們提到的Direct Map還有To WaitSet AssociativeFully Associative這三種不同的機制我們休息一下

我們來看這邊有一個例子它是一個 cache 有八個 entry這邊列出了one-way, two-way, four-way 還有 fully就是這四種 associative cache 的一個 structure我們剛剛就有提到 direct map它是 set associative 的一個極端所以它是one way所以我們可以看到這樣子的一個機制就是我們前面看到的direct map就是你對應到一個block之後這個block這個位置它就是一個block它沒有說還有兩個三個block可以讓你選就是對應過來它就是一個block所以這個就是one way只有一個那two way的話這個就不叫block

這個就是叫set因為它一個set裡面有兩個block這邊一個block這邊第二個block所以它這個是一個block兩個block所以這裡就不叫block這是叫set所以它也是一樣用block address然後去module你的set number你就可以找到它這個要對應到哪一個set接著我們再從這個set裡面看看要擺這個block還是這個block因為每一個block當

然都有它的tag所以同學不要以為說這個tag只有一個好像說一個row只有一個tag這個是不對的因為這個tag它是根block它是在identify這個block到底是不是我要的block我們前面講的 direct map因為它這個你如果把它看成是 set 也可以這個 set 就一個 block它也只有一個 block所以這裡面因為只有一個 block所以它就一個 tag這裡面因為它有兩個 block所以它有兩個 tag這個是這樣合起來是一個 block這樣子是一個 block所以這就是 two-way那 four-way 的話呢

不管你是 one way 或者是 two way因為它是一個 cache size 就只有 8 個 entry所以我們知道說這裡面就是 8 個因為它每一個 row每一個 set 有 2 個 block所以它只能夠有 4 個 set你如果是 4 way4 way 就是變成你這邊是 2 個 set每一個 set 是 4 個 block如果是 8 way 或者是 fully associative 的話它就是只有一個set然後有八個block就是這樣子

所以後面他會討論到一些情況這個情況有點類似有點類似什麼呢就是類似我們前面跟同學提到的catch size就是說catch size是固定的那你catch size是固定的話你的block size要大一點比較好還是小一點比較好這個我們知道說如果我們的Cache Size是固定所以我們的Block如果太小的話你每一次抓一個Block抓到Cache裡面你有用的資訊數目非常少所以我們利用到的這個Locality就不會那麼的使用力利用力不會這麼的高

所以它的效果比較不好那你要提高你的block的size可是問題是你的block size如果太大的話呢相對的你的block number你的block number這邊就會變少那你變少的話呢就是等於你要競爭一個block的競爭者數目就會變多所以你的miss rate反而會提高所以你的block size只能夠高到一個數字我們大概就是要去知道說它

大概定在什麼地方我們會得到最好的一個hit rate所以這是我們前面提到的實際上這種associativity它同樣有類似的一個情況因為譬如說我們這邊這個fully我們這個fully associative我們就不用去管說他進來之後到底要擺什麼地方不是說不用管他進來要擺什麼地方是說我們不用去做 mapping進來看什麼地方有位置他就可以擺所以你整個 cache 裡面你只要有空位你進到這邊你就可以擺可是像這裡面 譬如說我們假設我們這邊

這邊有人 然後我們假設是這樣子好了我們發現說這個 cache 裡面其實也使用力才一半而已 對不對這樣子的 cache 使用力才一半可是如果我下一個 map 到這個 set我如果 map 到這個 set 的話就表示說這個 set 裡面一定有人要出去因為它已經滿了一定有人要出去他才可以進來他才能進來這樣子的

話就會感覺好像說我們都把這些這些明明都是空的但是實際上它因為有分set所以你這樣子它就必須要去做一個replace的一個動作它可能就會多了這種所謂就是說被搬出去被搬走的這一個萬一之後，又被access到的話，它就是miss它就有miss penalty。如果是像這一種的話譬如說我們只用了這四個，你下一個再進來就是它。如果說下一個進來，它就可以

使用到下一個進來。如果下一個進來又是這一個set set1，它又要replace掉一個。可是，如果在這個情況下一個進來，它還是有位置可以擺所以類似像這樣子的一個機制的話，這個機制我們可以看到的，就是說我們如果是使用這一種fully associative的話，看起來好像是可以減少它被人家一直在那邊搬來搬去 搬來搬去可是這個代價太高了

我們不可能允許就是我們知道說我們的cash size目前都還不會太小當然跟我們的made memory比較起來是小非常多但是它的數據的話，你要用這一種fully associative除非你是一個high performance的機制你的target是非常高 performance這個cost有多高的話，大概就是可以用這一種不然的話我們就必須要在我們的cost跟我們的2way跟4way或者是它有很多如果有很多種choice的話，我們必須要取得一個balance就是希望它的heat rate提高又可以minimize我們的hardware cost

這邊有一個例子它就是比較這三個不同的機制然後看看哪一個Hit Rate會比較高這邊它告訴我們說這個Cache有四個它是四個Block的一個Cache然後我們說這邊是Direct Map或者是 two-way或者是 fully associative我們的 block access sequence是 08 068我們就來看這三個不同的機制大概它的 hit 跟 miss 它的情況到底是怎麼樣以這個例子來看的話因為它有四個 block然後它是 one-way所以它是

這個 direct map 它就是 one way所以它有四個你可以把它看成它有四個 set每一個 set 就一個 block所以這邊是 0 1 2 3所以我們說 0 8 0 6 80 當然是放在這個 0這個 8 module 4它也是放在這個 0然後這個 0 也是放在這個 06 它是 module 12所以是擺這裡然後這個8又擺這裡所以我們可以看到這個set非常的忙它0先進來之後8進來它把0踢掉然後之後0又進來當然它進來之前先把8踢掉然後0再進來接著這邊是6它這邊在這裡

然後接著又一個8 8又把0踢掉變成它所以同學可以看到它全部都是miss在這裡面有五個access它全部都是miss全部都是miss的話這當然是最糟糕的結果如果我們看它是一個two way也就是說它有四個block然後每一個set有兩個block所以它總共有兩個set所以它總共有兩個set所以set0跟

set1所以我們只要去把它的block addressmodule2module這個set number我們就知道它要放在哪一個set所以這個0它是擺在set0就是擺這個位置接著8呢它module2也是0所以它也是擺在set0這裡面set0它有一個空位所以它就擺在右邊的這個block第三個他access0所以他又在set0這邊找到他自己所

以這個就是一個hit6呢6我們說這個module2也是0所以大家都想擺在set0set0已經滿了所以我們suppose是把這個8踢掉所以我們就6進來8出去下一個access8結果8又找不到結果8又把這個領踢掉然後8進來然後這邊最後的結果就是cache的set領裡面有8跟6同學會說我們這邊來看說我們5個access只有一個hit4個miss同學會說我這邊搞不好我當初不是把8踢掉我是把領踢掉 對不對

有可能我把0踢掉 然後6進來 然後8保留如果8保留的話 最後一個8就會什麼就會變hit可是為什麼這裡會把8踢掉 而不是把0踢掉呢它是有原因的 因為我們一般我們要決定說到底要把誰踢掉我們這個不是玩大風吹 不是說大風吹然後就就全部站起來然後趕快重新再站位置這

個不是大風吹他會去看說一般如果可以的話他會去看說哪一個使用率比較高哪一個使用率比較低使用率比較高的那一個我們就把它保留下來使用率比較低的那一個我們就把它踢掉這個是理想的情況如果我們可以用很簡單的機制就可以去記錄這個使用率的話呢當然我們就是用這樣子的一個機制來看那以這裡面這個例子來看的話呢其實不用看什麼它使用率有多高多怎麼樣

同學可以看到說我們XS6的前一格是XS誰XS0 對不對那這個0呢是HIT所以也就是說這個0呢在Cache裡面它才剛剛被Access到你0剛被access到之後接著這個0跟8你要選一個把它踢出去你會選0還是要選8大部分的人應該都會選說我們就把8踢掉好了因為8它都沒有被用到這個0剛剛才被用到就locality來看的話0剛剛被用到所以可能很快它又會被用到

所以這個0應該要把它留下來所以用這樣子的一個簡單的機制我們就知道說在這個範例裡面我們應該是把0留下來把8踢掉 然後把6擺進來所以這種就是簡單的判斷說它是使用率比較高的一個block所以它應該要reserve所以這是我們看到的這個two-way set associative接著我們來看這個fully associative那 fully 的話呢

它就每一個地方都可以擺所以我們同學看到說這個 block 0 進來就擺這一個block 8 就擺旁邊這一個block 0, hitblock 6 就擺第三個這沒有什麼好搶的空位多得很就慢慢填當你全部填滿了這個時候再來搶所以這個 6 就擺在 8 的旁邊，然後最後一個 XS 8，所以就 0, 8, 6 全部都在 cache 裡面所以這個就是 fully associative 的一個機制所以這個東西就可以明顯看到的就是說它的 hit rate 是最高的剛剛把這一部分的 associativity跟我們前面的 cache 跟 block size

做一個連結那個連結是連結錯的做了一個錯誤的連結因為這邊是在指這個price它的cost是比較高並不是說你的fully associative會降低它的heat rate所以我們這個例子就可以看得出來說極端的 天秤的兩個極端一個是direct map另外一個是fully associative中間就是n位 n位的set associative到這裡同學有沒有問題Cache的一大重點就是這個地方Cache的重點不外乎就是第一個它的structure它的運作的機制它的structure運作的機制大概就是associativity的三種

Type,Fully,DirectMap, N-way另外一個就是Mis-penalty我們要如何去算Cache它的penalty把Cache的影響放到CPI裡面另外一個就是我們前面提到的Block Size對Cache它的Performance的一個影響所以這邊講說How much associativity他说increase的associativity decreases miss rate当我们的associativity这种程度提高的时候我们会降低miss rate但是这边有个重点但是你一直往上提一直往上提

它不至於像我們前面提到的說你的block size大到一個程度它的mix rate反而會提高就是mix rate原本是一直降降到後來反而就往上飄就提高了它不會像這個樣子但是它會怎麼樣你的回報越來越少我們原本說我們從2-way變成4-way你發現說這個mix rate降下去了我們再把4-way變成

8-way它又降了然後我就想那我是不是一直提高這個associativity可以這樣子一直往上拉呢hit rate一直往上拉miss rate一直往下降這邊告訴我們說其實它好像會麻痺你得到的這種效果會越來越少這邊我們看到說我們的一個 Simulation 它是 64 KB它的 Data Cache 它的 Cache Size 是 64 KB它是 16 個 Word每一個 Block 是 16 個 Word它的 Run Spec 2000 的 Benchmark它說 One-Way 的時候我們的 Mist Rate 是 10.

3然後 Two-Way 8. 6同學可以看到從 Direct Map到 2 way 它很明顯有一個 gap明顯有一個 gap 就是到這裡2 way 到 4 way 它就變成 8. 3它也有降 但是它還是 8接著 4 way 變成 8 way它也有降 可是它還是 8這邊降了 1. 7這邊降了 0. 3這邊降了多少 0. 2這個就是我們這邊提到的diminishing returns我們一直提高它的associativity實際上並沒有辦法就是說

好像說我們可以這樣一直降越降越多它的game程度越來越少所以我們這邊用一個例子來看這個set associative的cash organization在這個例子裡面我們這邊有256個index也就是說我們有256個set所以這边256個set我們這边就是8個bit來index這256個set裡面的某一個特定的一個set所以以這個例子來看我們的index找到了這個set但是這個set

它这边是1 2 3 4它是4位所以我们要知道说这个4位里面的哪一个是我们要的哪一个是我们要的呢我们就是要这每一个位4位都跟我们的这个tag来做一个比较所以同学可以看到这边的这个tag就过来跟第一个位这个4位里面的第一个block做比较接著這個tag它也跟第二個block做

比較它也跟第三個block做比较它也跟第四個block做比较這個是一個parallel search我就從這四個block的tag裡面同時跟我的要找的這筆資料它的tag parallel search找到之後假設有一個是一比是相等這裡面會不會有兩個是1呢 會不會當然不會 只有一個是1最多只有一個是1當然它會miss最多它要嘛就四個都0要嘛就其中有一個是1所以同學記得這四條線只有一條

會是1這四條線最多只有一條會是1最多當你是hit的時候只有一條當你miss的時候這四個全部都是0所以我們可以看到這边這四個open我們用一個or有或這邊就會有所謂的這個hit當然每一個block的very bit前面已經end過了前面的每一個block的valid bit都確定要都是1然後還有這個tag是match這

樣子就對了所以我們這边如果有一個match的話我們就會透過這邊這邊有四個block，四個block就透過一個4對14 to 1的multiplier就會選出一個block出來，所以這個就是我們set associativitySet Associative的Cache Organization這裡面同學可能會覺得比較奇怪的，就是說這個4 to 1的Multiplexer，它的Input Selection為什麼會是四條線，我們4 to 1的Multiplexer不是都是Two Input Selection， 對不對同學還記得Multiplexer，你如果是4 to 1，它的Input Selection就是Two Bit8 to 1它就是3 bit，對不對它是3 bit，這裡是4 to 1，你不是應該要2 bit嗎，对

沒錯這位同學完全答對，它不是一個我們以前提到的什麼4 to 1 multiplexer，它就是一個2-input selection，因為你2-input selection那兩個2-input，它有可能同時會是1，那兩個input就是00選0然後01選110選211選3，就是這樣子，所以它是這兩個input selection，所以我們看到的，我們看到的是這一個，我們一般以前看到的是這一個這邊有 two input selection那位同學解釋的就是這一個我們那四條線呢！我們這四條線就是這四條線，它已經四條線最多只有一條會失一它等於是已經解碼過了，

它等於是已經解碼過它就是只有一個情況會適應所以來做一個AND就可以四個選一個出去，這是比較minor的地方，所以有一些比較細心的同學看到可能剛開始覺得怪怪的說它怎麼不是二選一不是兩個input selection它的原因就是在這裡接著我們來看repressment policy。 repressment policy這是指什麼呢？我們剛剛跟同學提到的，就是如果說它是一個 n-way，它是一個 n-way 的一個 set associative 的 cache structure。我們知道說，如果 n 個 slot

全部都填滿了，下一個 block 要進來的時候，你就要把一個 T 出去這邊我們提到的就是說 direct map它沒有 choice，因為它是one way，它就是一定是把存在裡面的那個把它踢掉。你可以說它的replacement policy就是在裡面，就是要離開原本在裡面，就是一定要離開因為它只有一個位置所以no choice。如果是set associative 的話，如果它有

這種non valid entry(non-valid entry)當然就是指說，那個entry是empty是空的。當然我們就是放在空的地方如果它的每一個entry都已經有用我們就必須要選一個選一個這邊就是我們剛剛提到的list recently used我們縮寫就是叫LRU你可以說最常使用的那個要留下來因為它可能有好幾個要選一個所以我們不要講說最常使

用的要留下來我們是要是選一個要把它排除所以我們就要選一個選一個的話那個就是最少被使用的選一個最少被使用的就是最近最少被使用的那一個我們就要把它排除所以這邊就講說Just the one unusedfor the longest time我們就選一個說最長時間都沒有被access到其他留下來的那一些被access到的period都比它還要來得短就只有這個是最久的時間沒有被access到所以舉個例如果有四個在裡面一個就是前一次access到它的就是

一個cycle然後第二個潛意識access到它的是兩個cycle然後潛意識access到它的是三個cycle潛意識access到它的是四個cycle當然就是那四個cycle的那個就是最長的就是沒有被使用的時間是最長那一個就要出去其他的就留下來這個理論上來講是最make sense對不對 最make sense可是就這個reality來看的話你要去implement這樣子的一個機制實際上是有難度的因為如果說我們這個N位你要每一個都要去maintain它的使用時間實際上是就是說

可能你的這個機制的複雜度的overhead會太大我們後面我大概會提一下就是說這種機制它可能是用一些其他的方法來取代就是希望有這樣子的一個精神但是它沒有辦法exactly就是說我真的就是找到那個最長時間沒有被使用到的你要這個的話你要去記錄每一段每一個沒有被使用到的時間有多久所以這個比較不好所以他講說

two way simplefour way manageable你如果是beyond four way那會怎麼樣too difficult too hard你要去真的是realize這樣子的一個機制基本上是有困難度所以說另外有一種就是random它就是random反正就random如果說它的associativity的數目是很高的話它直接就是random就是只要滿了它就隨機取一個這樣子的話是最沒有overhead你要去imprint這個LRU這樣子的機制接著我們來看Multilevel的Cache我們前面提到的都是CPU然後CacheMemory實際上我們知道說現在很多

這個CPU它並不是只有一層Cache它可能有這個Level 1 Cache Level 2 Cache甚至有一些更高檔的比較貴的它可能是Level 1 CacheLevel 2 CacheLevel 3 Cache它有3 Level的這個Cache所以我們來看一下這個Multi Level的Cache我們這邊大概也是就觀念上面做一個簡單的分析我們說這個最主要的primary cacheattached to CPU直接它是非常的

小但是非常的快它很小當然它很貴它很小就是因為它很貴然後它也非常的快它算是最快那level 2的cache呢它就是service misses from primary cache它意思就是說CPU它要讀資料先到primary cache去讀最好就是heat所以他就在primary cache就解決如果primary cache miss的話它不是到memory它到level 2的cachesecond cache second level的cache它到level 2 cache所以這個level 2 cache它專門是serve就是primary cache的miss這個level 2的cache它就比較大它的size比較大

它也比較慢相對於primary cache相對比較慢但是它跟main memory比較起來它還是快很多所以接下來第三層才是什麼呢？才是main memorymain memory就是你的L2 cache真的又miss它真的又miss那不得已之好就是到main memory就是這樣子這邊就是2 level cache的架構就是長這個樣子這邊我們剛剛提到有一些high-end的它有三層的cache同學說這個有什麼奇怪的地方你可以用兩層、 三層、

四層可是問題就是說你的primary cache它的特點應該怎麼樣level 2的cache它的特點應該要怎麼樣這邊指的特點不是指說primary cache是small and fast，但 fast然後level 2 cache是larger but slower不是指這個特點我們的特點就是說我們在design primary cache跟我們design level 2 cache的時候我們要focus它的optimization在什麼地方比如說我們要optimization的可以做什麼呢？我們可以optimize它的hit time

我們也可以optimize它的miss rate就是heat rate所以我們可以optimize heat time我們也可以optimize miss rate同學說那我就兩個全部都opt optimize當然兩個全部都optimize最好，但是你只要是optimize的東西越多你的代價就越高，所以我們總是要選擇一個比較可行的。我們讓同學猜看看好了，同學猜看看。同學覺得primary cache我應該要optimize hit time還是miss rate反過來level 2 cache我應該要optimize hit time還是miss rate

快要投票了，我們來預演投票一下好了。同學覺得這個primary cache我們要optimize這個miss rate的舉手，同學勇敢舉那我們再舉第二個覺得primary cache要optimizehit time的舉手，那其他人呢？ 獨立候選人是不是有沒有同學要講個理由的，就是你覺得說我應該要optimizehit time或者是miss rate，它是什麼原因

這邊有兩個level，第一個level是對CPU負責primary cache它是對CPU負責，同學可以想想看就是說CPU就是它在primary cache找到資料，這是它最高興的萬一它沒有找到資料跟one level的cache organization最大的差別是什麼對 如果是one level的cache，如果是miss的話他很頭痛 為什麼因為他就要去對付直接去跟那個超級超級慢的就是很慢的那個傢伙跟他要東西所以他要等很久所以這是只有一個level所以對這個CPU而言他很怕這個miss對不對。他很怕miss你一旦miss的話

他完蛋了。 他要去等那個memory可是如果說是2 level cache的話你到primary cache你去跟他要資料你miss他會怎麼樣他還有level 2所以就這個怕miss rate高的應該是level 2還是level 1同學說level 2 沒有錯我怕miss rate高的應該是在level 2因為你level 2你一旦miss你就怎麼樣你就要面對memory這個是大家最怕的事情所以我們從這樣子的一個角度來看的話我們可以理解說為什麼他們在optimize level 2的時候

他們是要去optimize這個miss rate因為他很怕去面對這個memory但是他在optimize primary cache的時候當然你miss rate是越低越好但是他的focus point反而是什麼是hit time因為你的miss rate再多低你的miss rate再多高基本上他的miss rate還是相對的是非常的低絕大部分全部都是HIT絕大部分都是HIT少部分是MISS所以你絕大部分都是HIT當然我要把這個努力，把它focus在什麼呢？ optimize hit time，因為CPU絕大部分都是HIT/HIT/IT在primary cache上面絕大部分都是HIT，所以它就是要去optimize hit time。當然你可以

說，我要把這個Hit rate，例如說從90%我要把它加到95%。當然也是可以，只要你覺得這個effort花下去是值錢，是夠efficient。當然你可以做，要不然的話，其實倒不如你就focus在你的Hit time optimization、你的Hit time夠快的話，你90%以上全部都是HIT得到的game相對是比較大，所以這個就是他們的設計的哲學，他們的觀點是這樣子來看這樣子來分析的話，其實這個也是make sense就是primary cache optimize hit time、level 2 cache optimize miss rate。原因就是我們剛剛跟同學提到的這邊同學有沒有問題

沒有問題，我們就來看一個Multi-level cache的example。我們說給定這個CPU的Base CPI，它是一個Clock Cycle/Clock Rate是4 GHz。我們的Mist Rate是2%，我們的Main Memory Access Time是100 Ns。如果說只有Primary Cache就一個level的cache我們來看說我們的miss penalty呢miss penalty它是什麼首先我們這邊的access time是給100個neural second我們先把它轉換成cycle number所以我們100個neural second除以0. 25neural second這4GHz 0.

25個neural second那一除我們知道說miss penalty天啊這是400個cycle你說時間很快但是你換算成cycle number你就覺得說400個cycle實在是太多了你簡直可以執行400個instruction所以這是400個cycle所以我們effective的CPI它是1加上0. 02它的mix rate 0. 02再乘以400個cycle，所以這樣子，一乘出來就變成9個cycle，所以我們的CPI從原本的一個

變成9，這個相當的大。我们現在来看这个2 level，我们来看2 level就是说我们假设我们有这个2 level就是一个level 2的一个cache，它的access time是5个neurosecond，它的global的miss rate這一邊你在level 2的cache你一旦miss之後你就要去面对memory我們這邊的man-memory前面提到的400個cycle就要出現了這是在level 2它的miss rate是0. 5%所以這邊我們說primarily miss with level 2的hit它的penalty就是5个neurosecond除以0.

25neurosecond我們得到說它是20個cycle這個不是，這個是primary miss然後要去level 2的cache講錯了， 這邊是level 2 cache的access time，所以這個level 2 cache的access time指的是指primary cache miss之後它的penalty你要到level 2 cache來做一個read所以它是花5個neural second所以這5個neural second轉換是20個cycle這20個cycle指的是指我們的CPU到primary cache去read的時候當它miss的時候miss它必須要到level 2、level 2的cache去read它要花20個cycle所以跟level 2 cache miss要到memory它要400個cycle來比較20跟400相對的是少非常非常多

我們這邊看到的就是primary cache的miss它的penalty是20個cycle然後level 2 cache的miss它是400個cycle所以這邊就有兩個這樣子的一個值它的CPI原本base是1然後加上我們前面提到的0. 2%的miss rate這是指primary cache的miss rate所以它要乘以20個cycle的penalty然後這邊它有0. 5的miss rate是在level 2的cache所以0. 005乘以400所以400還在可是這個已經被降到0.

5%所以這個scale就差很多它就從9降到3. 4不到3倍接近3倍 它就是2. 6倍就跟我們的只有一個level的Cache來比較的話它的Performance可以提高2. 6倍所以這邊Multi-level Cache的Consideration基本上就是剛剛跟同學討論的就是這邊主要Focus在Optimize它的Hit Time這個第二階段的 cache 它的 hit time當然一樣是有 impact只是說相對它的 impact 沒有那麼的大你有f-ray 要去 optimize

它也是沒有問題但是 first priority當然還是要去 optimize 第二階段的 miss rate要它越少越好所以我們這邊講說這個第一階段的 cache它通常小就是說跟單一個Cache來比較的話只有Single Level來比較的話它通常都是比較小然後Level 1的Block Size它也是比Level 2的Block Size還要來得小這個當然是會比較小因為你Level 2的Cache它的Cache Size

想也知道它應該會比Level 1的Cache Size還要來得怎麼樣還要來得大一定是它的Cache Size這個Cache Size比較大這Cache Size比較小它的Block Size當然也是要比較小所以這邊有提到我們前面提到Advanced的CPU跟Cache它的Interaction這邊其實他沒有說什麼他講的都是我們前面提過的比如說他這邊提到說Dynamic Scheduling叫Out-of-order的CPU它可以執行就是說它一樣可以執行這個instructionDuring cache miss它可以不要store它可以去執行為什麼它可以執行因為我們知道說我們Out-of-order

有一些可以事先執行的就是什麼情況呢就是說反正現在這一些functional unit你如果不執行它的話它也是在那邊idol它不能執行就是因為它有一些值還沒有ready還沒有確定或者是它不知道是要做這個還是要做那個，你讓它idol你倒不如就直接讓它就做了它做了以後它可能是白做，也有可能是猜對了， 做對了

所以就是必須要panned他必須要panned在他的這個store他必須要等就是等到說最後他已經決定說他已經知道說他前面他先做不應該做他先讓他做的他到底執行的狀態是對的還是錯的，他只要確定他的執行狀態是對的那他就可以write進去，他確定了這個都是我們前面提過的，所以這是他這邊特

別就是指到說你cache miss其實一樣，你也可以讓他做，但是你就是必須要去pending他的write的operation，但是就是說我們的要去分析這種program當然是會變得比較複雜，所以我們來看一下，就是說cache跟software的關係，他說interaction with software，他說MIS當然它會depend on memory access pattern這個基本上我們有做過一個實驗，不過我那個實驗已經不太記得當然我不是為了上這門課去做那個實驗是我們實驗室的一個

一個research的work做的一個實驗，我們把那個pattern的順序把它搬動之後，它的performance可以快好多倍我們猜測應該就是猜測，就是因為它的cache的關係就是你把資料存到array裡面，你不是像以前一樣就是漫無目標的 sequential的這樣子A0、A1、A2、A3這樣存有一些資料，它是有關係的。你把那些關係，把它用一個你覺得有意義的，它在讀資料的時候，它在讀的時候

就一次把那一塊全部都讀進去。你如果不做這些arrangement的話，你就隨意把它存在一個array裡面，實它在讀的時候，你讀一塊進來，它不見得會利用到那個locality所以我們把它安排之後，把它讀進來， 那一塊讀進來，大部分都是會被使用到這樣子整個Program的效能可以快非常多，這是我們做過的實驗，他這邊，他

就講到這個這個，我確定是這個樣子。他說Mist depend on memory access pattern不一樣的話，你的效能就會不一樣，所以這個Depend on your algorithm behaviorIt depends on your compiler optimization for memory access因為不同的compiler，你們的optimization mode，它所產生出來的code基本上是不一樣的，因為不同家的compiler，它們的技術當然不盡相同，所以它們產生的memory access instruction當然也就不一樣另外一個就是右邊這張圖其實它要強調的是第一個

algorithm的behavior就是它不同的algorithm它實際上是會有不同的效果所以我們可以來看一下說這邊是說你平均一個item大概需要幾個instruction你平均一個item大概需要幾個class cycle你這邊是一個item大概會有多少的cache miss你會發生多少個cash miss同學可以看就QuickSold而言它是比較可以理解的因為QuickSold它是一直比對 swap之類它是item的size 樹木越多的話它這邊是緩慢成長然後緩慢成長 上面拉上去

那上面這邊為什麼會拉上去呢這邊為什麼會拉上去它的cache miss為什麼會拉上去所以同學答對了就是說你看你的item你的item的數目越來越多所以基本上你要放cache你要把它搬一個block搬到cache裡面你大概沒有辦法把所有的item全部都搬到cache裡面去所以你這邊會往上拉這個quick salt它比較可以predictradic salt它比較奇怪radic salt

它本身它的做法就比較奇怪比如說你先scan它的個位數然後它是用bucket 對不對你就根據它的個位數把它丟到它不同的對應該bucket所以你第一次個位數做完以後它等於是把個位做一個排序它做一個排序它不是在那邊swap它是一個順序做一個很大的轉變它是 sequentially 丟到 bucket 裡面然後再從 bucket 裡面再把它抓出來把它串在一起串成一個 sequential 的 order這個 operation

跟我們一般的 sorting就是做一個旁邊的比對做一個比對 然後做 swap這樣子因為你比對 swap 基本上這個比較會有那種 cache因為你都是使用到周圍的這種item所以你對Cache比較會有它的locality的這種現象 RedicSol it就不是這個樣子你丟到bucket以後就抓出來然後串在一起串在一起之後接著又比對這個十位數的digit然後再把它丟到不同的bucket所以感覺它的這個element

它的這種變動是非常的大它的變動非常大它不是這種sequential的這種move的這種移動所以這個東西它比較沒有辦法predict像這個quick solve這樣子它就是我們一條很漂亮的一個curve這純粽是algorithm的behavior的問題所以你不同的演算法就是會讓我們的這種cache的operation可能增加它的miss rate我看我們這個留到下一次再講好了就是這樣子不會說這邊講了一頁下一次同學對virtual memory又不太有印象

需要寫到什麼程度呢就是我們會有你就寫一支simulator然後它又可以吃一些參數這個參數比如說像下面這裡有看到它的檔名是什麼那檔名通常就是比如說trace1 trace2 trace3這樣那我跑一次程式就是吃一次的檔案那接下來要可以吃就是這個cage的size有多大然後它的line size是多少還有就是associativity是多少然後還有他的policy是那個first in first out或是LRU這樣有問題嗎重要的地方大概是這裡這個你要用c或c++寫都可以對 那個

就是input的話大概會是像這樣的格式就可能是一些memory的位置之類的就像課堂上上的一樣那每一個檔案就是會有一些一連串的位置那檔案結尾的話可能大家用EOF來判斷會比較好因為可能會有好幾個位置之類的它可能不是固定的那你就一直吃一直吃吃到EOF這樣聽得懂EO

F是什麼嗎就是檔案結尾還有就是所以剛剛說的話我在comment line下的指令可能會像這一行這樣就是你的程式叫什麼名字然後檔名然後它的line size跟associativity跟它的政策然後最後的話就是你要輸出像這個output格式的東西這樣可以嗎那請大家就是我們會就是這一組嘛這裡有一組對不对請大家這一組就是一定要全部都測過因為大家都知道我們通常基本測值的分數都會給的比較高

那請大家就是這個一定就是把它全部都測對這樣的話我想大家分數應該都會蠻好看的那我們可能另外會再多測一組或兩組而已我剛意思是說比如說Trace1你的Policy就是First In First Out LRU這些都要測過那Associativity就是可能124或這些都你最好都測一下那最後就是環境的問題環境的話就像剛剛同學

問的就是你C或C++都可以那你要run在Linux或者是Windows上都可以那Linux的話就是用資工系上的工作站那或者是你有自己的server也可以跑在上面那如果沒有這些環境的話你也可以用Visual Studio那有沒有人其他是用別的環境我沒有講到的因為像 Dev C++ 這些就是你也可以放在 Visual Studio 上嘛你就用那個 IDE 跑就可以那大家有其他問題嗎？

做的話你可以把它做成Standard Input可以嗎？對對對對如果我想Visual Studio可能沒辦法像Linux這樣跑一個沒辦法跑一個Script嗎?那如果我們知道怎麼跑Script的話我們會把它放在E3上讓大家知道怎麼去用那目前如果就是假設大家都不知道的話你可以把它寫成Standard Input這樣可以嗎?只是這樣的話demo時間可能會稍微長一點那沒有問題的話lab6大概就是這樣子.