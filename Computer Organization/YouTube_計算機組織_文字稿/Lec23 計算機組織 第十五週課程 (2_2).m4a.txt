undefined
我們上次跟同學介紹到LRU的replacement的機制，我們提到在disk跟memory之間的level，我們有用page table來記錄virtual memory的virtual page到底對應到memory裡面的 physical 的哪一個 page當我們有發生 page 4 的時候，我們上次提到說我們會用所謂的 reference bit或者是叫 use bit然後來確定說這一個到底是不是有被 reference 過那就是選擇最近沒有被 reference 到的那一個 page把它 replace 掉我們提到說 OS 它會定期的就是週期性的去把它 reset因為，

因為你如果是用加的話，我們會有所謂的overflow的問題最簡單的一個機制不要考慮overflow這種問題就是1跟0這樣子來check所以就是定期會把它設為0這個是我們上次提到的有關於Page 4跟我們在Cache裡面的Mist它之間的差異是非常的大因為，我們提到說這個在 cache 的時候它如果說有 miss 的話，它需要這個等待的 clock cycle 的數目雖然說不是很大，但是基本上其實相對一個 clock cycle 跟數十個上百個 clock cycle 來比的話它已經很多了但是，這個 disk 它的 access

這邊說 disk write它是會花費掉這個幾百萬個所以我們在做這種replacement的時候呢或者是說我們到底什麼時候資料要Sync memory跟這個Disk的機制我們不可能是用Write-through我們前面Kesh有提到就是這個Write-through是一個就是天秤的兩個極端其中一個就是你每寫一筆它馬上就update到Memory那另外一個是Write-back另外一個極端是Write-back我們前面有提到在 cache

裡面如果是write-through 的話它的效能還是會受到影響所以通常都要搭配所謂的 buffer就是我們會有所謂的write-buffer所以我們如果是要跟 disk 之間的互動的話大概就是用write-back不可能是用write-through即使我們前面的一些方法我們希望說讓降低我們Page4它的Penalty我們使用的所謂的Page就是說我們用一個Page Table來記錄Virtual Memory跟Virtual Page Number跟Virtual Page Number之間的一個對應如果說我們要再把這個速度再往上提升的話

我們有可能還會再使用到一個就是所謂的就是說我們用這個同學可以想想看就是我們在access的時候如果說第一個我們要去access這個PatchTable因為我們說我們要從Virtual對應到這個Physical這樣子的一個Adjus的Translation的話它基本上是需要這個額外的Memory的Reference這個額外的Memory Reference的話它會當然就是說

雖然它只是多了一個Memory的Reference但是畢竟我們前面在談這個CPU的Operation的時候我們都說Memory的Access它都是很浪費時間結果現在我們卻需要再多做一個Memory的Access而且這個是一定要做的怎麼說呢因為第一個我們就是要從這個Virtual轉成Physical那Virtual轉成Physical這邊就

是要去AccessPageTable我們前面提到說PageTable它是放在這個Memory裡面MateMemory所以等於說它要先去MateMemory這邊去Access就是PageTable那轉完以後呢然後接著才是做這個真正的這個MemoryAccess轉成Physical的再做一次MemoryAccess所以它這樣子Total需要做兩次的MemoryAccess

所以這個就是我們提到的即使我們已經試著我們已經盡量降低這樣子的一個Page4我們大部分就是要Access的Data大部分都已經是在Memory但是它還是一樣會有比原本的效能比較起來它就是要多做一個MemoryAccess去做這個PasteTable有沒有辦法降低這個Penalty就是讓我們這個PasteTable的Access讓它變得更有效率呢要讓它

變得更有效率基本上它的觀念還是又回到我們前面Cache的觀念我們當初之所以會有Cache就是因為我們發現它有這個Locality它有locality的这种现象所以我们可以把这个memory里面的资料就是一小块一小块这样把它抓到这个cache里面所以我们就不需要到memory里面去读我们大部分都会在cache里面去access到我们需要的这个资料所以这个就是locality既然有这个locality的现象的话我們去accessPageTable有没有locality这样子的现象呢

这个当然也是有因为同学可以想想看因为我们的这个page我们说一个block它基本上已经数十个到数百个的这个word的资料如果page的话当然就是更大page更大的话我们每次在access资料的时候它其实很有可能大部分都是落在同一個page里面所以這樣子的一個Access實際上我們可以預期說我們要

去讀一個Page Entry我們讀到這個Page Table裡面的這個Entry其實它很有可能就是後面它會陸陸續續一直讀到這個Page Table Entry的資料所以這個就是所謂的Locality既然我們在讀Page Table Entry也有這種Locality的現象所以我們可以把Page Table的access把它加速再把它加速加速當然就是我們提到的就是再加一個cache就是再加一個cache這個cache其實我們有一個專屬名詞我們就是叫translation look-aside buffer的TLB這個TLB它並不是儲存我們要讀的資料它是存這個page table它把最近被

常常被Access到的PatchTable的Entry我們知道說PatchTable裡面有很多Entry它是一個Array of Entries它把最近常被Access到的Entry把它放到這一個Buffer裡面來放到Buffer所以這樣子的話我們在讀我們第一個Access第一個Access我們並不是到MainMemory這PatchTable所在的MainMemory emory的位置去讀這個PageTable而是我們就直接到Buffer裡面去讀所以這個觀念基本上跟我

們Cache的觀念是一樣的，-only是說我們Cache是讀我們要讀的資料然後到這個TLB這個Buffer我們是讀我們想要做的這個Address的Translation，我們要去讀這個PageTable Entry這個Locality基本上它描述的是在描述一種Temporal大部分發生的都是這種Temporal Locality，就是說我們這一個PageTable Entry目前被讀到，它最近的未來，這個Entry它很有可能還會繼續再被Access，這是所謂的Temporal Locality，它不是Special Locality，它為什麼不是Special Locality呢，因為同學可以想想看，我們在

讀資料的時候，它是有Special Locality對不對，但是，我們一個Page的資料量其實它已經很大了，所以我們在讀資料的這一種Special Locality，它的現象其實是發生在我們一個Block或者是一個Page裡面，它有這種Special Locality，這個Page很大，我們前面提到的Special Locality是在一個Page裡面，我們這邊提到Page TableEntry它會重複被Access到是屬於這種TemporalLocality這邊列出來說我們一般PageTableEntry大概要放多少個就是我們大概要容納多少個把它放在TLB

所以一般这边提到16到512个Paste Table Entry如果是Hit的话我们对TLB的Access大概就是0. 5到1个Cycle如果是Mist的话就10到100个Clock Cycle它的Mist Rate这边非常的低Mist Rate大概是0. 01%到1%所以我們可以發現說這個Mist Rate是非常的低如果是MIS的話，我們後面會看到它可以透過Software也可以透過Hardware的機制來處理MIS的情況所以我們等一下後面會看到這張圖就描述我們剛剛提到的我們在Physical Memory跟Disk的Storage中間

我們再加了一個TLB這個TLB並不是儲存我們要Access Read Write的這個Data它是儲存這個Patch Table常用的Patch Table Entry所以常用的這個Entry就會被放到這個Buffer裡面來所以我們要讀的時候我們會先讀這個TLB那TLB如果說可以讀到我們要的Patch Table Entry這樣子我們就可以從這邊很快地把這個VirtualPageNumber把它轉換成這個Physical的PageNumber那Physical的這個address就會出來我們就可以去access這個PhysicalMemory如果TRB miss的話我們會到PageTable裡面來看說它是不是

在PageTable如果它資料已經有把它搬到Memory裡面PageTable這邊有記錄那我們就會把這個PageTableEntry再把它搬到TRB裡面來這個動作跟Cache的動作是一樣的一個機制當然它也會有所謂的replacement因為這裡面的size是固定大小你要搬一個entry進來你當然就要踢一個entry出來所以我們這邊看到這個valid data reference所以這边都有同樣的一份copy所以這個就是

我們剛剛提到的TLB如果有的話它當然就搬過來如果沒有的話它當然就要到Disk Storage裡面然後去把資料再把它load進來所以這個就是中間加了TLB加了這一個它就會讓我們的就是你要做每一次要讀一筆資料你要做兩個Memory Access它这个penalty就会大幅下降因为同学我们可以看到说这边Kit它是0。

5到1个class cycle所以这是非常短的。你如果说不是这个的话，你就是always要多一个memory access你就要看说一个memory access需要花掉多少个class cycle所以，这个TLB是对效能的提升非常的有帮助那，这边的重点后面大概他就在提到说，我们前面提到的这个TLB miss的TLB的hit，这个是最好那少部分0。 01%到1%的TLB miss的时候怎么办呢那这边首先先跟同学讲一下他的这个观念那后面还会再介绍TLB的这个handler

這個其實就是我們前面剛提到說TLB miss的時候如果Page是在Memory的時候它就是把我們在Memory的PageTable裡面所要相對應的PageTableEntry把它load了從Memory把它load到Buffer裡面來就是TLB接著再retry就是去access這個TLB這個動作當然它是可以用這個Hardware也可以用Software就是你這種處理的機制可以用Hardware、

Software都可以然後如果說Page它不是在Memory就是所謂的Page 4那這個Page 4的話呢當然就是我們必須要透過這個OS然後就是類似就是透過OS的機制然後去Disk把資料把它讀進來然後再把剛剛你們要讀到的這個instruction然後再restart這樣子的話它就可以在TLB這邊讀到它要的

資料我們這邊提到說你可以用Hardware跟Software去implement這些instruction課本裡面其實它有提到說不管是用這一種或這一種機制其實它們的效能應該是不會差太多因為為什麼呢你這個Hardware跟Software這兩個機制它們的Kernel的Operation基本上是一樣的它要用到的KernelOperation基本上大

概就是同樣的Operation所以你用SoftwareSoftware基本上你還是要用那個Machine Instruction去兜那你用Hardware的話它的Operation動作要做的動作都差不多一樣所以效能不會差太多所以這邊提到的 TLB miss 的 handler它要做的事情大概就是一個是看它有沒有在 page table如果沒有的話就是在 memory這裡面有一個這邊提到一個比較重要的是說它必須要及早確認 TLB missTLB miss 當然就是說我們如果這個 instruction 它有 write 的話你必須要在

在write發生之前當然你要確定說它是TLV missTLV miss的話它大概就會有就是必須要等待一些時間然後才能夠把資料再load到TLV這邊過來所以大概就是需要透過exception然後去處理這樣子的一個機制然後再把這個不管是直接從Memory還是到這個Disk裡面然後把這些PageTableEntry把它load到TLB接著再restart我們的這個instruction它就可以在TLB這邊去找到它要的這個address那這邊它這邊提到說這個Page4

Page4的HandlerPage4的Handler就是我們剛剛這邊差不多都已經講過了這邊是包含我們剛剛提到的你TLB如果也不在PageTable它是在這個Disk裡面這個時候就是發生了所謂的Page4 Handler就是Page4必須要由Page4的Handler來處理它就必須要從這個Memory裡面把一個Page

把它搬到從Disk裡面搬一個Page那PageTable這邊就要update它的資料說這個Page到底搬到PhysicalMemory的哪一個位置然後PageTable那邊要update它的PhysicalPageNumber然後也必須要把這筆資料再把它搬到這個TLB然後才能夠啟動後續的這個instruction所以基本上大概都是一樣，這一頁有一

個很重要的觀念就是所謂的physically address cache跟virtually address cache什麼是physically address cache跟virtually address cache。這邊提到的就是我們前面跟同學講的這個機制，它是其中的一種方式。我們前面提到說，我們這個virtual address必須要先透過這個Adress的Translation把VirtualPageNumber轉成PhysicalPageNumber然後，在PhysicalPageNumber再搭配這個PageOffset兩個就會形成真正的Physical的Address，這個時候就可以做我們的這個Memory的Access。但是我們知道說，我們做Memory Access實際上並不是直接就是去Memory裡面讀，我們是到Cache裡面去讀這筆資料，

所以真的每一次都必須要這樣子來做一個轉換嗎？我們剛剛提到的這個就是所謂的Physical Address Cache，就是我們一定是把Virtual Address全部轉成Physical Address之後，然後再怎麼樣，再去透過Physical Address裡面去index。這個在Cache的哪一個位置然後index完之後然後再用這個tag去比對說tag到底是不是跟我們physical address的tag到底是不

是一樣這個是我們cache的SS的機制實際上並不一定是用這樣子的方式有一些叫virtually address cache顧名思義我們剛剛前面提到的方法是所謂的physically address cache如果我們把它改成virtually address cache我們大概就可以猜得出來它其實不需要做什麼不需要做translation對不對它就不需要做translation它就是直接用virtual address然後去index cacheindex完之後再用virtual address裡面的tag然後去compare比對cache裡面的tag跟我們的virtual address裡面的tag到底是不是

一樣同學會說這個聽起來好很多我們剛剛幹嘛要一直介紹 address translation然後還要有一個 TLB buffer 來加速加速 double memory access這個這麼好為什麼我們就不用這一個其實現在應該很少有人用這種 virtually address cache因為它有問題它有一些 potential problem 存在它有什麼問題呢它的問題其實很簡單它的問題就是我們知道說既然我是用virtual address去index我的cache那我們virtual address它有一個特性是physical address所沒有的我們前面提到什麼呢我們有所謂shareshare對不對

share你multiple task我們可以去share同樣的physical location所以virtual你不同的virtual address它可能會對應到同一個physical的location碰到這個問題就是所謂的alias的問題它就是所謂的alias的問題那你alias的問題要怎麼解如果沒有alias的問題的話其實我們去index cache的話這是一個自然不過的機制但是你如果有這種alias

那我怎么去解决这种多对异的问题这个是我们Virtually Addressed Cache它最主要的比较难实行的原因在这个地方所以我们才会前面一开始介绍这一种Physically Addressed Cache我们必须要做Translation同学会问说难道没有别的方式可以有比较比这个physically跟virtually这两种方式都还要好的吗当然是有

我们这边提到的就是说我们一个是一样是两个极端一个是physically一个是virtually其实我们可以用所谓的这个virtually indexphysically tag的一种机制来去access我们的cash什么是virtually indexphysically tag的cache呢從這個名詞來看的話我們也猜得出來說我們在index的時候是用什麼address是用virtual address如果是要比較tag的時候是用什麼呢是用physical的address所以這樣子的話我們可以解決alias的問題它還有什麼好處呢

因為它如果沒有別的好處我們就直接用就是直接用這個physically cache就好了我們不需要用這種所謂的這個virtually index跟physically tag它的好處就是在同學可以想想看就是我們用這一個virtually index跟physically tag它需不需要做translation需不需要同學覺得需不需要因為你如果不需要的話哪裡來的ph

ysically tag因為它就是需要physical address所以它是需要做translation既然你需要做trans lation感覺好像沒有什麼game我們說它不需要做才會有game可是實際上我們可以把這兩個一個index一個tlb access我們可以把它overlap因為第一個我們說它是virtually index所以我們不需要等去access TLB做translation才去index cache我們直接拿virtual addressvirtual address我們就是可以直接去index到底在page的哪一個set我們就可以

直接這樣子index那index完之後我們要compare tag那compare tag這個physical的tag從哪邊來呢就是我們可以想像說我們在我們用Virtual Address去Index Cache的時候我們同時可以去Access我們的TLB同時Access TLB然後找到我們要的Physical Page Number我們就可以得到我們要的Physical AddressPhysical Address得到以後我們就可以拿我們的Physical Tag來跟我們剛剛Index到的Cache然後去Compare它的Tag所以

这边它省略了一个什么呢它不是省略基本上同学可以把它想象成就好像把它overlap其实这个就是一点publine的味道publine它不就是把很多task把它overlap所以它就是index的时候它也去access TLB所以这两个可以overlap我们index完之后我们的physical address translation也完成了这个时候再拿physical的tag

去做compare所以這個就是我們說virtually index跟physical tag它的cache它的優點在這個地方這張圖實際上是在呈現我們剛剛跟同學介紹的就是要做translation的一個機制這張圖非常的重要同學要搞清楚它所代表的意義所以我們這邊提到的就是我們看看說這個就是virtual address它是32個bit32個bit我

們這邊看到的是virtual page number是20個bit然後它的page offset是12個bitpage offset它在virtual跟physical的adress都是一樣所以這邊是直接原封不動搬過來接著它就在這邊它就找到了他要的這個entry這個entry裡面記錄了我們要的physical page number把它對應下來所以這一個就是我們新translate完成的一個physical address這一個跟這個一不一樣同學常常被這張圖給搞混了這一個跟這一個這兩個是一模一樣的東西是一模一樣的東西，它的值是完全一模一樣，

差別只是我們的看法不一樣而已。我們上面這一個圖是我們看它如何從virtual address轉換成physical address它轉換過來的時候是分成兩個field兩個部分實際上我們可以把這個address就是把它分成我們要去讀cache的時候我們是這樣子看的我們是看成三個部分一個是block offset 一個是cache index一個是什麼呢tag 一個是tag這個tag就是所謂的physical address tag我們前面都是叫tag而已，它這邊加了physical address tag表示說它這個是

從virtual轉過來已經轉成physical實際上就是我們前面的tag就是這樣子所以同學如果翻到前面去我們在談cache的時候它就是分成三個欄位最左邊那個欄位就是tag中間這個欄位就是index然後右邊那個欄位就是offset所以這兩個東西是一模一樣只是我們在看它的時候看的角度不一樣我們看它看這個這樣子它呈現這個是因為它剛從virtual那邊轉成physical所以它就是兩個欄位當你要去定值你要去抓cache的時候，它是這樣子看

我們必須要把它分成三個欄位，這一邊分的 這邊怎麼分呢這邊是完全dependent on cache的structure根據cache的spec我們可以得到這三個欄位的資訊這兩個欄位基本上，它是根據我們這邊virtual address我們前面有一個例子virtual address我們說它的page offset是多少PageOffset多少之後我們就可以知道這個VirtualPageNumber是幾個bit所以是這兩個會derive成這個format然後根據Cache的機制它的structure我們可以把這樣子的一個東西把它轉成Cache的一個format就是三個field

三個欄位所以這兩個其實是指同樣的只是你切的地方不一樣TRB為什麼有30 bit因為我們的page number它不是會記錄說這個page到底有沒有被update對不對我們看一下我們回到這邊來看我們的page table基本上就是記錄每一個page它資料使用的情況這個valid就表示說這個有沒有搬進來有沒有搬到memory30的話就是表示說

如果它是 valid 它已經在 main memory這個 page 搬到 main memory 裡面有沒有曾經被 write 過如果被 write 過的話它的 30 要設為 1reference 就是它只要被 access 一次它就會被設為 1它會被週期性的被 reset 成 0所以這個是 for replacement這個是 for write back就 write back 的時候這個page要被搬出main memory要被搬出main memory的時候我們要根據這個dirty bit來

決定它要不要把這筆資料寫回hardd因為如果沒有這個bit的話你最保險的方式就是每一次replace它踢出main memory它就要寫回這個hardd裡面可是寫hardd這個write time實在是太長了所以一定要確定說它是曾經被update過的那我們再做write如果沒有被update過就不需要做write所以為什麼TLB要有得

體因為TLB基本上它就是反映反映這個page的information如果沒有TLB我們先看沒有TLB好了沒有TLB你page在main memory裡面如果被update的話你得體就要設為1我們現在有 TLV 只是為了我們不要每一次都到 page table 去讀因為 page table 是 main memory 的 access它很花時間我們不要每次都到 main memory我們就是到另外一個 cache這個 cache 叫TLV所以你去 access你對 page 做 write它也是對它做 access所以你對它做 write你當然也必須要在這邊 update把它設為 1設為 1 表示說

這個page它已經被update過資料了比如說假設你就連續寫了10次你連續寫了10次好了寫了10次的話如果你這邊TRB沒有這個30bit你等於你那10次你都要寫到page table裡面來因為我不知道我這一次寫是不是最後一次寫所以我每一次做write的時候它就要update你的PasteTable的30bit所以你update了你就等於做了一

次MateMemory的access所以你要做十次那你如果有TLB的話你就是一直做十次的TLB的write你不需要做這個PasteTable你不需要到MateMemory去write十次你就是十次都在buffer裡面做write而已你如果TRB沒有這個ability你只要write你就要寫到page table你就一定要寫到page table你如果沒有寫到page table的話你等於你那個write的資訊已經不見了已經丟掉了它曾經被write的information已經lost掉對不對不然你如何

不然這樣講好了就是說我們TLB沒有dirty你有什麼辦法我說我寫了十次對不對我寫了十次這個時候它要被replace掉TLB裡面沒有dirty的information你如何讓它知道說你這個page曾經被write過就是你要考慮這個問題你如何知道這個page曾經被write過你沒有辦法知道除非你都寫到這個地方來但是你寫到這個

地方就很浪費時間剛剛我們這邊提到的這裡有dirty它就不需要寫到這裡它只要寫到tlb所以它就是這邊這裡有的它這裡都要有因為它可能會update這邊的status information那你如果沒有把這些Status的Information也放在Buffer的話那你要嘛就是Lost掉你的Status要嘛就是你每次都要在你的MateMemoryPasteTable裡面去Update這些Information那即使它是一個Bit它還是一個MateMemory的Access這個都是很浪費時間的所以它主要的目的是在這個地方

所以這個是我們這邊這部分就是TRV跟這個等於就是說Virtual address跟這個Physical address然後它用來定值這個Cache它們之間的一個關係這個觀念這個就是如果講期末考的話我們幾乎每年都會考的因為這是很重要的觀念。同學如果這邊通了就表示說你對這個Memory的Access它的機制大家都完全了解。所以同學

在讀這一邊的時候不要把它分開讀。同學可以試著試著就是說我一個Virtual address那你如何去看我們的這個比如說Patch Table它的AccessPatch Table的變化然後還有就是說在Block裡面它有Block就是cache的access它的cache它的hit跟miss它們之間它也有變化。這是要易以貫之把這樣子整個觀念都融會貫通這樣子的話這邊同學就會比較清楚。如果同學在中間如果覺得有哪邊卡卡的就要趕快來看是要上課的時候發問還是要在那個E3平台可以討論或者是來找我都可以

這邊一定要弄清楚。我們繼續來看這個Memory protection的部分。 Memory protection我們這邊就有提到過說我們不同的這個Task它可以Share就是Share他們的Virtual address的Space。我們要保護這個Memory或者是某一些資料它到底是Private或者是Share memory。我們前面有提到過都是需要透過OS的幫助當然也不是說就是OS完完全全都是透過OS來。做這樣子

的一個ProtectionHardware的一個Support是非常重要如果沒有Hardware Support的話OS大概也很難做到這樣子的一個地步像我們最常見的我們就是會把就是說我們會有提供兩種Mode一種就是所謂的Supervisor Mode或者是叫Kernel Mode另外一種就是所謂的User Mode對於一般的Process而言當然它Run大概都是Run都是用這種User Mode的方式在Run尤其是對一些特別Private的Resource它並不是所有的這種User Mode的Process它都可以Access如果是Memory的話

當然它也不是所有的這一種就是說某一部分的memory它也不是所有的process它都可以access所以如果說你要有比較大的那一種控制權你要去access那種比較敏感的大概就是要進入所謂的這個supervisor mode或者是kernel mode那如何進入supervisor mode呢要進入supervisor mode基本上就是要透過一些特別的instruction我們就是叫

這個instruction這個prelease的instruction你只要去執行那個instruction它可以允許你把目前這個process從user mode把它change成這種supervisor mode譬如說類似用這種system code的一個方式用system code的方式我們可以去change這種mode，你可以進入這個supervisor mode之後一些就是Memory的一些Location或者是像一些Page Table或者是在反正它原本是在Supervisor Mall才能夠Access到的State Information。我們這個時候就可以Access得到所以透過這樣子的機制，它OS就可以非常清楚知道說到底誰目前是在User Mall Supervisor Mall那哪一些Process它可以Access到

這一筆資料如果是被保護的資料哪一些Process是不能夠Access所以它不可能是User Mode的Process去Access被Protect的Data。所以這樣子的話，OS它要去Manage這樣子的一個過程就會相對的比較容易當然這個只是觀念上面的一個描述同學如果有興趣的話，我相信在OS那門課應該會介紹得比較深入接下來我們要跟後

面的部分我們要跟同學介紹的即使我們剛前面即使Memory到現在我們介紹了一個Cache還有就是Memory一個是Cache介於CPU跟Memory之間然後另外一個我們說我們這個Virtual Address它是Manage我們的Virtual Address的Space跟我們Physical Address的一個Space之間的一個Translation所以到目前為止我們至少看到的這個 Hierarchy 它總共有兩層就是一個是就是我們的這個 hardd然後 main memory然後再到 cache然後接著就是 CPU

要讀的這些資料那這些 memory 的這個 Hierarchy不管是怎麼樣基本上它就是最重要的大概就是下面這四件事情在每一個 hierarchy 的 level我們都必須要知道這個 block 的 placement它到底是如何進行然後我們要如何找到我們要的 block我們原本要的資料它的位置是這樣子這個位置我們要如何在這個比較快的一個媒介上面找到我們要的資料所以要如何找到這個 block如果 miss 的話是不是要做 replacement

還有Write Policy就是我們一旦已經有分Hierarchy所以我們寫資料我們就不是寫在Memory我們也不是寫在HD我們可能是寫在Cache上面那要如何去把我們update的資料再 Write回Memory或者是這個HD它也有它的這個Policy所以我們後面我們會根據這四個重要的機制會做一個探討其實介紹

的東西前面都已經介紹過了我們只是後面再做一個整理順便介紹幾個新的名詞我們先休息一下我們來針對我們剛剛提到的Memory Hierarchy它每一個Level裡面就是要注意的四個重點我們每一個來看一下我們說這個block placement我們知道說這個block的 placement它是由這個associativity來決定的我們前面提到

過它有三個機制一個是direct map這個其實就是one-way的associativity另外有一個n-way set associate這個n-way set就是你一個set你對應到一個set之後我們會有n個位置可以擺另外一個是fully associative所以它就是沒有set它整個cache你可以把它看成它就是一個set所以你任何一個block實際上都是對應到這個set所以它根本沒有什麼set index的問題它就是全部都是用comparator來比對它的tag我們也知道說比較高的associativity可以reduce miss rate但是

你的 associativity 太高的話越來越高的話，它們會有什麼問題呢？就是說本身它的這個complexity，它也會比較複雜cost cost 就是 comparatoraccess time 也會增加同學會說 access time 怎麼會增加呢同學應該還記得說，如果我們是一個我們是這一種只要是有 n 位的 set associative 的話同學應該還記得它每一個都會有一個comparator所以你如果N越大

的話comparator就越多所以這個就是我們說的這個cost就越來越多SS time為什麼會增加呢complicity complicity本來就增加因為你原本只要5個comparator就好你現在要20個100個comparator這個複雜度當然就增加了我們知道說這麼多個comparator同時進行在比較只要有一個比對是正確是完全吻合這個基本上就是HIT你要這麼多個comparator

然後有一個比對成功它就是HIT我們就需要一個OR同學應該還記得就是每一個comparator的結果它會全部接到一個OR接到一個OR GET我們前面已經提到過說這一種design我們的input number如果越多的話那本來它的delay就會越大它的delay就會越大所以你說你一個all你接了5個input跟接了20個input接了30

個input但實際上的設計不會有那種你接了三四十個input的一個all get它一定是用另外一種方式來做一個轉換那你anyway你不管是用什麼方式做轉換你還是一樣你就是會讓你的delay的時間會變得比較多所以它的access time本來就會比較長所以這個是從Hardware的Design角度來看同學應該還記得我們那時候在介紹Aether有沒有我們介紹Aether你把它分成不同的Hierarchy也是因為你最後一層All gate它不希望有太多的Input所以這個是同樣的一個原因

第二個我們是說要如何去找一個block如果找一個block這邊就牽涉到我們這邊三個機制這個我們都再複習一下就是direct map它的tag的comparison只需要做一個因為它就是對應到的這個index找到之後它也就只有一個地方可以擺因為它是one way它沒有說有multiple choice這個tag它只是在比較說它有很多個location會對應到同樣的這個block所以它要知道說這麼多個physical的位置對應到這個地方到底是不是真的是

我要的那個對應過來的另外如果是n位的話你除了這個 set index去index某一個set之外在這個set之內你必須要做anger comparison所以它是同時進行anger comparator如果是fully associative就是我們前面提到的它不需要去做set index它就是直接做comparator所以你看你有幾個entry你就必須要有多少個comparison就我們Cache的一個設計的話因為這

個牽涉到這個cost的成本的問題所以我們是希望去reduce這個comparison去reduce這個cost如果說你沒有這個cost的issue的話你說那我就是盡量提高這個associativity那你大概就是用fully的associative不過這個成本代價太高了所以這一般在cash裡面大概不會是這一種Virtual memory的話它的考量又是另外一個因為Virtual memory它是牽涉到Mate memory

跟HD之間的interaction Mate memory它的access已經讓CPU沒有辦法接受如果是對HD的access那更是一個非常它可能認得是一個很大的災難它要等太久太久所以這種的Virtual memory它根本不可能就是說它是希望它的m iss是越少越好所以，它尽量要去reduce它的miss rate，所以，它可能就是用這個full associativity這樣子的一個方式來降低它的miss rate那replacement這個也是我們前面提過的就是一個idea的情況之下我們是希望是LRU

最近最少被使用到的我們就希望把它replace把它剔出Cache或者是剔出Memory就用這樣子的機制來進行，但是如果是Cache就是CPU，Cache, Memory之間的這一層的話我們要implement這個LRU的話可能是太浪費所以可能它可以用這種random的方式它比較容易去implement如果是Virtual Memory的話我們前面有提到說它會

一個週期性的一個Reset再搭配一個Reference Speed這樣子的機制來Approximate這個LRU這樣子的一個SkinWrite Policy這邊就是我們提到的一個是Write Through另外一個是Write Back那通常Write-through我們當然是用在這個Cache就是CPU Cache Memory這個Hierarchy那這個Write-through的話呢它是最不需要去就是說你還

要再去記我這個Block它到底有沒有被update就是像那個我們後面有看到一個叫30bit就30bit它要去記錄它有沒有被update那你如果是Write-through的話你完全不用記錄說它有沒有被update因為它每次write它就update每次write它就update因為我們知道說write-through這樣子的話你等於說你必須要就是說可能有兩種方式假設你設計的是說你只要CPU去做cache access你要等到它的這個整個都complete之後你的CPU才能夠繼續進行結果你幾乎你是等於

你每一次都要write就是等於要等它做Memory Access做Memory Write所以這個是沒有辦法忍受所以我們通常都要再加入這個Buffer就是一個比較中間就是一個緩衝的機制Write Buffer至少你Write到這個Cache之後它還有一個Buffer把它就等於你就寫到Buffer裡面去CPU它就可以去做它的事情Buffer它自己

就慢慢的一個一個把它寫到這個Memory裡面那另外一個是Write Back這個大概就是我們在這個Virtual Memory這邊必須要使用的這個Write Back那這邊介紹了三個名詞這個三個名詞就是對我們所謂的這個Hit跟Miss，它的Hit Miss的這個種類我們把它分成一個叫Compassory Miss，一個叫Capacity miss，另外一個叫Conflict miss或者

是所謂的Collision miss就是這三種miss，那什麼是Compulsory miss呢，這一種或者是稱作叫Costar-Costar miss,Costar miss！就是我們一開機的時候機器一開，它裡面應該是就是都是裡面都沒有東西那你process開始進來以後它就開始抓資料進來開始抓資料進來，所以你剛開始沒有東西然後你 process 開始 run然後你開始抓資料你開始抓資料

之後，這裡面每一筆資料都是第一次被抓的對不對，每一筆資料都是第一次被抓，它沒有所謂說它已經很聰明，它一開機它已經先把一些預知這個 user它的使用習慣然後把它的一些資料都先全部先漏的進來或許可以這麼做他要去分析這個user的使用習慣才有辦法，所以如果沒有的話，你每

一筆資料都是第一次抓你第一次抓當然第一次都是miss第一次都是miss，所以你第一次抓這筆資料它相對應的block第一次進來的時候它就是miss你miss抓進來以後，後續同一個block裡面它就會開始hit hit hit！就是這樣子，所以這一類的miss就是所謂的compulsory miss就是first access to a block我們剛剛提到的是就是說剛

開機或者是你一個process剛開始被run或者是你一個process在run的時候這個block從來沒有被access過都是屬於這樣子的一個情況就是你process在run的時候假設它total會access到20個block那你這20個block總是有第一次被access的時候所以你第一次被access的時候它一定是miss那這一種就是compulsory miss那第二種就是capacity miss capacity miss它最主要就是因為我們的cache size它是有限的那cache size是有限的就是說cache size有限比如說這個cache它的size

讓我們只能夠容納20個block所以它同時只有20個block可以放在這個cache裡面當你要access到第21個block的時候它就必須要把這20個裡面其中一個block把它踢到main memory裡面然後這第21個才能夠進去變成第20個這剛被踢出去的那一個當它被踢出去之後後來又被access這個時候它就是miss就對被踢出去的那一個block而言它在重新被access到的時候

它就是一個miss所以這邊就講說一個被replace的block就是被踢出cache之後又被access到這一種就是屬於capacity miss為什麼是屬於capacity miss呢因為它是由於cache的size太小的關係它只能夠容納20個block它沒辦法容納21個那你如果case size大一點它可以容納22個所以剛剛21個進來的時候那一個被replace的它就不需要被踢出去那它不需要被踢出去它就不會發生miss所以這一類的miss就是稱作capacity miss簡單的描述就是一個被replace掉的block之後又被access

這個時候你會發生miss這個miss就是叫capacity miss第三種就是conflict miss或者叫collision miss顧名思義就是剛剛這邊是block在搶這個conflict就是你如果不是這個fully associative我們一定會有這種好幾個在搶同一個位置好幾個在搶同一個位置這種因為互相競爭比如在一個set裡面它會有好多個人都在搶你先進的就先贏當你這個set已經全部都佔滿了你下一個要再進來的時候沒地方放

它搶輸了總是要有一個人要出去所以那個要出去的，它就是被 replace掉被replace掉這種就是屬於當它又被access那它就是屬於Comfort的這個Mist所以它就是屬於Comfort Mist所以這個就是我們就是它這邊有說Compassory, Capacity還有Comfort，它在Set裡面的一個競爭，那如果是Fully Associative的這個Cache的話，呢它就不會有這種情況因為它這邊

最主要就是說它在一個set裡面的competition，一個set裡面的competition，它是把它定義成conflict miss這個fully associative，因為它沒有說multiple set，雖然我們說你可以把它看成它是一個single set，不過它這邊它是認為這個純粹是觀點的問題，它可以這樣子定義所以它既然定義的話，我們這邊就follow它的定義就是說你fully associative他就是不會有這種情況，所以這三種miss同學就是要搞清楚它到底是針對哪一種condition發生的所以他這邊他把它分類成這三種之後接著他就開始來討論說我們的

cache的design到底要怎麼設計然後才能夠去就是說這樣子的一個設計到底會minimize哪一種miss另外一種設計會minimize另外一種miss，他就是做這樣子的一個討論，我們了解了這種情況才知道說我們的Cache Design可以如何來做這個trade-off來做一個取捨第一個我們這邊就是Design Change他就講說我們有三種Design Change，第一種是Increase Increase our case size Increase our case size呢，第一個我們想到的就是什麼？我們如果說我們的case size增加case size增加我們剛剛前面提到的就是說

我們的這個block的數目就可以比較多，我們不會因為說你這個block不夠多所以你必須要把一個block把它replace掉，所以這一種很明顯，它就是它可以降低什麼？ Capacity Miss它可以降低Capacity Miss，那Cache Size增加呢，它有可能的就是Increase我们的这个Access Time，因为你Memory的Design或者是Cache的Design都一样，就是反正你的Size增加它的Complicity变得比较复杂那我们的这个Hardware的一个Design就有可能会它所需要的Delay就有可能会增加，所以这一种？就是

造成的 hardware delay 增加其實就是你的 access time你要去讀它要等多久才能夠讀得到這基本上就是 hardware design 的一個問題如果說我們增加這個 associativity 的話我們知道說我們就可以 decrease 我們的 comfort miss因為我們這邊所謂的 associativity 指的就是指說我們有這個 multiple set我們在每一個 set 裡面這個associativity的數目讓它增加那我們

的conflict miss我們討論的就是討論在一個set裡面它因為競爭而導致被replace之後又被access這樣子的一個情況那你如果這個增加的話它可以容納在一個set裡面可以容納的block數目自然就變多它被replace的機會當然就會比較降低所以它可以 decrease這個 comfort miss它有可能會 increase 它的 excess time它為什麼會 increase excess time呢這個其實就是我們前面提到的associativity 增加的話你的 comparator

數目增加你 comparator 數目增加你 comparator 的結果最後必須要把它 all 在一起所以你那個 all它的 input source 數目增加自然而然我們的這種GET delay或者是Hardware不一定是一個GET，它可能是用另外一種方式去完成這樣子的一個ALL。 Anyway它的Hardware的Design的Delay自然它有可能會需要比較多的一個Delay所以Access time就會增加。那如果是Increase我們的Block size那這個就是很知久我們就可以想到Block size增加呢。我們的Compassory miss

就可能會減少對不對因為compulsory miss就是我們前面提到不管你是機器是屬於什麼狀態它的重點就是我們提到你一個process run下去的時候你這個process所需要access到的block它第一次被access的時候一定是miss第一次被access的時候這個miss就是叫compulsory miss。所以我們要如何降低第一次被access到的這種miss就是你把block size

增加你把block size增加你一次讀多一點資料進來那你讀多一點資料進來。我們suppose我們在讀資料的時候它不會跳到別的地方它就是都是在這樣sequentially的access那我們當然就可以避免怎麼樣避免再去access另外一個block的一個情況這個就只是一個很簡單的觀念就是說我們假設就是做這樣子的一個access

那我如果block size這麼大我只要miss一次我的block size如果小於半所以我第一次miss就抓這一份進來當它讀到這裡的時候它會發生第二次 miss對不對 就是這樣子當然我們這邊就不要去討論說這個block size應該多大這個只是一個general 的concept我們一般 general concept就是你要降低compulsory miss大概就是要增加你的block size要不然的話你就等於要miss幾次才能夠分批把這一筆資料全部一個一個block把它搬進來這個就是我們在這邊所主要比較常看到的increase cache size increase associativity increase

block size這三個面向然後分別會有這幾種情況當然我們剛剛提到的 increase block size又會回到我們在介紹Cache的時候一開始提到的它有可能會怎麼樣它有可能會因為這個pollution你一次抓太多你一次抓太多的資料進來可是實際上我們不可能都會這樣sequentially的一直在這一大塊在區域裡面一直做access它跳到別的地方去的時候

你就會 miss你跳到別的地方去，你會miss結果。你這一大塊裡面抓了這麼多資料進來，這個沒有用到的抓了一大堆沒用到的資料進來就是我們前面提到的pollution它可能會發生pollution另外還有一個就是你的miss penalty, miss penalty就是你miss的時候你要去memory或者是你要去hd去抓資料一個page或者是一個block抓到cache裡

面來，那你要你的一個block的size比較大你自然就要抓比較多的資料到這個cache，你抓比較多的資料你的penalty當然就會比較重你要等比較久的時間去抓那些資料所以這個是increase miss penalty，這個是一定會發生的那這種increase miss rate的話呢它就是你有Pollution它就有可能會Increase這個Misery所以這個Tradeoff接下來我們再來看這個Table這個Table其實它是在探討什麼呢，它在探討這個TLB還有Page Table還有Cache這三個我們真正在Access一個資料的時候

他們這三種這三個這個Memory它到底會發生什麼樣的一個狀態，這個狀態每一個比如說TLB它可以Hit它可以Miss然後Patch Table它也可以 Hit它也可以Miss然後Cache它一樣可以Hit它也可以Miss這幾種組合到底哪幾種可能會發生這邊考慮的是就是所謂的這個Physically Cacheindex cache就是physically indexphysically tag的一个cache既然我們知道說它是一个physically的index cache我們就知道說它access的順序是什么它access的順序第一个一定是讀誰这个嘛 对不对这个读到假设是hit的话

那我們就會開始做translation然後轉成physical的一個addressphysical的address接著我們就會去讀這個physical addressphysical address出來以後我們就可以去讀cache因為cache是physical indexphysical tag的一个cache所以它就可以去讀cache就是這樣子如果說TLB miss的话那我們就要到PageTable去讀PageTable去讀不管是Hit或者是Miss最後我們就會轉換成一個Physical的一個Address然後才有可能去Cache這邊讀所以我們要先了解這樣子的一個順序了解這樣子的一個順序之後其實你課本裡面，它也有寫像第一個就也不知道它在寫什麼。

第一個你說這個TLB hit，他說Patch table hit然後Cache miss。我們如果不要看Patch table，我們看TLB hit Cache當然有可能hit，有可能miss，這是很正常的。 對不對，那我為什麼還要到Patch table去access呢？我TLB都已經要到我要的資料了，我幹嘛還要去Patch table accessAnyway，他說這是possible他是说 虽然我們已经没有必要去做这个access反正他这边他就把它

列成是possible不过同学要了解说根据这个机制，我们实际上TRB hit我们是根本不需要再到Page table去accessTRB hit资料就已经是在已经确定是在main memory而且我们已经拿到我们的physical page number要的资料都有我們就直接轉成 physical address然後接著再去 cache 做 access所以它有可能是 hit 也有可能是 miss接著他說 trb misstrb miss 當然接著就要去 paste table access所以你 trb miss 之後你的 paste table假設是 hit 的話就表示這筆資料已經在 main memory已經在 main memory

我們把它轉成 physical address我們接著就要來 cache 這邊看說它有沒有在 cache那有沒有在 cache當然有可能 hit 也有可能是 miss當然有可能所以這兩個都有可能會發生所以這兩個組合它有可能是會發生的一個 access 的情況那另外一個 另外一個說 tlb miss然後它就去 paste table 去 access 去找pitch table也miss所以他就知

道說這個情況就表示這筆資料在什麼地方呢在secondary storage假設我們說是hardd他是在hardd他不在main memory所以這個時候你這個時候去case去抓不可能會是heat因為他都已經不在main memory他不可能在cache所以同學要有一個觀念這筆資料如果不在 main memory它不會在 cache 裡面因為 cache 是它的 size 相對的是非常非常小它是替換它是相對的小那你 main memory 的資料那麼的大它如果不在 cache它如果不在 main memory它不會在 cache它一定是搬進 main memory

之後它超有可能從 main memory 裡面被搬到 cache所以這一邊不可能說這個也miss結果這邊是hit所以這個 miss miss miss miss，這個是可能的接著這邊他說，如果TLB hit，然後page table miss，還有可能嗎？當然不可能，你TLB hit就表示這筆資料最近一直被access，一直被access，它就是在main memory裡面的，所以這個它當然不可能是TRB HIT結

果Pace Table是MISS，所以這兩個都不用看了，這兩個IMPOSSIBLE跟它沒有關係跟這個Cache沒有關係，是跟這兩個的組合有關係，這兩個組合不可能發生。最後一個就是我們剛剛提到的TRB MISS，Pace Table是MISS，就表示它在Secondary Storage，所以它不可能在cache裡面，所以這個就是它不可能說這個miss 這個要hit所以這邊這個table同學就要了解它這樣子的一個組合大概，它這個只是在測試我們對這樣子的這幾個TLB、Page Table、Cache access的順序的流程要了解，那這個大概就沒有什麼問題，

這邊有沒有問題到這邊我們的Virtual Memory跟Cache大概都介紹完了，所以重點應該很清楚，重點其實就是在我們最後Big Picture之後提到的那些方法機制Hierarchy裡面都會面臨的這個問題，它只是做一個review跟整理那detail的內容同學應該就是看這個課本裡面的分析接下來我們要跟同學介紹這個Virtual Machine有使用過Virtual Machine的同學舉手還蠻多的我們系上有一位Virtual Machine的專家同學知道嗎？

就是徐惠中所長他是Virtual Machine的專家他好像也有開一門Virtual Machine我以前也用過用那時候是因為早期大家不知道說Apple它的CPU我們知道說Apple Computer我們不是在講它的Portable Device我們是在講Computer不是講手機也不是講iPad我們是在講它的那些什麼iMac還有什麼之類的就是它的什麼MacBook Pro什麼之類的它們那些Mac的電腦它們早期的CPU它們並不是用Intel它們是用Power我記得好像是叫PowerPC什麼之類的好像是IVM他們做的IVM他們design一個蠻不錯的一個CPU的系列

那它PowerPC當然它跟這個Intel系列的CPU是不太一樣的所以以前這個Mac它的這個電腦它沒有辦法run這個微軟它的這個軟體所以以前Mac你只要是用Mac你大概沒有辦法用那個大家都習慣的就是Office微軟的這個Office但是後來他們開始有慢慢把這個off ice port到這個Mac的computer上面但是在以前那個Mac

它還是一樣就是它的市佔率非常非常的低這個以前在第一章已經跟同學講過剛開始Personal Computer出現的時候Mac是不可一世它是非常興盛的後來Personal Computer出來之後它就節節敗退後來它的市場就小到不行它的market share是小於10%全球的這個computer的市佔率是小於10%非常非常小那它就是

因為它的獨特性還有封閉性所以喜歡Mac computer的大部分都是就是那些小錯人就是那個現在很流行的什麼什麼粉絲什麼什麼粉絲什麼就是那種就是只要那個有人一出現然後底下就開始鼓掌這樣子但是後來他們發現說當然就是因為有人實在是覺得Apple的設計做得很好所以他們開始

做那個Virtual Machine在早期它還不是用Intel的時候用PowerPC這種CPU它就是做了一個Virtual Machine你可以在它上面Run那個Virtual Machine你就可以把你所有的這個我們PC的所有的軟體全部都灌到上面來因為以前剛好用一台Wall Station是Apple的後來發現廠商他們有介紹那個Virtual Machine所以我用過我

用過的可能是早期的那速度非常的慢那個原本是在以前你要有那個Quad Code的機器非常非常少那時候PC好像還沒有在推那個就是那時候可能頂多只有Dual Code而已它那個Quad Code的那個Wall Station那個速度一般跑程式非常非常快因為它的OS是用Linux Base去改的所以我們也可以用一些Linux的Kernel去做Compile還有Run程式的一些它跑起來非常快可是你一旦跑Version Machine那個速度真的是

有夠慢的你要做一個文字的編輯它都會有一些Delay這個Virtual Machine現在就非常重要因為同學知道說現在很紅的雲端Cloud Computing它就是其中有一個很重要的技術就是這種Virtual Machine的技術Cloud Computing它就是把以前很多舊的技術把它整合在一起做一些新的應用什麼是Virtual Machine呢Virtual Machine簡單講就是你讓這個使用者

他就覺得說他是在用微軟的作業系統那實際上那台電腦他根本不是跑那個微軟的作業系統他可能是UNIXLinux或者是什麼anyway那他只要上面有一個Virtual Machine的一個monitor那他可以support假設他要support這個Win7 Win8的這種OS他可以support其他的OS那你user進到那一邊它可以提供那

種虛擬的環境讓使用者覺得說這台電腦是微軟的作業系統然後它就照著這樣子的方式它以前習慣的方式去用完全都一模一樣這個有什麼好處呢我們來看一下說這種Virtual Machine它就是這邊講說以E-maillet guestoperating system還有machine的resource我們現在看operating system它可以讓很多人進去都覺得好像

他是在用不同的作業系統其實這樣子對這種multiple guest的isolation區隔每一個人好像都在用他自己的OS他不是都是用同一種OS用同一種OS有什麼不好呢其實它有一個很大的問題就是securitySecurity的問題就是你沒看現在那個我們每一台電腦它都一直叫你要更新那個什麼病毒碼然後你如果過期的沒有再跟它買它就每一次開機它就一直提醒你說你快中毒了然後你要趕快買這樣子

就是我們已經花了很多EVA在單一的OS上面做的各種Security的方式但是它還是一直都被Hack就是沒有辦法做百分之百的安全那為什麼這個Virtual Machine它會比較安全這個我不是很清楚這個我不是專家但是他們說Virtual Machine這樣子的一個機制這種Multiple Guest它可以提供這樣子的Isolation這樣子是非常好的然後也可以增加它的Reliability我們剛剛提到的Security然後還可以Share Resource因為以前

如果這一台Walk Station它如果是讓Linux那你如果不會用Linux你大概不會去用那台機器 對不對這是很正常的就好像說我們以前實驗室就以前還在念書的時候這個可能跟同學提過以前還在念書實驗室那時候用最多的就是Sun Walk Station幾乎每個實驗室都是買這個Sun Walk Station它已經不見了 已經變成Oracle

Sunward Station它其實設計得很好但是就是說它的市佔率當時非常的高但是它有一個問題就是它開window它沒有辦法開太多的window比如說你開個20個window有人會說我幹嘛開這麼多個window但是有人就是喜歡開那麼多window你開了20個window它的system的performance它可能就會degrade當然是gracefully decorate它不是

就馬上就死給你看它是慢慢的就它的performance就會降下來，那時候有，就是有一個叫，好像是叫DEC還是什麼，我不太記得他們有推出一個新的workstation，它速度非常快，它可以啪一下開了超過100個window然後速度就非常快可是都沒有人去用，都沒有人用，因為他們就很奇怪，他們就自己把當時的這個UNIX然後改

了一個版本，改成自己他們公司內部不知道叫一個什麼version，那你改一個版本沒有關係，你大部分都是compatible都可以使用都是相容的，就好它就不一樣，所以你等於你要用那台機器，你要重新再去看menu再去學它的一些command，那大家就不想用所以它，那個computing power非常的強，但是實驗室就買了一系列不知道

幾條，我忘了就買了一系列擺在那一邊，我就記得就從來沒有人去用過，大家都是走到另外一間去，那一間新建的LAB都沒有人進去用，買完之後就擺在那一邊，最後時間到了就是什麼就是報銷就是這樣子，這個東西，你如果有Virtual Machine的話，它就不會浪費這樣子的一個resource就是進去，就是你習慣的一

個作業系統的一個環境，所以這種Virtual Machine，它的優點就是在這裡雖然它有這三個優點，實際上課本提到第四個就是這一個就是好像我剛剛提到的早期，你Virtual Machine讓下去非常的慢，你做一個editing的工作它就在那邊慢慢動這個沒有辦法忍受，但是現在因為CPU越做越快，所以它已經有辦法去承受這樣

子的一個loading所以你要去，即使一個single core的一個CPU要去上面跑這個Virtual Machine的這個monitor還是可能的所以這已經是一個feasible它不是infeasible的一個情況那這邊看到的，它列出來就是IBM VM370同學可以看到說19七十年Technology然後一個叫VMware這個都還找得到還有這個Microsoft Virtual PC這個也找得到這就是早期在Apple上面大家都是用這個Microsoft的這個Virtual PC這個最早期IBM他們發展這個Mainframe Computer的時候

Mainframe Computer它的computing power很強他們的OS當然也是會跟別人，就是他們有他們自己unique的一個OS你如果說要強力去推廣說，你大家都來買我的這個mainframe computer都來學我的OS那大概又有一大堆人都拒絕改變，那個使用習慣最難改變的就是engineer的使用習慣同學你們以後就會知道當你習慣一個工作環境，你就是習慣這樣子做公司會說我們幫你們花了幾百萬幾千萬添購了一個什麼新的軟體你要不要來用這個但沒有人會要用

因為你要改變你的習慣就大家都不用這個人很奇怪就是這樣人就是習慣就是一個慣性的動物那IBM370 VM370他們就是一個Virtual Machine1960年代就開始發展所以他們可以知道說這個也不是新的Technology只是說當時你這個Loading你這個Loading你不可能在Personal Computer上面去Run這樣子的一個東西所以只有可能在這種mainframe的computer上面看到這樣子

的一個機制所以其實IBM他們做的這個實際上是還不錯的那就是目前現在的需求因為這個關係所以它重要性又浮現然後這個Cloud computing又讓這個應用又更加的就是每一個人進去反正他就是都以為他都在用微軟的電腦實際上可能大部分都不是這個Virtual Machine就是說我們會有一個Tool去Run這樣子

的一個平台然後他讓User每一個人進去都以為說這台機器是他習慣的OS然後他可以用各式各樣的Resource這個Tool就是叫Virtual Machine的一個Monitor這個Vertical Machine Monitor它就是要去控制什麼？控制這個Resource，因為每一個作業系統，它在使用Resource的這種管理可能不一樣；每一個User，他要使用這個Resource的時候，可能這個Resource是被別人使用。你要如何去讓這個Resource來

就是大家來share這個resource。基本上大概有幾種情況，一種就是最簡單，就是time share，就是分時間，就是每一個人都分一點時間去share這個resource；那另外一種呢，這個resource如果可以partition的話，它就partition它。如果你可以partition成幾份的話，那一份是負責什麼，那一份是負責什麼，那一份是負責什麼。另外一種是說，有些OS它可能

是說譬如說，它真正這台機器裡面沒有這個resource可是，它有一些OS style這一類的resource那你要如何去模擬讓這個使用者他覺得他可以使用，因為你既然是一個模擬的環境，你要讓他覺得他以前可以用的現在都可以用，所以你要去emulate你要去模擬說這台機器上面有這樣子的一個resource讓OS在跑的時候，

它可以去Access。所以這種Immulation它也是其中的一種，所以它就是必須要去這個Virtual Machine Monitor它就是要去Map Virtual Resource，Virtual Resource就是它要去模擬的每一個OS上面的Virtual Resource，變成它這台機器上面真正有的Resource，一定有的當然就是Memory其他的比如說Memory、IoDevice什麼之類的就要看說他們要怎麼去用。我剛剛提到的一個Time Sharing Partition、Immulation都可以來做這樣子的一個Resource的一個Mapping。我们知道說每一個Virtual Machine，比如說我進去Run然後我是Run這个微軟的，我是Run這个Office，Office你Run的時候

基本上它就是一個user的一個program，所以它應該是屬於這個user mode，它是屬於user mode那你user mode我們前面提到，你user mode本來就是只能夠access到一般的resource，user mode可以access到的一個resource，那你如果說你要去access一些特殊的一些resource的話，它可能這種是有保護的resource，它可能就是要透過這種free list的instruction然後透過這個VMM然

後去進到這種supervisor mode去access它的這個要的這個resource所以這個就是最主要的這個名詞就是這樣子的一個軟體就是叫virtual machine monitor那這邊提到的其實它就是把我們一般的這個time sharing的這個方式對比我們的這個VMMVirtual Machine因為我們知道說我們在一般一個電腦就是Multi-TaskingMulti-Tasking我們不是有這個Time Share那Time Share的話呢我

們就是有這個Timer的Interrupt那Interrupt可以讓一個CPU然後把它分成時間點分成很多Slice去Serve不同的這個User或者是Serve不同的這個Task然後讓每一個人都覺得說這CPU是在幫我做事所以它就是說用這種Time Share的方式透過這個Interrupt它可以把這個CPU分給所有的Task我們的Virtual Machine Monitor因為它有可能有很多個OS它有很多OS可能是你各式各樣不同的OS在跑的時候它也是類似用這種好像是就是說它就是先Suspend

目前的Virtual Machine然後接著呢就是當然就是透過這個Interrupt然後接著再選下一個它要啟動的這種。 Virtual Machine看是下一個是哪一種Machine然後換這一個那做一做之後呢它如果再換下一個這類似反正都是感覺都是用這種Time Share的這個方式只是說這個是在原本的機器裡面CPU去Share那你這邊是有很多OS要在那邊一直跑 輪流跑所以它就是用這種方式 Suspend 目前的然後再找下一個 VM

進來然後再 Restart 然後再跑如果還要再換下一個就再 Suspend然後再選擇下一個 然後再開始那在 VM 裡面呢本身一個 VM 裡面它也是會有 Time Share一個 VM 裡面它也是有 Time Share因為你你在模擬這個比如說你模擬這個Linux你也一樣可以Submit非常多的Task出去這個在VN裡面你要Time Share你也是必須要這種Timer的Interrupt這個時候它可能就是要一個Virtual的一個Timer這個Virtual Timer通常它就是透過這種Physical Timer Interrupt然後來完成這種Virtual Timer Virtual Timer你還是要有一個真正的Timer

真正的timer就是physical的timer interrupt的一個機制去implement一個virtual timer所以它這樣子就可以在一個VM裡面也有這種timer interrupt的一個機制所以這個就是所謂的timer virtualization這邊提到的一個instruction set的一個support這個是指什麼呢這個大概就是指說我們這個CPU設計的時候我們在設計Instruction Set我們在設計Instruction Set的時候它到底有沒有考慮到之後這個Virtual Machine有可能會在這個CPU上面跑跑這樣子的一個Virtual Machine它不是

譬如說我現在在Intel在Design它的CPU它的Instruction Set當然就是Intel的Instruction Set可是他如果沒有考慮到之後他這個CPU上面可能會跑VM比如說他可能會跑這個PowerPC他會跑其他的這種這個這種不同的這種Machine的這個Platform那你到時候你的Virtual Machine在上面跑的時候他可能就會很浪費時間那你如果當初設計Insertion Set的時候你就考慮到你可能要Support不同的

那你的instruction set到時候真正跑VM的時候它的這種mapping translation大概就不會說它很當然還是會比較慢，但是它就會比較快，它就會比較efficient，那傳統的AMD跟Intel他們完全沒有考慮到VM VM的support，所以他們的instruction set完完全全就是他們當初自己設定他們要設計什麼樣的CPU，要提供什麼樣的這個future，他們就是

這樣子設計那IBM VM370 他們在1967年代的時候就已經考慮到這件事情所以IBM的VM370，他們是真正的真正的，就是所謂的這個，就是virtualizableVisible Level的意思就是說，他們在設計Instruction Set的時候已經有考慮到以後會有VM在他們這個CPU上面跑，所以他必須要他的Support的Instruction Set必須要能夠考慮到，說我這樣子設計，以後做這樣子的對應，會不會比較EfficientIVM的VM370已經有AMD跟Intel他們在2006年的時候好像

有propose說，他們也要做這樣子的一個設計，後來怎麼樣就不是很清楚不知道，有沒有現在的版本不知道已經有沒有考慮這個VM，這我就不是很清楚，所以這邊提到的就是我們剛剛提到，就是說，你要有instruction set，這個instruction set當然最基本的，就包含我們的user mode system mode因為你透過這個VMM然後你要進入這個

privilege的就是supervisor mode大概就是一定要有一些特殊的一些privilege的這個instruction然後才有辦法讓你做這一種transfer不然的話大概也是沒有辦法所以Virtual Machine我們大概是簡單先介紹到這個地方接著我們來看這個Cache的這個controlCache control其實這邊好像也沒有講到什麼我們大概就是只是

把觀念介紹一下它有一些Material都放在這個Appendix裡面同學有興趣可以去Appendix就是那個光碟片看一下光碟片的這個內容我們這邊是課本裡面的這個部分我們在這裡面我們用一個例子一個簡單的例子它是一個Direct MapWrite BackWrite Allocate然後它的block size是4個word4個word就是16個byte

所以16個byte它是4個bit這邊offset它是4個bit它的edges最右邊4個bitreserved給block的offset既然它是16個byte然後它說它的cache size是16KB所以16KB除以16它總共有1024個block就是1K個block那它一個一個block的話呢，它的index就是需要10個bit，這是10個bit這2的十字方就是10個bit所以它

Tag總共有18個bit，所以這個就是我們現在當例子的Cache一個簡單的機制，它是32個bit byte address有very bit還有30 bit每一個Block都有very bit跟30 bit那它是Blocking Cache，Blocking Cache指的就是指說它這邊寫說這個CPU它會等到這個Access都完成了、Complete之後CPU它才會再開始進行；不然它就等在那一邊就一直等等到它整個都Complete它再進行。 我們這個Cache Controller我們是用Final State Machine來完成的，所以

所以我們等一下也只是觀念性的介紹一下它Final State Machine，它的State大概長什麼樣子就Cache CPU Cache Memory它的一個Interface的Signal來看的話大概就是這樣子的一張圖。我們的這個CPU Cache，它的Address 32 bit、Write Data Read Data這邊是32 bit；然後這邊有一個Valid還有一個Ready，Ready就是表示說Cache它那邊都已經完成了、Ready，那你可以Cache CPU嗎？就可

以issue一個Access的一個Demand那Cache跟Memory之間呢我們假設它也就是簡單的有這RewriteValidReady然後Address是32個bit但是WriteData跟ReadData它是128那128最主要就是我們這邊講的它的這個block size是4個wordblock size是四個word所以它是一二八個bit所以write跟read都是四個word就是一個block所以這個是他們這兩者之間的溝通這兩者之間communication的一個機制所以這個final step machine我們suppose大家都已經了解大家都知道說這一張圖長這個樣子是什麼意思這個就是combinationalControl, Logic,

Combination of CircuitsCombination of Circuits它會Read我們的Current StateCurrent State就是你這個Final State Machine它有幾個State那它幾個State就是都存在這個State Register裡面那Current Register再搭配我們的Input我們的Input我們可以決定它的Next State會變成什麼樣子那當然它還會這個Combination of Circuits它還會決定它的这个output

所以我们这边所谓Cache的Controller最主要就是在这边的一个design就是combinational circuit的一个design当然我们也要知道说它有几个state它的几个state根据我们前面的一个描述的话其实它大概就是只有这四个state一个是idle就是IDLE它要等這個CPU的一個Request所以它要等CPU Request它就會進到IDLE這邊來那你進到IDLE呢CPU的Request就會過來就會過來說你要讀你要寫那這個是

最主要的一個State它是叫Compare Tag我們的CPU的Request一過來之後呢它就可以開始去比對就是說看看說這一筆這個 address 它要的資料到底是不是在 cache 裡面它就會開始去說到底是不是在 cache 裡面如果是 hit 的話呢hit 的話它就會回到這邊然後這邊它會 mark cache 的 ready因為它已經讀到了如果說是 miss 的話呢如果是 miss 它就分

這邊有兩個因為我們知道說miss它包含了什麼呢包含了一個read miss還有一個 write missmiss實際上它也包含了什麼呢就是說我miss的話你是把一個block讀進來就結束了還是你要把一個block讀進來然後再把一個已經存在cache裡面的一個block把它踢出去如果你要把它踢出去的話那你就必須要

做write的一個動作所以這邊分成兩個state這個state就是write backwrite back這邊就是指說我的miss我這邊要讀一筆資料讀進來然後讀進來它滿了它要放的地方滿了所以它必須要把一個block把它踢出去所以它就會進到這邊進到這一邊它就會做什麼write把舊的資料寫到memory裡面去這個state它有一個circle這個circle就表示說我在做write的時候

它一直write還沒有寫完所以你這邊就一直在這個state一直跑一直跑跑到什麼時候跑到我們的memory的write都結束了結束之後它就會進到這一邊所以這邊只是先把被replace掉的那一個block先把它寫到memory寫到memory寫完之後它就會進到locate這個state這個locate這個state它就是要把我們的memory裡面的資料讀回cache裡面因為我們前面講什麼呢這邊是write locate

另外一種是什麼呢？ NoAllocate它沒有Allocate，所以你就直接寫到Memory它不需要讀到Cache，但是我們這個是WriteAllocate一定要寫到Memory再把Memory讀到Cache所以這邊它就是會進到Allocate的這個State所以我們這個就是一直把Memory讀進Cache你還沒有讀完的時候它就是一直在這邊state在這邊跑在這邊等等到它memory讀到cache裡面讀完以後它就memory ready已經讀完了它就進到這邊來它就回到這邊回到這邊然後它再回到這邊所以它基本上一個基本的運作就是分成四個state然後

如果是hit的話呢就是這樣子如果miss的話miss的話就是兩條路一條呢就是你不需要做write你不需要做write back動作就是直接到這邊讀資料把memory讀回cache就回去那你另外一條呢你要write你就把它被replace的要write你就到這邊來然後write完之後再read進cache然後再回去所以大概就是這四個state它真正要做的事情就是在這個state裡面要做它的在這邊combinational circuit就是要design這部分這部分design如果說一個state要做的事情越多那你這邊combinational circuit那一個state所相對應的

它的logicdesign可能就會比較複雜比較複雜它的delay可能就會比較多所以它這邊就是說如果你怕因為你的某一個state要做的事情太多你所設計出來的logic太複雜使得你的delay比較大你的cycle time就會比較長你如果要避免這種情況你可以把這個要做比較多事情的State把它Partition你可以試著把它Partition成兩個State那你每一個State要做的事情就會比較少所以它相對應的Logic就會比較簡單就是這樣我們今天先跟同學介紹到這裡.