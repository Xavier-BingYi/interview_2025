undefined
我们上次跟同学介绍到这个DirectMap的Cache，我们上次跟同学提到说这个DirectMap Cache，它在这个就是说每一个记忆体的location它存放在Cache的位置只有一个，所以它只能够存一个位置，因为Cache的size相对于这个Memory的size是小很多，那你一个location又只能够存一个位置，所以可以可想而见我们对这个MemoryMap到Cache的这种Mapping，它

是一个多对一的Mapping，所以比如说像这个001这个例子，这个Cache的Location，我们可以看到在这里面就有四个箭头，就四个Memory的Location对应到同一个位置，所以这边对应到这里到这里，所以也就是说，我如果要把这一个记忆体位置的值，把它搬到 cache 的话，它一定是放在这个位置这个，也是一样，它也是搬到这里，它也是搬到这里，所以，如果说它已经搬到这一边，这一个，它又想再搬到 cache 的话，我们就必须要把这一个location address 的这个值，

把它踢出这个Cache然后才能够把这个搬进来，所以我们后面就会有一些机制，它就是在探讨说，我们要如何让这个Cache可以很有效很有效率的工作很有效率的工作当然，就是它不希望每一个搬一个纸进来没多久马上会被踢出去。然后新搬进来的可能下一次还没有被Access到它要被另外一个人踢出去。

如果一直发生这种情况的话，我们可以知道这种cache hit的几率就会非常的低，cache miss它的几率就会非常的高。所以，这个并不是我们所乐见的。我们还要再注意一个地方的就是说我们要如何知道我们，如果知道说这个memory address，它到底是放到这个 cache 的哪一个位置，还有我们这边知道说这个 cache 的address，因

为它不是只有对应到一个 memory 的 location所以，我们到这边来读这笔资料的时候，我们还要知道说这笔资料到底是这一个位置的还是这一个位置的还是这一个还是这一个。所以，我们要知道这几种情况我们要能够区分，所以，我们在这边看到的就是说，我们对一个memory的一个address，就是对我们这边是32bit，我们把它区分成三个部分，右边这个部分就是offset，这个offset指的是指什么呢，它指的就是指说我们前面已经知道说我们这个cache

就是 memory 跟 cache 之间的 access我们并不是说我每一次搬的时候就是搬一个 word一个 word 一个 word 这样搬一个block，这个 block 的 size当然你可以去设计，可以设计成一个 word两个 word 四个 word 十六个 word或者是 256 个 word你可以定义你一个 block 到底是多大定义完之后我们每一次如果要搬资料从Memory搬到Cache我们就

是一次一个block为单位当然你如果说有一个Cache miss你必须要换一笔资料的话它大概也就是用这样子的一个方式来进行所以这个offset指的就是指说我们的data是在block里面的哪一笔资料比如说它一个block是32个word是32个word里面的哪一个word所以这边是指这个offset那左半部呢这个我们就可以把它看成是所谓的block addressblock address它包含了index跟tag这个index指的是指什么呢index指的就是指cache里面它的这个address

比如说我们这边看到它总共有八个这个 cache 里面总共有八个 word所以它的 address 是 010 0011 010 到 111所以这边的 index 就是指这一个最左边的这一部分叫 tagtag 就是我们刚提到的你一个位置 cache 的一个位置它可以对应到 memory 的很多个 location我怎么知道说这个001是这个001还是这个001还是这

个001还是这个001所以我们这边看到的这个location，它的address是0001这个是叫0、001这个是叫1、001它都有一个共同的特征是什么呢？它的右边的最右边的三个bit都是叫001所以这个001就是我们这里面所谓的index；index就是指这一个block address的这个001，所以我们在这边这个图里面看到的这个例子，我们已经把这个offset把它省略掉了；我们只列出我们这边看到的它的address；我们只列出它的block address；我们这边的offset我们省略这边没有列出来所以，001

它可以存到这里，这也叫001，它可以存到这里所以，到底是哪一个001呢？它就是会把这个001扣掉block address扣掉index以后剩下的这个00这个就是它的tag；这个001扣掉剩下01这个就是01的tag，所以我们如果是以这个例子来看它的block address，它有5个bit；它的index有3个bit；它的tag就有2个bit；所以我们的index是拿

来定指它是cache里面的哪一个位置找到了cache里面的哪一个位置之后，我们再去判断说判断什么呢？判断这一个现在存在cache里面的tag到底是哪一个它如果这时候tag，它如果是叫01的话，那我们就知道说这个001它是什么呢它是01001所以这个tech加index就可以组出来这个block就可以反映出我们在这个memory里面到底是哪一个001所以我们就是用这样子的一个方式这样子的一个方式来判断判断说这个资料是存在cache的什么地方

Cache里面现在存的Cache里面的这个位置存的到底是不是我这笔资料用这样子的方式所以我们这边可以知道说我们如果有一个block address的话我们要知道它对应到对应到这个Cache里面的哪一个位置我们就是用modular就是modularCache里面的block numberModularCache的这个blockNumber我们得到的就是这

些数字所以我们把这一个数字去做Modular得到的就是这个index下面这一个我们只是把这个offset更仔细的把它列出来因为我们知道说我们在这个版本MIPS这个32bit它有这一种align address它有align的一个作用就是说它是一个四个byte组成一个word所以我们这边offset其实包含了什么呢包含了两个部分第一个部分一定是B4一定是有两个bit0跟1这两个bit是什么呢是指这个byte就是一个word里面有四个 byte 所以，这边有两个bit

扣除掉这两个 bit 以外，另外这个部分是叫 word offset,word offset 指的就是指什么呢，就是我们刚刚跟同学提到的这个 cache 里面，它一个 block 里面有几个 word，如果 cache 里面它一个 block 里面有四个 word，那它的 word offset 就必须要两个 bit 来区分两个bit来区分，是这四个word里面的哪一个word，所以它的这个offset它就会是两个bit加两个bit所以我们再举另外一个例子假设它一个block有八个word一个block里面有八个word请问它的word offset是要几个bit几个bit

同学要不要回答一下一个block有八个word那我这个就是要来区分说它到底是这个八个word里面的哪一个word所以它需要几个bit同学答对了就三个bit我们还在加这个是byte，就是default是两个，所以它的offset这边的offset就是几个bit就是五个bit就是这样子所以它的这个观念这个整个原本的32个bit，它的

这个address的定词，我们在这里面就是用这样子来看区分成三个部分那你在detail来看的话，offset又分成word offset跟byte offset这个index就是dependent你cache里面到底有就是说你有几个block所以我们这边就是你这边有八个所以我们这边就有三个因为你要三个来区分到底八个block里面的哪一个如果是以这个例子来看的话这个tag就很大了这个tag有多大32减多少减3再减5所以我们tag的算法基本上就是用这样子来的

我们会知道说它有多少个block我们也会知道说一个block里面有几个word所以我们可以透过这些资讯来推出offset来推出index最后tag剩下几个bittag就是32减掉index再减掉offset就是等于你tag需要几个bit就是这样子所以这个是我们对这个cache第一眼的认识至于它比较detail的运作方式它的

一个图我们等一下后面会看到这里面已经包含了刚刚跟同学介绍的就是说我们一个cache里面存了资料进去我们可以透过blockedges里面的index找到了找到了这笔资料在block里面在cache里面的位置找到了之后我们还要知道什么目前存在 cache 里面的到底是不是他还是其他的好像是孪生的兄弟一样只有 tag 不一样index 一样所以就是由 tag 来判断另外还有一个我们要知道说我们透过 block edges去 index cache 的 location这个 location 里面

到底有没有资料它是空的还是已经从memory里面抓资料到cache里面它就是用所谓的very bit来判断very bit就是说如果它设为1的话就是表示这个地方已经有抓资料进来了如果very bit是0的话就表示说我这个位置还是空的这个位置还没有从memory里面抓资料存到Cache里面的这个位置所以

我们就是透过这个Value bit这个1或者是0来判断有没有资料在里面如果Value bit是1的话接着我们再判断这个tag这个tag是不是跟我目前的这笔memory location的tag是不是一样如果一样的话这笔资料就是我要所以它就会Hit如果说Value bit是0或者是tag不match这种就是所谓的cache

miss它就没有真正去读到在cache里面读到资料它要的资料还是存在memory里面所以它判断最主要就是透过very bit还有tag所以我们后面有一个例子来看一下这个例子我们它裡面有八個block在 cache 裡面它有八個block每一個block我們假設是一個 word它是用 direct map 的機制來做 memory-to-cache 的 mapping它的 initial state當然就是我們一開始都把 valid bit 全部都設成 0表示說 cache 裡面的資料都沒有所以我們可以看到 cache 的一個

一个structure就好像类似像这个样子这边是它的位置我们来找来定值用的然后有没有存资料现在有存的话它的tag到底是哪一个还有它资料的本身就存在这个地方所以一开始全部都是0我们接着来看我们假设第一笔资料它的word address是22它的binary相对应的是10110那10110呢我们这边已经

把它分成两个部分左半两个bit是tag右半三个bit是什么呢是index所以我们就知道说这个location我们就是要去找110这个位置那110呢我们已经把它highlight出来那刚开始呢110这边它的very bit是none是zero所以我们知道说是一个miss那miss的话呢我们就是把这笔资料把它读进来把它读进来读

进来把资料存在这个位置然后这个tag存什么呢就是存10它就存10所以我们这边第一个是miss接着第二笔是26它的bind address是11010010刚刚是没有东西的所以一样我们就是把这笔资料把它搬进来然后把它的tag11写在这个地方把very bit设成yes所以目前这两个是设成yes接着它要access

22跟66那22呢110110是在这个地方那它看这边very bit是yes所以接着比对呢tagtag是10这边也是10所以我们知道说这个cache里面存的资料就是它要读的这笔资料所以它是hit下一笔它是26所以是11010它要找这个010010在这里very bit是yes然后text是1111然后这边也是11所以match所以这边就是hit所以这就是两个hit的一个例子接着这边又存了一个16它要access这个16所以它是10000所以000

这边同学可以看到这个010原本是没有东西的所以它就是missmiss之后就把这个资料存进来然后把这个tag10存到这个地方然后把verybit改成yes然后3是01011那011在这个地方我们来看一下011原本这边是no没有资料的所以我们就是miss就把资料存进来然后最后再一个1616

就是刚刚这一个所以这边就会hit所以它就是先找000然后very bit yes比较tag10 match所以这边就是hit所以它的这个access基本上就是像这样子这个就是一个miss所以我们这边最后一个例子同学回去可以自己看一下这是一个简单的一个miss跟hit的一个example接着我们后面这边就是把我们

刚前面其实已经跟同学介绍过了我们如何把一个memory的addresspartition成三个field一个就是最左边是一个tag中间是index右边就是一个offset这边有两个例子这个是一个general case它告诉我们说我们要如何去derive它的index还有tag要需要多少个bit然后顺便可以算出它的cache它的cache size到底是多少我们可以来看说它是32个bit32bit的byte address它是用derive map的一个cache

cache它有2的n次方格block所以这边告诉我们什么呢它有2的n次方格block所以它的index是几个bit对不对这个就是index的bit的number就是n个bit接着我们来看它说block的datasize是2的m次方格word每一个block有2的m次方格word所以它的word offset是几个bitm它的word offset是m可是它还有byte它的byte offsetdefault是2是两个所以它byte offset是2所以它total的这个offset是

就是你如果是用m用word来看它就是一种m，然后你总共来看的话是m加2个bit，m加2个bit2是for byte offset，m是for word offset，所以从这边我们就可以知道说它的tag需要几个bits。 tag就是把index减掉offset，32就是32减掉什么呢，它的index是n，然后它的offset是m加2，所以32减n减m减2，这就是它的text size。总共它的cache cache的size是多大呢？ case size怎么算呢我们来看这边case size，

case的结构大概就长这个样子，一个就是一个block，所以这边是一个block，这边是两个block，这边三个block，你如果有10、24个block，它的index就是从0123到10、23所以这样子是一个block。 case的size当然就是什么呢？它的block number再乘以block size对不对，就block number再乘以block size，所以重点是它一个block的size是多大呢？ block size是什么呢？每

一个block都会有一个vary bit，vary bitvary bit是1 bit，然后tech呢，tech size是多少，就是我们这边算出来的tech size，那data size呢data size当然就是看看说你一个block到底有几个word你一个block有几个word所以我们这样子就可以很容易的算出来说这边就是我们的block size这边就是我们的block size这个就是我们的data size每一个block存2的m次方个word所以它的2的m次方乘以32， 32 bit一个word， 32 bit所以这个是data size

然后加tag-tag就是32-n-m-2这个就是这边的tag然后再加11是什么就是very bit，所以这个是一个block的size那总共有多少个block它告诉我们有2的n次方的block所以是2的n次方乘以block size就会等于这一个所以同学到这边有没有什么问题这个是我们在讨论Cache里面的第一个很重要的这个point我们要了解这个Cache size基本上它是怎么算的当然我们要了解Cache size怎么算我们要了解Cache的structure还有它的tech是怎么直接出来的

我们再看第二个例子其实这边同学了解的这后面大概就简单了我们说它这个是16KB数据，然后4个word的block所以它的data总共有这么多个它的data size总共这么多data这是它的data然后它每一个block是四个word它也是32bit的这个address一个block是四个word我们从这里面从它的data的size还有从一个block有四个word我们就可以推出来它总共有几个block所以我们来看它这边

total是16kb这个是byte这个是byte那byte我们要把它转成word所以就除以4 对不对所以它4kword所以它这一边total是4kword然后它一个block是4个word所以它总共它总共有多少总共有多少个block就是4k除以4对不对4k除以4所以它total就是1k个block所以在这里面在这个例子在这个例子里面它这边总共是1k个block1024个block所以我们这边就知道说我们要怎么去算它的tagtag就是32

减什么呢减掉indexindex我们就要知道说它有几个block它有1024个block所以它的index是几个bit是10个bit它的index是10个bit接着我们还要再减掉offsetoffset有两个部分一个是word offsetword offset它需要几个bit它有四个word所以是两个bit然后第二个部分是byte offsetdefault是两个就是四个byte两个bit，所以这

个部分剪出来就是这个case里面的Tag bit，它的Tag总共有这么多个bit，然后Tag再加上very bittag再加上very bittag再加上very bit就是这个部分，然后再加上它的data size-data size是4个word乘以32，所以这个total就是一个block Cache里面一个block，它的size，然后它总共有1k个block所以是2的十字方乘以一个block size就会差不多等于这样子的一个数字，所以同学最主要的还是在这个它的general的这种case，我们可以理解以后

其他的大概都不是什么问题大概就是一些转换而已，所以我们可以从这张图可以看到就是我们刚刚一直在强调的这个例子，这张图里面它有10,24个block所以它的index就是从0到10,23所以这边index的fear需要10个bit-10个bit可以定指这10,24个block当它定指某一个特定的block之后，它接着会用它的这个address的Tag-tag-fear，我们可以看到这里面的例子是20个bit的Tag-fear它会抓下来跟谁呢，比如说这个例子它是定指到这个block，

它就会把这个block的Tag拉下来跟它上面的Tag去做一个比较看看它们是否match如果它们两个tag相等的话相等而且very bit是1那我们就会送出一个hit的一个message就是说我们已经在cache里面找到这笔资料所以这个hit它就是必须要满足第一个very bit是1第二个它的tag field是match。比较之后它是match两个都满足这两个条件之后它就是hit，这笔资料data就会被缓存出去所以这个就是我们在cache里面的一个机制我们再看下一个例子这个例子

它告诉我们说它有64个block它有64个block，然后它每个block是16个byte，每个block是16个byte我们问说我们的这个edges，我们这个edges都是by-edges我们的edges1,200它到底对应到我们cache里面的哪一个block它问我们1,200这个位置是对应到cache里面的哪一个block其实就是要问你是block0到63到底是对应到哪一个block它是要问这件事情所以我们就要这个很简单，它只有两个计算，第一个我们要先把这个by的address我们要把它转成block address

block address怎么得来呢其实我们就是把原本的这个mem ory address的offset那部分把它去掉所以我们用这种flow function就1200除以16这个flow得出来的这个整数75就是取得就是把这个offset那部分去掉剩下tag加index接着这个75这个block address我们再去module它总共64个blockmodule64它会等于11这个11其实就是我们1200对应到cache里面的block number就是11同学会说为什么会是这两个运算算数运算算出来就会得到这个11呢我们来看一下这个图解分析

这个图写分析我们看到的120. 0比如说，它大概就是像这样子的一个address，我们一样，我们把这个address把它区分成三个field最右边是offset，然后接着这个是index，然后最左边是tag，所以我们知道说这边是16个byte，所以我们这边会有4个bit，2 bit for byte，2 bit for word，所以总共是4个bit接着，它是64个block，所以我们这边有6个bit来定值这64个block，所以同学可以看到12.

00它的值就长这个样子，我们把这个12. 00把它做一个flow的一个function就是除以16取整数这个整数当然是最大的，然后小于这个数的一个integer number我们这样子做完以后，它得到的数是什么呢，就是把这个去掉，就是取出这一个数，这个数就是这个number就是这个数，我们现在是要得到什么呢，index是要得到这个index，

它的block number其实就是这个index，所以你这个index你要怎么得来呢当然就是把这个数去做什么呢，这时候不是在做flow，你做flow你会得到这一个我们要做什么modular所以是modular 64，我们就会得到这一个最后边这六个bit，所以第一个flow会得到走半步，然后再做一个modular得到右半部，这11就是我们的block number，所以这个例子有这个图节相对的看起来应该就非常的清楚知道了这个它的这个adj mapping，它的计算还有case size的计算之后，我们来讨论一下我们的block size对

Cache的这个运作到底有什么样的影响我们第一个直觉我们当然会觉得说，我们这个block是我们读了一笔资料之后呢，我们就我们要一笔资料那它miss呢，我们就会把跟这个就是这一个资料所在的那个block全部把它搬到Cache里面来，那我们把它搬到Cache里面来呢，我们当然是希望说我们的block数目是

越大越好对不对，因为你如果说我一个block就是两个word这样子你会发生cache miss的几率应该是非常的高因为你读一个你只是在多抓另外一个word进来所以 suppose你会cache hit你就是一定要access这两个word你如果一次抓16个当然你cache hit的几率就会更高你一次抓256个word进来你会cache hit的几

率又更高所以我们希望说block size是越大越好所以大的block size它会怎么样呢会增加我们的cache hit的hit rate可是它不是一直增加一直增加都会得到这样子的一个增效应它这边就告诉我们说就是说第一个就是我们刚刚提到的你越大的block它会reduce miss rate会increase hit rate为什么呢因为spatial localityspatial locality它告诉我们的就是说我抓了这一个位置跟它相关的就是它周围在它周遭的这些data它可能在最近也会被access

所以我就一次一大笔的把它周围的资料全部都抓进来如果它往后的这个access真的都是满足这个都是属于这种special locality这种现象的话那我一次抓一大笔它的效应就很大它就一直hit hit hit所以非常的大可是我们的case大小因为不是无限大我们的case size是固定的，所以当我们的case size，这本

来你每一个design的case size一定是fixed size，不可能是无限大所以我们的case size当它是一个fixed size的时候，我的block size越大会发生什么样的一个情况呢？ Block size越大就表示我的block number怎么样越小Block number越小block number越小会怎么样为什么我知道同学他的意思，同学他答对了，因为我们的case的size是固定的，当你block一个

block size变大的时候，我们的block number就会变少了Block number变少，它的情况是怎么样呢？它的情况的意思其实就是你多对一的多的数目变大比如说假设原本多对一是15对1好了，就说15个位置会对应到同一个block，那你现在你的block number变少了吗？这15就不是固定了你的block number，如果变小的话，你这个15会变大还是变小Block number你的block number变小的时候，你这个15对1的这个15会增加

对不对会增加对不对，因为你这15对1还是20对1还是30对1，这是怎么算的，就是你的mem ory size除以你的cache size对不对，那我们现在我们的cache size我们的cache number不是cache size，cache number我们的cache的block number数目变少了以后，因为那个数目数目变少所以你可能就会从15对1变成30对1也就是说有30个memory location在

竞争同一个block就等于是有30个location、memory location30个在竞争同一个同一个cache的一个位置那你更多人在竞争同一个位置就表示什么呢，表示说当我一个block搬进去以后原本是15个人在跟我竞争现在30个人跟我竞争所以我被踢出去的几率是比较高还是比较低当然是比较高越多人跟你抢你坐这

个位置坐久的几率当然就降低很容易就被人家又踢出去了，所以同学可以想想看两个人竞争一个位置跟100人竞争一个位置你可以坐在这个位置上面做久的机会谁比较高当然是两个人竞争一个位置你可以做比较久，你一百个人竞争一个位置你可以坐在那个位置上面的机率相对的就非常的

低所以就很容易被踢出去进来就被踢出去进来就被踢出去，所以这个就是刚刚同学的意思为什么你的block size变大，那我们的block number数目就会变少、block number 数目变少就会有比较多的竞争，比较多的竞争你就很容易被别人踢出去。另外还有一个原因，这是一个这是第二个说比较大的block大好，但是不能太大，当你太大的时候，我们知道这个special locality也不是无限制，

它一直都会有这种spatial locality的现象发生，所以当你太大的时候呢，当它spatial locality没有这么的严重的时候，你抓了很多资料进来其实都没有被用到，这就是所谓的pollution，就是在我们block size很大的时候，我们会抓很多资料进来，就随着一个case miss把一个block抓进去，很多跟它不是这一次要access的资料很多就一次都

被带进来，但你被带了这么多资料进来，它的special locality可能就是一个局限的范围，所以在那个范围之外一起被带进去的那一些都是什么都是没有用的，它们都是占据在cache里面，但是因为没有special locality所以不会被access到，这一种现象就是叫pollution，你的block size太大，所以带了一些没有带了一些不会被access到的资料进来，占在那个cache浪费空间，这个叫pollution所以为什么

对一个fixed size的cache你的block size太大反而会降低你的hit rate提高你的miss rate原因就是这边是第一个这个是第二个这个是我们在 cache 裡面一個很重要的觀念而且同學可以知道就是說當你的 block size 很大的時候你一次 miss 的時候它的 penalty其實也是很大因為你一次 miss怎麼樣呢你一次 miss 以後我們要抓很大筆的資料從 memory 抓到 cache這個就是它的

算是它的一个loading它必须要做这些工作它每次一miss它就要去抓一个大的资料从memory到cache相对的我一次要抓256个word跟我一次要抓16个word当然我一次miss我抓16个word它的penalty相对的是比较低你若一次要抓256个word它的penalty当然会比较高所以当你penalty高你的miss rate又高所以当初你抓进来要满足这个要有利于special locality的这些优点

优势就会被吃光会被消耗掉所以这个就是我们要考虑它的一个原因在这里我们这边有一张图我们可以看这张图就是说这边它是block size这边它是它这个mixed rateblock size从16到32 64这边可能是Wool 16Wool 32 64 128 256我们这边看了四个curve这个curve就是它表示它cache有4K它的cache size是4K cache size 16K 64K 256K所以每一个curve都是针对

这个curve就是针对4K size的这种cache来看当它的block size增加的时候它的miss rate的变化我们可以发现你block size增加的时候它miss rate的确是降低这是好现象可是它要反转反转以4K的这个cache size来看的话它的反转点是在64在64 这边64它开始就反转就向上就表示说以4K的这个size而

言我们的block size不希望大于64当你大于64我们前面提到的competition会变得更激烈pollution会变得更严重这个就出现了这个出现会吃掉它的大block size的优势反而会让它的这个会变得更严重所以你看越大的时候它就越严重16K它有一个反转但是这个反转没有4K来得那么的明显这个说明什么呢说明什么同学会说照理说我们刚讲的那个现象应该都一样都要这样子为什么4K这么明显16K没有那么明显为什么

其实没有其他什么原因这个原因就是我们刚提到的16K比4K大所以你对同一个block size来看的话16K除以128它得到的block number当然是大于4K的这个design的block number你的block number增加了所以我们刚提到的那个效应就会递减对不对它的那个效应什么效应呢？竞争变得非常的激烈，竞争变得非常的激烈。这当然就会递减，所以这个是竞争的严重程度，这是4K，这是16K，所以它增加了4倍，所以 suppose它的竞争的就是几个memory location竞争同一个cache，

这个竞争程度会减少四分之一，那你竞争的激烈程度减少了四分之一，就变成原本的四分之一当然我们刚提到的这个效应，它就会变得没有那么明显，但是它还是会有一个这样子的curve接着64、256同学可以看到这个效应，就越来越小，因为它的block number越来越多，所以它那个效应就变得几乎都快

没有，所以我们在这边看到的这张图告诉我们的就是这件事情接着，我们再来看cache miss，我们前面提到的cache hit跟cache miss，它们到底有什么不一样这个差非常多，因为我们知道说memory一个access，它花的CPU cycle数目是非常多的。如果说是Cache的一个access的话，如果是Cache hit，它很快就抓到资料，所以 Cache 这个 CPU，它就可以很正常地继续在工作，它不需要wait在那个地方如果是Cache miss就表示我们必须要到memory里面去读资料这个时候你就必须要store就必须要store

因为它要去读的资料不在 cache 它要去等它要从 memory 里面去抓回来这个需要时间所以它必须先 storestore 之后它就开始从下一个 hierarchy level 的这个memory 去抓一个 block 抓进来如果是 instruction cache missed 的话它就 restart instruction fetch刚原本要读那个instruction没有读到那你就重新再启动instruction fetch那如果是data cache miss的话呢那你现在资料读到了你就可以complete你的这个data的access所以这个是我们就是hit跟miss差别很大一个要store一个就不需要store那我们前面提到的是一个cache

大约它的一个运作机制包含它的mapping还有包含Cache的block size它所带来的一个效应还有Cache的一个structure还有Cache hit跟missCPU它的一个情况但是我们知道说Cache毕竟它并不是我们最后真正储存资料的一个location以CPU的观点来看它希望所有的资料都是在Cache里面就可以抓得到，但是我们知道说Cache它是一个temporary的一个location一个temporary，但是是一个very fast的一个媒介我们读资料

从 cache 里面读或者是我们写资料写到cache，我们如果是做一个write，我们是把这个资料就直接写到这个cache，那这个 write 呢并不表示说我们已经把这个资料把它写到memory，因为真正的 data 是在 memory不是在cache，所以我们要如何去让这个 cache 跟 memory它们之间保持这种 consistent就是保持 data 的一致性这个有不同的机制，它

的机制，我们这边第一个看到的就是所谓的write-through，write-through就是什么呢，就是一旦我们要写资料就是说我们要做一个data write，你如果是write-hit的话，我们就是第一个update我们的cache，然后第二个也要update这一笔资料在memory的位置，也就是说它要update cache跟memory它都要update，所以write-through就是除了把资料写到cache你也必须要update memory里面的这个值，所以write-through是最简单的一个机制反正你只要write它就cache memory一定是consistent它的资料一定是随时都是synchronization

做得很好可是它最浪费时间你每次write你就要去write memory所以你要write cache你要write memory这个当然不好所以他这边就提到说我们假设说我们的CPI是1我们有10%的instruction是storestore就是要write我们在write到memory需要100个cycle所以它实际上平均它的CPI是多少它的CPI其实并不是1因为1是没有store那你有store要怎么算呢它平均是10%10%的几率是store每一次是100个cycle所以它average是1加0.

1乘以100个cycle所以是几个cycle11个cycle所以同学不要看到1好高兴可是实际上它是C所以right通过当然不好right通过不好的话我们当然就要想一个方式这边有一个机制叫right buffer(right buffer其实算是一个中性的机制这个是extreme两端的一个方法就是write-through每次就write到memory这个extra的另外一端就是我们后面这边看到的write-backwrite-back是什么呢write-back就是我们都always都是写到cache都写到cache里面那memory就不要管什么时候会update memory呢就是当这个block被踢出cache的时候它被踢出来

就是它被别的block replace被别的block替换掉它被T2 cache被T出来的时候如果这个block它是dirty什么是dirty呢它会记录说这个block是不是曾经被update过如果这个block曾经被update过这个block就称作是dirty它就会把这个dirty block写到这个memory里面去如果它不是dirty block这个block即使被T2 cache它也不需要做write的一个operation所以纯粹就是由这个30bit来判断说这个block是不是

曾经被update所以这种writeback是当它被踢出cache的时候再去做update这个extreme的两个端的中间的一个方法就是叫writebufferwrite buffer是什么呢我们就是会除了你update你的cache之外我们还会怎么样呢会写到一个buffer里面，这个buffer cache本身你可以把它看成是一个buffer，反正它是很快的。再把它写到buffer里面，这个buffer它就会hold住这个

data等到什么时候才会把这个data从buffer里面清掉呢？就是等到它从buffer把资料写到memory写完以后，Buffer裡面的Data就可以清掉，所以它這個叫WriteBuffer。那同學說這個有什麼好處呢？它的好处是什麼？它的好处是，它也是CPU就是寫進去之後它就可以開始去工作，它不用等這個Buffer寫到Memory它不用等，因為最慢的是你從Cache寫到Memory或者從Buffer寫到Memory，這個是

非常非常慢。 CPU它不需要等你就write写了进去以后，CPU它就可以继续去做它的工作，buffer to memory它就自己去在那边慢慢写，只有一种情况CPU必须要等哪一种情况呢？是CPU要写到buffer的时候，buffer已经满了这个情况可能会发生，因为buffer到memory的速度毕竟还是比较慢，buffer到memory还是比较慢。如果说你的CPU在某一

个时间点之内，它一直在write所以它必须要怎么样？ CPU它等于是一直去write buffer write buffer所以你buffer写到memory还没有写完就buffer就被写入了好几笔资料那buffer就满了。 buffer满了之后CPU你还要再写写到buffer它已经写不进去了，所以这个时候CPU就要hold CPU这个时候叫hold，它要hold到什么时候呢？它要hold到等buffer to memory里面

的operation就是有一笔资料完成，完成之后它把buffer的那笔资料清掉。所以buffer它有空出一个位置，这个时候CPU就可以把它的资料写到buffer它就可以继续在工作，所以这种write buffer是两个极端的中间的一种机制，所以我们可以预期它应该算是一个比较efficiency，它不需要等到说要ride back或者是最极端的ride through一直写一直写那这种ride buffer就是我们刚刚提到的这样子的一个情况，我们今天就跟同学介绍到这个地方.