undefined
我們上一次跟同學介紹到Dynamic Pipeline的Scheduling相對於Static的Scheduling的話我們知道Static基本上看你是多少個issue比如說Dual issue或者是Triple issue它會固定把兩個或三個instruction配合在一起Dynamic的話它執行的order不一定是它的code sequence這是最大的不同所以我們這邊提到說它可以允許這個CPU就是說執行這個instruction它不是根據code sequence它是out of order那為什麼

要out of order呢它當然就是為了主要是為了要避免store我們知道說你如果是根據這個code sequence那如果說它有這個hazard那你必須要加store的話那它就一定避免不了除非说你可以去改变改变的话当然我们前面提到过compiler它可以去做reorder我们这边提到的是说它是透过硬体的方式它可以完成这样子的一个动作但是有一个很重要的原则就是说我们执行是out of order的执行那我怎么保证我的执行的结果一定是正确的因为你没有按照

Code的Sequence執行我怎麼能夠確定說我這樣的執行跟另外一種方式執行最後的結果是一模一樣，你要保證最後的結果一模一樣，它的方法就是你必須要怎麼樣呢，必須要CommitResultsToRegisterInOrder，就是說我執行的順序可以不一樣，但是我寫資料到Register裡面的順序要一樣，你只要寫資料寫到Register去的順序是一樣的話，那我就保證怎麼樣呢保證我的執行的結果一定是一樣的，所以這個是

一個非常重要的原則，所以我們等一下會看到它的一個structure裡面，它有一個部分，它就是去把執行完的結果，它先把它存起來，存起來等到，就是說它的應該，它可以寫到register裡面去了，那它才把它寫進去所以这样子的一个机制，它有所谓的防弊措施，防弊措施当然就是说我的out of order的execution，如果是错

的怎么办錯的话，它頂多就是再重新执行它，就是說这个执行是没有效的，但是它也不会造成错误的结果，因为它没有去update register，所以这是一个很重要的觀念，所以我們這邊有一个例子，這個例子就是一個load的ADDU，那我們知道说这个是一个load use的一个hazard，它会使用到这个load的一个結果那这个subtraction

呢，我们可以發現說它是34那这个34呢跟前面的012它没有關係，所以這個S4跟T3呢，这个inst ruction它用到的两个register跟前面都没有关系所以基本上其实你这个subtraction你并不需要等到ADDU执行完以后它才能够执行其实我们可以在ADDU执行完之前我们就可以把subtraction就把它丢出去就让它去执行如果T3跟S4这两个value已经available已经ready当然这个subtraction它就可以执行所以这个例子就是很明显的我们不需要等ADDU complete

才是借这个subjection这个是一个例子所以我们看到的一个dynamic code的这个scheduleCPU我们说它大概就是长这样子所以它基本上有分我们可以把它看成它有四个structure第一个structure第四个stage第一个stage我们说它是这个instruction phase还有decode unit我们这边有一个注解它说它是一个in order的一个issue也就是說我們在fetch instruction還有issue

instruction到它的publine裡面開始要執行的時候其實它是in order它並不是說隨便亂抓它是照著code sequence去抓的同學會說既然照著順序抓是不是就照著順序執行因為我們的在這一邊同學可以發現說它的functional unit相對的就多好多个它不是像我们那一种好像是像比如说前面介绍的Deal Issue它是上面的

这个Data Flow它是For两种Type的Instruction那下面的Data Flow它是For Load Store这一类的Instruction所以它把指令把它分成两边然后各走各的它不会说ALU跑到下面Load Store跑到上面这是我们前面的Static但是我们这边看到的Dynamically Scheduled它是有很多的functional unit这么多的functional unit它每一个functional unit前面都有一

个所谓的reservation station那reservation station基本上它就是我们这边issue的时候它就会看看说到底比如说哪一边当然它会考虑到所谓的low balance的问题或者是说它觉得把它丢到这边来它的执行就是说不用等待太久这样子的一个议题它会决定说往这边丢 往这边丢如果三个integer的话它在这三个里面会

选一个最好的把它丢过来所以我们在这边reservation station当然就是会假设说这边执行的慢的话这边丢过来的话它这边就会存在这个reservation station所以我们这边描述的它就是所谓的这个holdpending operand hold pending operand 就是說這一邊還沒有輪到它執行我們的 instruction 已經丟進來了instruction 丟進來它每一個 instruction 都會有需要 operandoperand 有的是 ready有的是還沒有 ready所以我們準備要執行的全部都 hold 在這個地方執行完的話下一個就進來執行完下一個就進來

所以我們在這邊看到的話我們根本不知道說我們這邊in order的issue將丟過來到底誰會先被執行完全dependent說這個到底丟過來在裡面的順序還有這邊執行結束一個就下來一個結束一個就下來一個看看它什麼時候才會被執行到所以在這裡面它是out of order的execution但是我們可以確定一點的是什麼就是說

在这里面只要进到这里面执行的我们都是说这个instruction它的operant都已经是ready的就是已经有它的operant它才会把它丢进来这边执行它不会说我这一个家需要两个operant有一个ready另外还有一个还不知道在哪里结果它就进来就是卡在那一边在那边等你要等的大概就是都在这边等那你只

要有的那它就这边有空的就会进来进到这边就开始执行所以这个是我们在这边说它是in order issue然后这里是out of order的execution完全dependent说在reservation station它进来的先后顺序还有什么呢还有它的ready是不是ready所以这边就是这样子执行完以后我们前面说我们必须要Commit执行完它不是直接就把它写到Register它

什么时候才可以Commit它的结果呢当然就是我们讲的就是说这边Commit unit里面它有所谓的Reorder Buffer这个Reorder Buffer它就是这边算完了它还没有轮到它可以做Save Write的一个动作它就会把它存到所谓的reorder bufferreorder buffer就存在里面它就一直等等到说轮到它write它就会把透过community把它write到register里面去write完之后它所占据的reorder buffer就可以free掉它就把它free掉所以这边它也是有这种缓冲的机制不用怕说你这边

执行执行然后执行完又没有办法write他不知道丢到什么地方去我们这边会有一个缓冲区然后就是去save那些还没有轮到他的write一直到说他的前面他的前面的那些write都已经complete轮到他了而且他也确定他的这个结果是正确的。他为什么会说他确定这个结果是正确的，我们后面会看我们后面看说我们刚提到说这里面的operand

都available之后它就可以进到functional unit去执行，这当然包含说它已经抓到抓到它要的data其实它还包含什么呢包含就是说我们前面不是有什么speculation我可以去猜对不对 我可以去猜说我这个到底是要不要跳或者是我这个load它到底要到什么地方去load之类的这样子的一个资讯把它去猜， 然后去把一些需要等的反正他要先执行执行完以后他就hold在这边等到前面的跟他相关的已经complete之后他确定说他前面的猜是对的这个他就可以

write如果他前面猜的是错的错的话他就没有办法他就不能write他不能write他就是必须再做一个正确的一个execution所以这样子的一个机制我们就可以保证就是说到最后执行的时候out of order但是最后的结果它是正确的这里面还有一点detail的就是说我们要了解我们在这里面functional unit执行完的时候它不一定都这个值就是直接好像都一定要马上就是说它只有写到reorder buffer不一定因为我们在这里面

这个pending的operand它有两种情况它会把这个pending的operand把它补 overwrite就是说这个operand已经available它就把它抓过来一种情况是它在这边pending然后结果是怎么样呢就是这里面的functional unit它的结果刚好算出来所以它算出来的这个结果其实它要用的instruction已经在这里面pending在那边等所以这边算出来以后这个值它会直

接送到reservation station它就直接送过来另外一种情况它已经算好已经save在reorder buffer里面它是先算好的已经存在reorder buffer这个instruction要使用这个结果的instruction后面才进来进来这个时候当然它就可以从这个reorder buffer里面把这个值把它读回去就是从这边就把它读回去所以这边我们说reservation station它的operand它可以从这边过来

如果它已经算好已经available在这个reorder buffer的话它就从reorder buffer从这边过来所以我们这边看到两条线代表的就是说进来以后在那边等这个算好就走这一条那它算好存到这边已经存好了这边进来那它的纸要从这边送过去所以它是有两个Path它的意义是在这个地方所以这个就是我们要跟同学介绍的这个简单的Dynamic Call的Schedule CPU同学有没有什么问题

你說最後邊這幾個嗎還是那邊有Integer 從左邊到右Integer Integer Load Point然後有Load StoreLoad Store有什麼意思這個可能就是專門執行這個Load Store的Functional Unit所以這邊同學可以想的它可能就是說譬如說這邊有一個Floating Point這邊有一個Integer那可能就是它這邊舉例是說假设它有一个专门是在做

load store的一个unit那load store的话它当然就是一定会送到这边来所以感觉这种structure跟我们前面介绍的那一种就是这个就是说同学可以想象成说你这个load store基本上它还是有pipeline它还是有pipeline大概不太了解Functional unit到底是什麼東西Functional unit是什麼東西你可以把它想成說這個就是做Integral的加減乘除像一個al這邊就是做14 point的加減乘除所以你只要是那種Integral的這些osmetic operation

大家都是送到这边那如果是14 point的这些osmetic的 operation那就送到这边来所以它每一个是一个小小的 pipeline 是吗Yeahload store的话就是送到这边来那这样的话它里面也有自己的memory因为如果它要做load或是store它要load到memory或是从memory所以它里面每一个里面有自己的memory吗所以我们有很多memory units吗

应该不是说有很多个memory unitmemory unit我想应该是一样的memory应该是一样你如果说各有各的memory unit你还要做synchronization那个又是一个不简单的一个机制只是它这边它没有touch到那一部分的operation它只是一个concept这个concept让我们知道说它大概就是有很多个地方可以submitsubmit我们的instruction它

有不同的type所以这边最主要的关键是说它有不同的different type你同一个type就是可能有很多个目标可以丢所以你可以就是一直可以丢很多的 instruction出去如果它的data dependency没有那么严重的话，它是可以预期是可以提高这个parallelism没有问题我们就再往下看后面我们要提到的当然是我们前面就是介绍的这个Dynamically Scheduled CPU

它里面一样会有一些机制，这个机制就是我们前面有提到的一个是Register Renaming因为我们知道说我们有时候要去除掉这些Anti-Dependency我们必须要做这个Rename你如果没有Rename的话其实它看起来名字都一样所以它有这个Dependency所以我们说这边的Reservation Station还有Ordering Buffer他有提供这种register renaming的这种机制所以这边只是让我

们知道说他有提供这样的机制但是detail的话这边也没有详细的介绍所以这边的描述基本上就是我刚跟同学的介绍同学可以自己看一下跟我介绍的应该都是一样只是说我们了解说刚刚前面的架构里面有包含我们前面提过的register renaming还有speculation这个speculation这边有在稍微做一下说明当然就是说第一个我们可以predict branch还有continue ue的issue所以我们不需要说等到branch outcome都决定之后

就是说等到Branch Outcome都决定之后然后才去执行它后面的但是你可以先执行你可以先执行但是你不可以不可以Commit你的这个结果你一定要等到你的Branch的Outcome已经确定了之后你才能够Commit这就是我们刚刚提到的Branch已经确定我们前面的这个猜测是对的所以我们就可以把这个结果Commit出去另外一个

就是 load 的 speculationload speculation 它这边提到的就是除了我们前面知道的说我们 load 因为它会知道这个结果会出现不是在 execution stage 是在 memory stage所以 memory stage 之后它的结果才会出来是会晚一个 class cycle其实另外还有一个情况就是我们等一下会跟同学介绍的 memory这个 chapter 里面有提到所谓的 cachecache 就是我们知道说我们

不是所有ReadMemory的operation都是直接到Memory里面去读因为我们Read的Memory或者是Write一个operation的速度相对于CPU的这个速度是很慢所以我们不可能每次都是Memory读我们会到Cache如果Cache是Hit的话，我们去读这笔资料不需要到Memory直接到Cache就读到资料这样子速度非常快，就没有所谓的miss的这个penalty。如果说你去Cache读

就没读到，你还要再到memory里面去读，那我们这个CPU它就必须要store它要去等这个memory的资料读回来，那这个时间就相对CPU而言就很久，所以它就必须要把这个instruction把它store下来。所以，我们为了避免这一类的这一类的这个penalty的话呢，我们大概就是会做一些预测那这里面的预测呢，比如说，它会predictEffected address我

们说我们去我们去预测说我们要去哪里抓我们去predict这个loaded value我们去预测说我们抓回来的资料是哪一笔资料，然后它说还会去load beforeCompleting outstanding store那store我们知道说它是把这个一个register把它write到这个memory里面去load我们刚好是要去memory里面去读资料所以，如果说这个store还没有complete如果说它没有dependency你去load的话基本上它也是有风险，这个也不管反正它先load它在store还没有完成之前它就先load就是说bypass store的value to load unit跟这个是一样的

就是我们不需要等到这个store的这个value直接存进去之后再去读就是直接把要存的这个资料如果他们的确是有这个data dependency我们就直接把load的资料直接transfer到到哪里呢到这个load所以我们做的这些东西呢我们基本上都有一些这个猜测的这个风险猜错但是如果猜对的话呢你就有game所以我们这边就会

用這樣子的一個方式就是先讓它去執行但是還是一樣一句話就是說Don't commit load你最後無論如何就是不要去把你讀出來的子Write到register除非說我們已經確定說我們前面的猜測已經知道說是對我們就可以把它Commit出去不然的話你一定要Wait在那一邊所以这个就是我们在Dynamic Schedule在这一块里面一

个非常非常重要的一个观念就是Out-of-order Execution但是你必须不能够Commit直到你确定你的前面猜的或者是在等的那些In-order的Write都已经结束了你才能够Write我们接着继续来看Dynamic Schedule我们说为什么会需要Dynamic Sched ulling呢我们刚刚看起来整个structure好像比我们传统的这种plotline还要复杂了许多。为什么需要这么复杂的一个机制？为什么不是就让compiler来reordering来schedule这个issue这样子就可以了呢？所以我们来看一下这边他提出几个

提出几个理由。第一个，这边少了一个T，它不是所有的store都是可以predictable都是可以预测的，有哪一些store是没有办法预测的呢？它这边提出来有一个我们刚刚提到的cash missed就是我们如果要去读一笔资料尤其是比如说我们这个load这个load它的结果已经不是在execution stage出现它已经delay一个stage是在memory stage才出现结果它delay了一个stage才出现结果去读的时候读cache它又发现没有在cache那这个又更惨它要去memory里面去抓资料所以这种cache miss会让它付出惨重的

这个代价因为它要去等这个memory的access所以通常这个要好几个这个CPU的这个cycle，所以这个就这东西是没有办法预测我们没有办法预测说它到底有没有在cache里面那还有呢？我们说第二个，是我们也没有办法都有办法去做这个branch的这个predict然后去根据这个branch的predict去做schedule，同学会说为什么会没

有办法做这个schedule呢？我们不是有一些predict的机制吗？可是，我们在这里是说，如果不是dynamic schedule，我们如果不要dynamic schedule，我们就是由compiler来负责那ompiler负责的时候，他要去predict，因为我们很多branch的predict尤其是这种dynamic的prediction，我们是根据wrong time的status才能够去预测对不对；我们是根据说上一次他执行的时候，他到底是猜猜什么猜对还是猜错，这一次才能够知道要猜什么，所以是wrong time的时候，你才能够知道我要怎么猜，所以我们ompiler的时候，compiler没有这么聪明.

compiler它不是说，它不是一个simulator可以去模拟它的执行所以compiler不知道说它run time的时候到底是猜对还是猜错，所以它没办法猜，所以compiler它也没有办法做这个scheduling没有办法搭配你的dynamicprediction的skin来做scheduling第三种我们知道说不同的就是說implementation即使是一種ISA同樣的instruction set architecture那你不同的implementation的話我們會有不同的一些hazard就是說

會有latency跟hazard它的這個數字它的值會不太一樣這個不一樣的話會造成什麼呢會造成就是說如果我們是用compiler來做scheduling的話你compiler雖然說它都是同一種ISA可是它不同的implementation它會有些微的差異針對它的latency hazard會有一些些微的差異那compiler怎麼辦compiler它必須要提供不同的option或者是不同的version或者是像就是你下compiler你可能要下一個option-什麼

跟他specify你这个到底是哪一种机器你告诉他是哪一种机器他就知道说他们这个之间的差异他就会去根据这个去做一些optimization这样子的话对compiler基本上其实是一种负担最好的解决方法其实就是你根本不是用software不是用compiler就是透过hardware因为我們剛剛前面看到的那個機制它到底會怎麼執行我根本不知道

你也不用去管它反正它自己有一套可以良好處理這些Hazard Store這些機制你就把它丟到這種Dynamic的Scheduling的Hardware讓它自己去執行自己去判斷說到底誰要先執行誰要比較晚執行所以這種完全不需要Software去take care所以就是有这些原因所以才需要说要dynamic的schedule所以同学对于这样子的一个原因同学要知道就是说他有三个这边有三个原因为什么需要dynamic schedule有一些例子这边同学要注意一下所以

我們在課本裡面我們最後說這個Multiple Issue到底有沒有work它不是說Multiple Issue這樣子的Design到底可不可以動當然可以動啊這麼多的已經商業化的CPU都可以動只是說它的Performance到底有沒有我們來的預期的這麼的好就是說這個Multiple issue它当然这样子的觀念我们的确可以realize它也可以呈现出我们预期的这种行为但是它不见得会得到我们预期的很高的平行度它不一定可以得到一个很高的预期的平行度为什么呢

我們这边它有列出一些原因第一个就是说实际上program它有很多这种dependency所以让我们在instruction就是说我们要透过这种inst ruction level的这个parallelism的确是有一些复杂度而且有一些它是没有办法侦测出来就是说hazard它到底我们刚刚提到的那些hazard看起来都是显而易见比如说有一些hazard

有一些dependency是很难去被侦测出来或者是被侦测出来然后把它remove掉比如说有一个叫pointer aliasing什么是pointer aliasing呢我们通常指这种aliasing指的就是指说同一个memory的location它是透过不同的这个variable去access也就是说我有一个A有一个BA跟B看起来不一样A跟B看起来不一样可是实

际上这个A跟B呢它却是指到同一个memory的location我们知道说我们只要宣告一个integer A integer B它两个就是不同的variable它两个就是占据不同的address可是我们如果是用pointer就是C写得很上手的同学就很喜欢用pointer那 pointer 用多了就是有时候这个页路走多了就是会碰到一些奇奇怪怪的一些 bug那些 bug

呢当然就是都是我们 pointer 没有适当的使用然后没有适当的管理所以你根本不知道说一个 a 跟 b 的这个 integer pointer 的 variable结果 a 跟 b 看起来是不一样结果你这个 star a 跟 star b实际上是指到同一个 memory location这个东西你根本没有办法去分析判断你只有在run time的时候你才会知道就是你执行到某一个

阶段的时候原本两个是不一样透过一些update之后两个就直到同一个位置所以这个东西你没有办法去分析你也没有办法去把这种dependency把它拿掉可是我们真正的program里面又常常看到这种point所以这个是很麻烦有一些 parallelism你也没有办法去把它呈现出来为什么说没有办法呈现出来因为我们在分析这种 parallelism我们不会怎么样我们不会说我一次我就把所有的 code 全部摊开来我就把所有的 code

全部摊开来然后分析它的平行度这个复杂度也是非常高所以通常我们都会是看一段一段的一个 code所以类似像这一种还有我们前面提到的就是memory的delay就是你如果说是cache的一个miss你必须要到memory里面去堵的话它这种penalty通常是很高的所以你必须要store待几个cycle所以我们就很难去让我们的popline整个让它都是full

当然这些问题就我们这边提到的如果说我们有一个很好的speculation的机制这个是可以帮助改善我们前面提到的这些情况所以这个multiple issue如果没有处理得好的话其实我们很难得到我们想要的这种高平行度的效能这边有提到另外一个问题就是目前大家非常重视的这种powerpower的

issue因为我们现在很多大家都在谈这个绿能像这个绿能的确是很重要最近家里接到电费的单子已经连续两个月被台电表扬连续两个月当月用电度比去年節省多少多少多少節省百分之幾十%當然它只是那張紙給你表揚一下它沒有什麼然後再說就可以減免你的電費多少錢那個

也沒有多少錢但是你會知道說你家的用電到底是省了多少其實我們沒有改變什麼我們只是把一台老舊的冰箱換成那個是有濾冷效果的冰箱所以它會省掉很多的電这边他还在讨论说Power Efficiency我们前面提到的Multiple Issue然后Popline的机制它到底效果好不好它的Power耗掉多少Power可以得到多少效能的提升这个很明显我们如果使用Dynamic Scheduling它的复杂度

它一定会多一些Hardware多出来的Hardware就会用掉PowerSpeculation也是一样我们多了一些功能它一定就是需要Additional的H硬件去执行那一些功能所以，它一定是需要Power，所以我们同学来看一下这边Power使用最多的就是集中在这边10,37590个同学可以发现说103然后这个issue with是3然后到out of order speculationyes，所以它的power是最多的。同学可以看到issue with只有1然后out of orderspeculationno，它这边70瓦这边是103瓦可是它有8个call，

所以他是认为说multiple simple codesmay be better可能会比较好 justepower efficiency来看的话可能会比较好可是，我们还要知道说你这个八个code你要怎么用你的八个code要怎么用我丢一个很复杂的程序进去让它跑，它要怎么用它有办法把一个程序它就自动地它的Compiler OS就自動地就就劈一啪把一個程序然後就散到八個

Code裡面同時去執行執行完之後就很快地就Return你的結果會告訴我們嗎有沒有可能現在好像還没有這麼好的一個環境所以你这个Code再怎么多也是没有用所以這必須要搭配整個這種軟體的這個環境才有辦法后面这个我们就跳过来同学自己看一下他也是把我们比较常见的市面上的一些这个CISC它的这个CPU简化的这个架构图让同学看，所以我们看最后最后的这个Force这边，他告诉我们说，我们会有一个错误

错误的观念。说这popline非常简单，popline简不简单，我们在讲popline的时候，我们第一个例子是介绍什么，就是介绍跟同学息息相关的这个洗衣服对不对洗衣服、 烘衣服，这听起来好简单，然后马上就可以得到一个performance的一个estimation，它的一个公式，这也是蛮简单的觉得说，好像这一章就讲完了，但是结果没有想到后面

噼里啪啦，又跑出来一大堆issue。其实所有的research基本上都是这个样子，就是原始的concept应该都不会太难，但是你要把concept把它realize，要让它尽量approach我们idea的这种performance的话，你就会碰到很多很零碎那些很难解的一些问题，所以我们就后面又提出一大堆方法。基本上都是要希望让我们的一些原始的idea可以

让它完美化。基本上就是这样子，所以魔鬼都藏在细节里面，所以当你要看到detail里面去的话就会有出现一大堆issue。所以这个大家都了解了，我们说poplining跟technology是没有关系的真的是这个样子吗？当然没有，因为同学可以发现说我们的popline有这个forward的机制有这个Hazard Detection的机制，这些当然看起来不会非常

的复杂，但是基本上，它就是需要额外的HardwareStatic的Multiple Issue跟Dynamical Schedule的一个issue这个很明显也是尤其是我们看这个Dynamical Schedule的这种Pup line，我们会发现说它的structure相对的是比较复杂。如果说我们的Semiconductor的technology它没有办法support可以pack这么多的transistor到一个single chip里面去其实我们的所有的那些天马行空的观念是没有办法realize在一个single chip里面。你如果没有办法realize在一个single chip你必须要把它做成two chip那些观念是没有用的为什么因为它两个two chip合作，它就是一定要

透过什么off chip的一个signal的transfer一个off-chip signal transfer它就会把你所有的gain全部都杀掉全部都吃光光，因为你一个off-chip的一个signal transfer它的delay是远远大于你的CPU它的一个cut cycle所以我们就是你的一个好的idea没有办法pack在一个single chip什么都没有用所以当然是跟technology有相关所以我们要知道说technology有没

有办法support这么复杂的机制最后我们就来看几个这本书介绍的是risk的架构所以我们当然要来讨论一下说risk的好处然后还有sysc的它这边没有讲说sysc的坏处它只是讲说poorISA他也没有说破ISA到底是什么但是他说会让这个poplining变得更困难更复杂其实就是让我们设计一个popline会变得更复杂设计比较复杂你设计出来的东西当然一定也会比较复杂所以比如说他说complex的instruction set像VEX IA32

這樣子的一個機制我們現在大概沒有用這個這個要去博物館裡面應該找得到或者是部隊裡面可能還找得到以前我在當兵的時候就是維持那個在市面上都看不到的王安殿好大一台然後那個印刷機也是好大一台像这个大家就知道IA32这样子的一个比较复杂的机制的话它会让我们在设计popline的时候

相对的比较困难为什么因为复杂的instruction set代表说它可能会有很多种它指令可以分成很多类每一类它所需要的时间是不一样的你需要的时间不一样的话它可能会让你在设计PUP line的时候你的PUP line的stage没有办法balance，所以这个是一个issue。我们知道说PUP line你的每一个stage如果说它刚刚好每一个都切得好好的都没有idle的，这个问题这种是一个idea的一个PUP line的一个design。如果说你的PUP line stage非常的多，它没有办法是一个balance的一种

partition的话，那这个对POP9的设计它的结果当然是不好它就会浪费掉一些这个时间，所以类似像这一种的都是不好的。所以像那个IA32这一种，它有的instruction非常单一一个instruction operation非常复杂，所以它必须还要再加入这个micro operation，micro operation是比我们前面在提到的这一种Machine instruction还要low level，还要low level的instruction，这些micro operation它是更

low level所以它可能为了要完成一个Machine instruction，它必须要去执行一堆micro operation，所以它的micro operation像在这种比较复杂的机器里面，我们都可以看到它会定义这种所谓的micro operation还有complex addressing mode就是说它的adjacent的mode不是只有一种所以它可能有很多种mode都可以去accessregisteraccessmemory这种比较复杂的这

种mode当然你要去判断hazard或者是其他的那种机制相对的都会比较复杂你只有一两种要去判断hazard或者storeforward当然会比较简单你有很多种机制的话你有很多种mode这种就会比较复杂还有就是说我们前面提到的delay branch它有比较长的delay slot所以你要如何去fill去利用那些delay

slot所以这些问题都会让说一个比较复杂的designinstruction set它要做part 9的话相对的就会花比较多的effort所以我们的第四章大概就是介绍到这个地方我们下礼拜的期中考包含第四章的全部还有我们等一下提到的第五章我们看第五章讲到什么地方我们第五章的内容是要介绍MemoryMemory的话一定要提到Memory Hierarchy因为如果没有Memory Hierarchy的话

我们的电脑还有任何的电子装置不是又快又贵不然就是会又慢又便宜大概就是没有那种比较折衷的，所以 Memory和 Rocky是我们等一下要介绍的重点。 Memory其实这一张同学如果看新闻的话应该都知道，我们台湾的几家DRAM公司就是已經虧了好多年了，每一年虧的钱都是嚇死人的多他们每一次虧

都是幾百億幾百億這樣子在虧那个好像钱都不是他們的，这个钱都是銀行的很多钱都是跟銀行借的銀行的錢没有辦法還最後變呆帳誰要負責就是我們大家每个人分一份大家分摊分一份把它分掉所以这个其实都在赔大家的钱不要以为说这个跟大家没有关系像我们台湾其实就是迷信做大的产业他就是说你要资本的要大然后Hire的人要多他比较没有去管说他的效应到底是怎么样他也不管说这种产业

到底要用什么方式来经营那你要大的资本的你要Hire的人多你要资本密集没有关系可是我们台湾就是喜欢什么最多的就是中小企业每个人都喜欢当老板大家都不喜欢屈居在别人的下面即使你是一人之下万人之上也会觉得说还是不够我一定要是万能至上所以大家都要当老板所

以你看我们上一次低润产业上一波拆连死掉然后政府出来说要救所以就要整合要整合可是他们就不要因为整了以后只有一个老板到底谁要当老板呢所以每一个人都是私心每个人的私心都非常的重现在已經救不了了所以現在已經沒辦法救所以現在就是就是看賠的越少我們也

就賠的比較少。如果繼續再賠下去的話，那個會變成無底洞。我們剛剛講的就是這個。他們就是都在做這個DRAM既然要做這種產業，你就要像韓國他們一樣就是你要資金要夠大，你要資本夠雄厚不要說每一家都這樣小小的跟人家比都是小公司要去跟大公司比好像是很多小公司就可以打贏一家大公司一樣。所以我們在這邊看到的這個Memory的Technology這邊看到幾種分類就是SRAM DRAM還有這個Magnetic Disk

就以前從早期的這種大片的這種軟式磁片然後到現在已經都沒有人在用了還有這種idea的這個memory我們希望idea的memory是什麼呢希望說我們速度非常的快就是像SRAM這種速度是最快所以這個data應該需要update了因為這個data是作者大概應該是兩三年前的這個數據可能需要update0. 5Ns到2。 5Ns，它的access time可是我們看它的per GB，它的price是2,000到5,000美金。我们的DRAM大概它的access time50Ns到70Ns，它的price20到75Ns。

所以，同学可以发现这个price差距非常的大但是它的delay差距也非常大。所以，我们最好是什么我们的DRAMsize全部都是SRAM。这电脑一定快逼了快得不得了。这又更慢，然后这个又更便宜。所以，我们是希望有这么大的一个容量，然后这么快的一个速度，这是一个我们希望的那，如果是这样子的话呢就是我

们希望最好是这个，就是企业界就好像是当那个慈善机构一样，就是就是生产SRAM然后用用这个硬的价钱在卖这样子是最好。那如果这样子的话，我们就不需要这个什么locality。但是实际上不可能，所以我们必须还好我們發現有這種locality的現象什麼是locality呢。 locality它的意思就是說其實在program執行的任何時間，它有這種資訊集中化的現象。它這種locality它有兩種就是temporal locality，另外一種是spatial locality一個是時間性，

另外一个是空间性什麼是时间性的locality呢？它的意思就是说我这个item最近被access到的，它最近被access到它现在被access到的话，它最近的未来也很有可能再被access到。所以这是指時間指这个时间轴上面，我現在或者是我刚刚被access到的这个item，它很有可能它就很快又会被access到，比如说什麼呢就是类似像这个instructions in a loop我们在一个loop里面我们在loop里面在那边跑这个loop在那边跑呢它loop里面的instruction它就一直被执行

所以我们在fetch instruction的时候它就一直在fetch那些instruction所以这个item它被access到的时候它可能如果是在loop里面它又return回去它又很快又被执行到还有所谓的induction variableinduction variable是指什么呢induction variable它指的就是指说比如说我们有一个for loop比如说一个for i等于多少然后就是i小于等于多少然后它就一直repeat这个loop然后每一次loop执行完都会i加1i加加在loop里面就只做一件事情

就是j等于j加10假设我们有这么一个简单的一个loop所谓的induction variable指的就是指那个i跟j为什么是i跟j呢它有什么特性呢这两个i跟j的特性就是在loop里面它都固定被加同样的一个constanti永远都是i加1j它可能永远都是j加7或者永远都是j加10这一种就是所谓的induction variable所以其实这个也是发生在一个loop里面像这一种的都是你现在被access到之后因为就是在loop里面在那边绕所以它在

最近的未来大概都很容易还会再被access另外一个叫spatial localityspatial locality就是空间的大家就可以推得出来就是说我目前这个item被access到所以这个item的附近的item它也可能很快就会被access到这种就是spatial locality所以很明显的一个例子就是sequential executionSequential我们就是这样1 2

3 4 5 6 7就一个指令一个指令的这样子一直抓一直抓一直抓Sequential的抓所以我现在抓到10那11呢等一下就轮到它了13也快到了所以这一种就是Sequential Instruction的Access还有就是所谓的Array的Data我们说ArrayInitial ArrayA10所以我现在是access到A0所以A2 A3 A9那些大概就很快就被access到这些都是属于这种spatial locality因为有这样子的一个特性所以我们在access memory的时候

我们可以利用这种locality的特性怎么样呢就是我们去抓资料的时候我们不要一次就抓一笔我们不要一次抓一笔我们就一次抓一个单元比如说抓一个block我们的这个unit叫block一次抓一个block因为它有locality的特性就是它周围可能就会快被用到所以就一次抓一个block所以抓一个block就不会说我一次都抓一笔另外这一种temporal locality它现在被access到

之後也都應該有很高的機率會被Access到所以我們就可以在CPU跟Memory中間加一個Cache這個Cache就是去Hold什麼呢Hold最近被Access的那些Data把它Hold在Cache裡面所以我們知道說CPU到Cache去抓很快CPU到Memory去抓很慢所以我就把最近被抓到的把它放到这个cache所以你下一次

要再抓的时候它搞不好就在cache所以我这样子之后它都一直到cache里面去access所以它就是这一种temporal locality我们这边special locality就提到说你到memory里面去读一笔资料就是把这一笔跟它周围的一个block一次抓到cache里面去就一次抓到cache里面去这样子的话我们就可以在cache里面

可以利用这一个又可以利用这一个就是Temporal跟Special都可以善用这样子的一个特性所以就是我们刚刚提到的因为它有Tempor al的locality所以我们可以用这种Memory Hierarchy就是加了一个Cache。你如果觉得一层Cache不够，你就是Two Level Cache或者是Three Level Cache你可以Level多一点那就是我刚提到的就是把最近被access到

的还有包含它的nearby附近的全部都把它抓抓到这个，就是抓到那个，这边是写从disk抓到DRAM，它是在下一个level，因为我们最上面的level是cache，那接下来是memory，再接下来是hardd就是disk所以，它说我们可以把所有的东西都存在disk，然后把最近我现在access到的跟它附近的资料整块从Disk搬到DRAM，所以你就不用每一个都到这个Disk里面去抓还有，还可以再把这个DRAM的资料再搬到SRAM，这就是所谓的Cache。我记得我在开学的时候有跟同学提到过，就是以前我们去

做的这个tool到customer那边去试run那个tool，就是一个chip design读进来以后，它就在那边卡在那边卡很久就卡了一个晚上，一个很简单的一个location要把它point出来，然后要把它highlight出来，它就搞了一个晚上，它为什么会搞了一个晚上呢，因为它是在做这个disk，你看它mem ory不够它的design的size就已经比D-RAM的size还要大，

所以它没有办法把它的design全部都放到D-RAM里面，所以它必须要在D-RAM跟这个HD disk里面一直在那边做swap所以你就听到那个disk在那边一直这样叫一个晚上这样子操的话，那个HD很容易就坏掉。根据我们刚刚的一个描述，我们说我们的memory hierarchy大概就是长这个样子，processor，然后cache，然后memory，所以就一次抓一个block就是一个unit ofcopy我每次copy就是copy一个block，这个block它可能是multiple word可能是很多个word还有就是说，如果

我们要去读一笔资料，比如说，我要从Processor去读Cache去读资料，我在Cache里面就已经找到这一个要Access的Data这个就是叫Hit，就是说In upper level，所以对Cache而言，这个叫Cache Hit它就是在Cache里面，如果说它不是在Cache里面，它是存在Memory里面，这个就叫 cache miss就叫 miss当你 cache hit 的时候这种是最快乐的，就直接从 cache 把字要读走，如果是 cache miss 的话，这个就麻烦了你就必须要到 lower level这里找不到到 lower level去把一个 block把它 copy 过来这种叫 miss我们在 design 这样子的一个 hierarchy

我们分析它的performance我们最care的是什么呢我们最care的是hit ratio就是说我有total有一万个SS结果我只有一百个hit这种hit ratio非常非常的低这个几乎没有善用Memory和Lucky的效果我们当然希望说我们的hit ratio百分之九十几miss ratio就非常的低所以miss ratio是等于1减掉heat ratio所以这个是一个

我们第一个看到的memory hierarchy刚开始的这个观念所以我们这边有一个这边以这个cache memory来看这边这张图它只是解说说这个cache memory以这个例子来看这cache里面它原本是长这个样子那我如果说要去access一笔data叫SNSN在这里面都找不到所以你就会从memory里面搬了一个SN过来然后放

在这个是空的地方这边有空的它就摆在空的如果没有空的怎么办呢假设这边都满了没有空的你就必须把一个某一个把它拿掉把它从cache里面拿掉然后再把这个SN把它搬进来怎么拿怎么搬我们后面会介绍，但是这里面我们要知道的就是说，我们把资料放到Cache里面，第一个我们怎么知道说这个Data是在Cache里面，我要判断我要判断说这个Data有没有在Cache里面，如果在的话，它到底是在什么地方，它在Cache的哪里，

所以我们后面要跟同学介绍，就是说这个Memory跟Cache两个之间的一个Mapping，这个Mapping可以让我们知道说这笔资料有没有在Cache在的话，在哪里，第一个方法就是Direct Map Cache这种Mapping的机制叫Direct Map Cache，基本上同学要了解就是说Cache，它也是Memory Cache，当然是Memory，只是說它是速度特快然後還有價格很貴的一種Memory，所以當

然Cache，它也必須要有Address，我们的Memory，我们原本的Memory也有Address，对不对，我们Memory裡面也有Address譬如說，我们來看假設說，這個是我們原本的Memory，這個是我們原本的Memory，它是長這個樣子，它長這個樣子它長這個樣子我们把这个memory，它的address分成三个field，最右边的field是offset，这个offset指的就是指说，我们可以透过这一个field来找出它是第几个byte或者是找出它是第几个word，它是第几个word我要找第几个word，然后第几个byte它是用这个来identify

后面的这两个fear其实它就是拿来用用作什么呢用作来identify说到底在cache的什么地方走半步走半步这里用来identify它在cache的哪一个地方所以我们是由address来决定它的location那direct map它有一个特征它的特征就是什么呢它的特征就是说我根据我的这个memory的address根据它的address我只能够摆在cache的某一个位

置只有一个位置可以摆所以它说only one choice你从memory放到cache只有一个位置可以摆对这个memory的location而言你不可以说我又摆这里又摆这里又摆这里又摆这里这种机制它是不允许它的Mapping的方式就是一个位置对应一个位置它是一个位置这个位置它只能够对应到Cache里面的唯一一个位置那怎么对应呢它对应的方式很简单它就是Block address、Modular number of blocks in cache比如说这边有1、2、3、4、5、6、7、 8

它有八个block你就是把block address module number of block in cache所以这边就module 8所以同学可以看到你module 8的话，你会得到多少0 1 2 3 4 5 6 7所以你每一个你每一个memory location，它的block address去module 8它只会得到一个固定的值，你一个address去module8不可能会得到两个不同的数字，只会有一个固定的数字，所以它就是对应到它，

它就是对应到它，也对应到它这个怎么看呢所谓的block address它指的就是指这一边，就是指这一边，就是左半部，这一边所以左半部，这一边我们这边的例子，这一个memory的block address是00 001那它module 8会得到什么呢，就是得到最右边的三个bit，对不对也得到最右边的三个bit，所以我们可以看到001就是对应到这个001，然后这个block address呢101对应到的就是这个101对应到它，那这个呢01 101

最右边三个bit也是101你module8就会得到它的余数就是这个，所以它也是map到这个101所以这样子的一个mapping有一个特色，它什么特色呢它这个mapping是多对一的mapping，这边这个也对应到它，也对应到它，也对应到它多对一的mapping，多对一的mapping表示什么呢表示就是说以 cache address 001而言至少在这里有1 2 3 4有四个memory location在竞争一个cache的location有四个在竞争一个你有四个在竞争一个就表示什么呢就表示说

最坏的情况是什么最坏的情况就是我第一笔资料access第一笔access的资料是这个位置第二笔access资料的位置是这个第三笔access的资料第四笔access的资料是这四个位置这个对K学员是这个knock man为什么呢因为他第一次access他他就把这笔资料搬进来结果他第二笔SS他搬过来发现

这里有人占了怎么办就把这笔资料剔掉把它剔出去再把它Safe进来想说等一下应该还会再SS到他结果第三次SS很不幸变他他又把第二笔又把它剔出去把第三笔再存进来结果第四次呢结果他又换他大家都很忙就像现在大家都是穷忙就是都很忙在那边进去出来进去出来都没有

reuse这个都没有reuse完全没有reuse就是进去以后马上就被踢出来进去以后马上就被踢出来所以其实它比直接去access memory还要慢对不对你直接去access memory就直接到memory去抓就好了你这边你先到 cache miss然后再到 memory然后存进来第二次又 miss再到 memory所以反而更慢当然这个是我们是用一个极端的例子来解释说这个是最差的情况一般不会这样子因为有locality同学要相信locality所以这个locality会让这样子的一个效能会好非常的多

所以这边最主要的问题是在说多对一它的一个特征基本的对应的原则就是每一个位置只会对应到Cache的唯一的位置所以这就是我们介绍的Direct Map Cache我们今天介绍到这里.