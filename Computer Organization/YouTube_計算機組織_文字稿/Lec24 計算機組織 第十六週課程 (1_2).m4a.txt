undefined
我們現在來看Cache Coherence的Problem這邊討論的Cache Coherence主要就是考慮到我們現在大概都有Multicode CPU它們如果是Shared同樣的Physical address space比如說每一個Code它有它們自己的每一個CPU它們的code它們有自己的Cache所以說CPU A的Cache還有CPU B的Cache然後它們是共用一個Physical的Memory我們使用的Cache的Write機制是Write-through的一個機制我們來看一下這個例子這個例子它有三個Time step三個Time step分別是CPU A Read

location x cpu b read location x接著是 cpu a write 1 to location x比如說假設原本的x它原本是0所以它initial的值是0所以當我們cpu a去read的x的時候我們會把0把它讀到a的cache裡面那CPUB它Read的話它當然是把這個0把它讀到這個CPUB的這個Cache但是第三個步驟我們是A把這個1寫到這個X這個X首先我們知道說我們Cache這個是WriteHit所以我們的這個A它的這個Cache會被update成1因為我們這個是

WriteThrough的一個機制所以它一旦這個Cache被update的時候我們也會馬上把這個e把它update到這個memory location x這個位置所以到目前這個時間點看起來好像一切運作的都非常的順利可是我們可以從這一個table我們看到的是經過這個step 3之後其實這三個entry它應該都是指同一個都指同一個數對不對它指的就是指這個MemoryLocationX這個位置的這個值那我們

會發現說這邊是1這邊是0這邊是1所以我們就是知道說以在這個情況之下這個CPUB它的Cache裡面的值其實它已經是算是你可以說它是已經落伍了就是因為它沒有及時的去update這個Memory的這個X所以我們後面这边要探讨的其实就是这一类的问题我们要如何当我们的这个code我们的Mati code它有它自己的这个cache我们要如何来保证说我们的这个program它在run的时候

它都能够维持这样子的一致性还有这个连贯性在后面我们看到会有一些机制基本上就是希望能够来CPUB這個時候它如果做Read的時候它應該是Read到誰呢它應該是Read到1而不是Readto0以目前這個結果來看的話我們如果說CPUB它去Read的話它會得到一個Hit那它Hit它的值是一個舊的值它並不是1它是0所以我們後面就是做這樣子的一個

在这方面我们大概就是要讨论到两个面向一个叫coherence 另外一个叫consistence我们就是有这样子一个coherence跟consistence才能够确保说我们的这一种multicode然后它们有各自的cache它们在运作的时候才不会出现非常离谱的错误也會讓我們這個程式在執行起來會有一個正確的結果首先我們來看一下就是說

什麼是coherencecoherence其實我們這邊有一個informal的定義它告訴我們什麼是coherencecoherence它說其實就是我們這個讀當我們要讀一筆資料的時候到底是讀到哪一筆資料呢它是一个 return most recently written value所以它是会读到一个就是最近写进去的一个词它会读到最近写进去的一个词这个就是叫co

herence比如说我们什么是最近写进去的词因为对一个location x而言可能其实很多人他都会去想要去access这个词这个access它可能是做一个read它也可能做一个write如果說很多人去做write的時候當然write它會有這個先後順序可是有時候它的先後順序即使兩個同時都要去做一個write都是同時，但是我們知道說在電腦裡面沒有所謂的這種同時這種事情。你同時，但是你一定會只有一個人搶到這個resource所以也就是說你兩個同時要去做一個write，

他一定還是會只有一個會搶到這個right的這個權限。另外一個當然就是要等到第一個right完之後第二個才能夠去做right我們講的這個是一個很極端的例子，就是說兩個同時要去做right。如果說每一個人其實他去做right，我們看起來好像幾乎都是同時，但是實際上他還是有先後順序有先後順序的話。他right

我們就必須要保持這樣子的一個先後順序。既然有這個先後順序的話呢我們就是要說我們read到底會read到誰它這邊就說read到最近寫進去的這個字而不是說read到很久以前寫進去的這個字那這樣子就沒有所謂的這個時效性。所以我們的定義呢它這邊有定義它有三個三個情況，所以我們來看一下說第一個呢

他必須要follow這三條第一個他說p write x然後這個p read x。我們就說這個都是p所以這是指同一個這個processor。他說他write到這個s那自己又去x這個地方做一個read這個時候他會read到誰呢他大概就是read到自己寫的這個X，它大概就是Read到這個字體寫的S，那當然這樣子它必須要怎麼樣它必須

要說這個PWriteX跟PReadX這兩個Action中間，它沒有其他的Write要對這個X做Write在它們這個中間它沒有其他的Write就沒有，所以也就是說對X而言P對它做Write完以後沒有人再對它做Write所以你 P 對它做 write 完之後呢當這個 P 在對它做 read 的時候，它就會 read 到剛剛寫進去的這一個值，所以它說它沒有其他的 write 參雜在這兩個Action 的這個中間不會說中間有一個Write 插進去然後要把它改變這個X 的這個值如果它沒有這種這樣子

差在中間的Write的話呢這個Read就是read到這個Write那這個其實它保證的是什麼東西？其實就保證我們一般我們的sequential program我們一般program sequential execution的時候我們不是都是這樣sequential這樣執行下來所以你前面先write那你後面再read它一定是read到前面Write的值對不對所以這個就是保證我們一般的program的一个order第二个它是不同的这个processor它說第一个P1 write X然后P2去read X我们说 P1 write X P2 read X这是两个不同一个P1

一个P2这边它有一个condition它说你这个P2不是P1 write完之后它马上就去读P2是等到足夠時間的間隔過去之後這個P2才去讀為什麼要說要足夠時間的間隔其實當然就是保證說我的P1的write已經完成了如果說你的P1的write還沒有完成另外一個P2馬上要去讀它當然讀不到所以這邊它說sufficiently later最主要就是要保證說我們的P1的write是complete它已經完成了

所以你保證已經完成的時候接著然後P2另外一個去讀它的時候我們就一定是保證說它一定P2一定是read到P1write的這個value就是這樣子所以它這邊舉的一個例子就是我們前面看到的就是這個我們說這個A它對它寫了一個1寫完之後有足夠時間的間隔過去之後那你這個b再

去read它應該read得到誰應該read得到1而不是0如果說你足夠時間過去以後你這個b去read同樣的這個location結果你read得到0這個就是錯的所以這個就是我們第二個第二個定義的就是它要保證保證說你一定可以讀到前面其他的人write complete完之後的這個result同學會不會覺得奇怪說為什麼第一個他沒有的人說，sufficiently later他為什麼沒有說你有足夠時間過去以後，然後你再去做一個read沒錯

我們這個阿羅小同學說對了，就是這個因為它是兩個，所以你兩個，它同時在進行的時候，你有可能它write的時候其他人它馬上就直接read可能就隔很多少時間它馬上就直接read，所以你這個one還沒有write complete的時候，其他人其實就已經去read，但是我們第一個，其實它是指同一個，所以它這邊沒有P1 P2，

它這邊都是P，所以你P，你沒有complete你的write當然不可能再去做一個read所以這個就是你write完之後，然後接著再去read這當然沒有問題，所以這邊是前面兩個第三個，它說P1 write location X P2Rise location x如果是這樣子的話，首先我們要確定的就是說這個location x它是被寫了兩次，一個是被P1， 一個是被P2假設P1 P2寫進去的值是不一樣的首先我們要確保的就是說這個location x最後存在x裡面的值一定是P2裡面的這個值，

它不會是說你在location X裡面最後的值是P1寫進去的那個值，那這個就不對了為什麼呢，因為我們剛剛提到write有它的sequence，在這裡面，我們看到是P1先write然後P2再 write我們不可能說這個先寫的值最後會留在裡面結果後面寫的人反而沒有辦法把它蓋掉這個顯然是錯誤的所以我們最後location x裡面

的value應該是P2另外其他的processor當它去access這個location x的時候它一直在access這個location x的時候它access到的這個值它change的order它也是先access到P1寫的值然後接著才access到P2它不可能先access到P2的值接著才去讀到P1的值這個是不可能的因為我們知道說它寫的順序是P1先寫 P2再寫所以它讀的時候它一定是會先讀到P1才會讀到P2它不可能先讀到P2然後再讀到P1所以同學要了解這樣子

的一個順序是很重要它不可能去reorder它的這個write的這個order它的這個write的這個order所以我們這边說coherence實际它就是要定義定義就是說它有這三个这样子的一个特质接着我們來看就是說我們提到這样子的三个property我們說它到底是如何來完成這样子的property我們這边提到所谓的coherence的protocol那什麼是Coherence的這個Protocol呢就是說我們基本上如果說它有很多個這個Cache那我們大概都是透過Bus us或者是這個Network然後去Access這個Cache然後就是說

它是透過這個Bus跟或者是Network那它也可以去Monitor透過這個Bus跟這個Network去Monitor，說現在到底有哪一些Demand現在有哪些頂面到底要去access哪一筆資料，它都可以知道這些事情要完成我們這樣子的這個coherence通常當然就是說第一個一定是我們會把這個data我們會把這個data migrate到我們的local cache裡面，我們不可能說所有的data全部都在這個shared memory裡面然後全部都在shared memory裡面去抓

同學只要有寫過這種像CUDA或者是其他這種Multiprocessor或者是像GPU類似這樣子的Environment我們都知道說就是說你如果是到那一種這個off-chip很大的那一種Global的這個Memory是XS的話，它的速度通常都會很慢最快的一定是要on-chip當然就是說像我們這邊提到的shared memory當然它有可能是on-chip的shared memory，但是我們如果要去reduce

它的bandwidth的話，你一定就是要把它放到你的local cache裡面去所以我們大概就是會有一個一份資料會有同時不同的copy在我們不同的local cache裡面所以這邊我們就會有一些protocol就是我們會監看說現在到底有哪一些資料有access到這筆資料這筆資料是在哪一個cache裡面他知道這些事情要做什麼呢我們首先來看一下說他知道這件事情

要幹嘛就是所謂的invalidating snooping protocol當他可以監看我們的access他access到哪一筆資料這筆資料在哪一個cache裡面他要做什麼事情呢Access如果只是Read的話大家都是在Read這個都沒有什麼事情他今天看了他是怕說是不是有人要做Write這件事情因為大家都已經把這一份資料Copy到自己的這個Local的Cache如果沒有人Write大家都是在Read這個時候Performance是最好的都不用Update

就是大家都一直在讀自己的local cache可是當有人要去update資料的時候這個就可能會出現我們剛剛看到的第一個example的這個問題就是這個A write他的cache然後write through也update他的這個memory但是B呢結果他讀到的是一個舊的資料那這樣子就錯掉了所以他要如何來避免這件事情呢？我們剛剛提到的他竟然會監看說到底有誰去access到

這筆資料他會要write的時候他就會送一個exclusive access什麼是exclusive access我現在要write我現在要write的話他會送一個exclusive accessexclusive access別人要read的時候就怎麼樣就沒有辦法read所以同學可以把這種exclusive access把它當成是有人要write的時候他送出去這個write它同時會把它要去write的這筆資料它如果有存在其他的local cache裡面那

些存在的local cache的那幾個copy全部都會被invalid都會變invalid都會變成它是無效的無效是什麼意思呢？變成無效以後，那一個processor它要去讀它的local cache它會得到什麼miss 对不对，同学应该还记得有个叫very bit有个very bit我要知道有没有资料在里面我首先要知道要check那个very bit很 bit如果是1的时候才表示有资料存到cache你very bit如果是0后面那些大概就不用check所以它指的就是指这样子首先要write的话它会把这笔资料它也同时存在其他的local cache

相關的那一些全部都會被invalidate那invalidate這樣就是保證怎麼樣呢保證別人要去read的時候它會變miss那你miss就怎麼樣呢就必須要從memory裡面去把它搬上來那把它搬上來當然就會把我們剛剛某一個processor它去write的那一個local cache也update到memory裡面的那個值然後順便就把它搬到各自的local cache所以它就是透過這樣子

所謂的invalidating snooping protocol的一個機制來確保說write的時候其他的read就會變missmiss強迫到memory去搬再搬進來就會搬到最新的值所以這個就是我們在這邊提到的一個coherence這樣子的一個機制所以這邊它列出來的這個Table我們說CPU A Read X這個時候是Cache Miss因為它原本裡面是什麼都沒有所以這邊就讀了一個0然後CPU B Read X所以這邊對B它的這個Cache它也是一個Miss接著CPU A Write 1 to X這個時候它是一個Write Hit

因為它的Data就在它的Local Cache它就把這個E寫到它的Local Cache寫到Local Cache之後如果說它是Write-through這個E它也會被Update到它的Memory這個時候你的CPUB你去做一個ReadRead的時候它就會變成一個Cache Miss因為它的這個WriteCPUA的Write它會去Invalidate其他這筆資料在其他的Local Cache裡面

它會變成invalid所以它去read的時候就變一個missmiss的時候它就會去updateupdate成一個one所以這個就是我們提到這樣子的一個機制接著我們要來看另外一個叫memory的consistence我們剛剛提到一個是coherence另外一個是consistenceconsistence它指的是指什麼呢它指的就是指說你这个write什么时

候会被其他的processor所看到你write什么时候会被其他processor看到当然看这个是一个很笼统的字眼看是我们人在看所以到底什么叫看呢看的意思这边就提到说其实就是说你一个read我要去读同样刚刚被write的那个location我去read的时候它会return這個被寫進去的這個紙而不是舊的那個紙當然

我們前面提到的你寫的時候不可能說我寫馬上去讀他馬上就讀到他新的這個紙所以他不可能說是瞬間立即他寫然後馬上就讀出來他必須要有一個適當的一個時間的間隔他去讀的時候他這個時候就保證他就一定會讀到他要的這個紙這個consistence就是說我們這邊有提到說它有兩個這個assumption第一個說一個write complete它說一個write complete它complete的condition就是說是所有的processor都看到它看到當然就是說

所有的processor去讀的時候都會讀到這個write value被寫進去的這個字這樣子這個才是所謂的complete另外一個就是一個processor它不會reorder就是不會reorder write它的意思就是說你A B C D然後它寫的順序是A B C D這樣子寫你在讀的時候你在讀資料出來你應該就是讀A B C D而不是說會讀BADC這樣子的一個order這樣子當然是錯的所以你寫的時候一定就是這樣子

的一個寫所以說我們在寫的時候我們在寫的時候通常大概都是會serialize這個right就是說假設你有一個right就很多right的一個demand進來我們當然不可能同時把所有的 write 頂面全部都 complete因為你，如果要寫同一個位置，那有很多人都要 write，那就是大概就是按部就班先拿到這個write，這個 write 是權力的write，他拿到這個 access 的這個write，那他就可以去寫那他如果沒有拿到的話，他就必須要等前面一個 write complete 之後呢，那才會輪到他

再輪到下一個拿到這個resource update resource的權利它才能夠再去寫所以它一定是一個serious的一個operation即使你demand這樣很多的demandconcurrent demand進來，它還是要serious這個write那serialize這個write之後你去read的時候，它就是這個serial write它的一個order它是這樣子會循著這個順序讀出來所以這個是一個很重要，就是我們剛剛提到一個很重要的一個原則所以我們說另外這邊還有一個，就是說

他提到，就是說假設，就是說我們根據我們剛剛前面這樣子的assumption，我們說這個p假設他寫到location x然後他也寫到location y這是然後就是他先寫一個value寫到location x接著他再做一個write寫到這個location y如果說這個processor其他processor他都看到了這個write他都看到了在location y的新的這個值這個時候你絕對不可能說有某一個processor他舉手說我只看到y的新的值我沒有看到x新的值

它不可能它不可能這樣子它一定是它如果每個人都看到y新的子那它一定就都一定會看到x寫進去的新的子為什麼因為這個就是我們前面定義的這個complete還有order一個complete一個order因為在這裡面我們的write的order它是先寫x再寫y所以suppose應該是complete x之後再complete y對不對那它既

然已經complete x的right就表示什麼呢所有的processor都可以看到x的new value不可能有人沒看到x的new value看到y的new value那就表示說你x沒有complete你先complete y那你的order就錯掉了所以他這邊描述的就是在強調我們這邊這兩點這邊同學的重點就是我們提到的他先complete x所以大家都看到它了然後接著再complete y所以如果說所以這邊講說如果大家都看到y了新的y就表示y已經complete那y complete x也一定就complete因為這是它的順序

它也一定都會看到新的x所以這個就是我們這邊提到的，就是在consistence這邊，它有兩個這個sumption。其實我們在做這個，就是multicode或者是像那個GPUminicode，它的這一種pair。我們把一個serial的這個algorithm，你想办法把它变成一个paralgorithm，然后把它搬到这样子的平台去run。其实它的performance，实最主要最主要的问题都是在memory的这个access都是在memory access，这个根据就是我们以前我们做过的这个研究，就是我学生他们发现他们发现说

像這樣子的一個Memory Access其中有一個就是有幾個重點比如說有一個叫Risk Condition這個大家可能應該都已經知道Risk Condition，就是你有就是有同樣的一個Location有人要Read 有人要Write就是像我們剛剛提到的其實這個並不是什麼問題這并不是什麼問題這不是說這是不能解的一個問題有人要Read 人要Write你要如

何去達到這樣coherence跟consistency可是問題是你只要碰到這種risk condition的話它整個這個parer的這個performance它都會下降你如果說在你的整個operation的過程裡面這種risk condition是發生的很嚴重那你跑到最後你搞不好沒有多少的speed up搞不好甚至有可能會比那個sequential還要慢也說不定所以第一個就是說你平行化的時候你

最重要的就是你能夠避免掉risk condition你就盡量避免你不要說我們那個我記得以前都有提過Hardware software都有support都可以解這種問題所以就讓他去吧讓他自己去解那你如果一直讓它發生這種Risk Condition的話那其實就是等於是有很多Thread它可能都Idle在那邊它就Idle在那邊等因為它Idle在那邊等它的Risk Condition才

有可能被解掉所以你盡量能夠不讓它發生Risk Condition就盡量不要有Risk Condition那這個也就是你要Paralyze能夠成功的其中的一個Point你如果沒有辦法避免掉這個的話你的Performance大概絕大部分都已經被消磨掉了第二個呢當然我們知道說譬如說你如果用GPU的話你是從這個CPU然後搬到這個GPU裡面去那你如

果說就是我們剛剛提到的你的Global Memory或者是你的這個Local Memory那你的Local的Shared Memory如果資料都可以放到裡面去的話，這樣速度當然是最快可是問題是我們知道說以GPU而言它的這個它的这个processor的數目也還蛮多的那它的每一个可以放的这个shared memory的數據量当然就没有那么大的所以你不可能把

所有的这个你的所有的数据全部都搬到你的shared memory所以你如何有效的去把数据做这个partition然后尽量减少搬进搬出搬进搬出你可以minimize你的这种in out的这个number的话呢你也可以提升你的Speed Up另外還有一個大家比較少注意到的就是這個也是跟我們這個Chapter有關係的我們不是在講說Cache其實就是一個一個Block搬對不對你一個一個Block搬我們知道說如果說我要Access的資料你這個Block搬進來以後我大部分不知道

大部分我最近這一段時間在Access的資料都在這個Block那至少保證我這一段時間裡面我的效能都是最好的那我這段時間這些Data都用的差不多了然後我需要再一個新的Block資料那你就一個Miss來一個Miss沒有關係本來就是要Miss你第一次Access一定要Miss那Miss再抓進來以後又大部分的数据都在這個Block那其實我們一般在寫這個Sequential Program的時候一般都不會注意這種事情因為

不會想到這些機制當然如果說你寫Program都要知道你Data什麼時候被Access那也是很累人的事情但是如果是在做這種譬如說你GPU跟CPU之間我們要盡量減少它的Data的這種In-Out你要一筆資料進來大部分要能夠Mathemize它的Utilization這個就很重要譬如說我們如果宣告一個2D的Array那你2D的Array那你的data你到底是row-based的access還是column-based的一個access舉例而言我們先不要談這個row-based current-based舉例而言就是說我們的

資料如果是2D比如說X1 Y1 S2 Y2所以我們每一次做operation的時候我們一定是X1搭配Y1 S2是搭配Y2因為它們是一組資料它們是兩個Data配在一起才是一筆有意義的資料所以你在存這個S1 Y1 S2 Y2的時候那你就要小心就是說你存的時候你可能就不要存S1 S2 S3 S4這樣子存完以後再存Y1 Y2 Y3 Y4這樣子存因為你這樣存的時候你抓一個block進來的時候你可能是抓X那你抓X的時候你要讀X1跟Y1

結果 Y 就不在裡面那你就等於你要你會 miss 兩次那你如果是把 S1 跟 Y1存在相鄰的地方那你這樣子 XS 的時候它一次就全部進來所以你就要 S1 Y1然後 S2 Y2S3 Y3你就同時你的資料保證你怎麼去做的時候都會抓到你要的單一筆資料不要小看這個差很多當你做Terror的時候

這個東西這種小地方就會差很多我們來看這張圖這個是Intel Nethelen 4 Quad-Code的一個Processor它這邊是一個Level 3這邊我們看到的是它有三個Level兩個Level是包在裡面然後這邊是Level 3的這個Cache這個我想同學會去自己看一下對照一下他的spec這個沒有什麼他就只是把spec list

出來讓大家看而已他這邊是有提到說像這個Intel AMD他們會reduce他們的miss penalty這個少一個s miss penalty其實有幾種方式第一種就是說比如說第一個我們不要就是說我miss我就趕快去把那個block就把它抓進來因為我們知道說其實它一個block如果比較大的時候你抓一個block跟抓一個word它的時間是不一樣的既然時間不一樣的話我們要爭取時間我們是希望說我們現在這一個要用的這個word趕快抓進來

趕快用其他的它在用的時候你後面可以慢慢再抓所以它說return requested word first我們要用的那個 word 先進來進來之後接著再把其他的再把它填滿其他的就是其他你 block 剩下的所以就是先抓我們要的那個 word這樣子你 access我們前面不是有提到我們前面不是有看到好像有三種機制對不對它一次可能一次就抓一個 word那你如果要四個 word 你要抓四次

它的送回CPU那邊它的bandwidth假設也是一次只能送一個word你如果要四個word你就要分四次送有的機制它是一次可以抓四個word一次送四個word有的是一次抓四個word然後sequentially送四次我們前面有提到這三個所以那些就是說就是說雖然有那些的幫助但是我們先把要的這個work抓過來 抓回來這樣子是比較好的第二個

他說non-blocking missed processing那什麼是non-blocking missed processing呢它指的就是說譬如說我們如果說有一個cache missed那我們可能這個cache我們根據我們前面的這個final state machine同學還記得final state machine它只要miss它怎麼樣呢它miss以後它的state就到其他地方去做了對不對它要嘛就是去把資料讀回來要嘛它要先

update把它writeback先寫回去寫回去之後再去讀它要的這個block然後這個Final State Machine它下面的read跟write全部做完了它才會回到前面去idle說它已經ready了同學應該還記得我們上次提到的那個Final State Machine那這種呢當然就是所謂的這個blocking你只要有一个miss你必须要把它前面把后面的那些operation全部都做完就这个

你只要miss的话它在这边做完做完它才会回去它说其实可以不需要用blocking的机制它就是non-blockingnon-blocking意思就是说你都已经miss了所以你miss了你可能已经在处理miss的情况但是它还可以允许他可以允许下一个access他下一个access他可能就hit所以你miss的同时他可能也有另外一个hit发生所以另外一种情况

就是说他可以允许miss用miss因为他已经miss他已经miss他在处理他前一个miss他前一个miss他没有处理完他后面他可以允许他后面再来一个access那access如果好的话就是什么就是hit那如果不好的话呢又是倒楣就是再一個miss iss再一個miss它就是允許multiplemultiple outstanding miss這不是傑出的它是還

沒有完成的就是還沒有完成的miss所以它可以允許這種multipleincomplete的一個misses所以這個就是你不要把這個cache把它design成這種blocking的type它就是一個non-blocking這樣子也可以reduce我們的miss penalty它等於是隱藏了它的latency對不對因為它兩個它可以把它double在一起那接著它有

說它how well can prefetch那這個就是我們前面就是大概有類似反正可以先讀這個資料那尤其是如果說比如說它要讀的data是array它是一個array那array的話呢suppose我們在用array大概常常都是用到一個for loop所以你一個for loop裡面即使沒有把整個array traverse完大概也就是local array的local的某一段落的這個data這樣都把它抓出來所以你第一筆array access之後呢即使你就第一筆定下去的那一筆資料往後的幾筆資料你可以

同時都把它抓過來那這種就是所謂的這種prefetch那這樣子的話呢當然都可以幫助我們的miss的penalty最後我們來看一些陷阱這是列了幾個同學大家要注意的其實這邊大概也就是第一個就是byte addressing還有word addressing因為我們前面提到的都是byte addressing這邊用了一個例子他說我們如果有32個byte的direct map cache這個direct map cache它的case size是32個byte它的block size是4個byte所以它有很多個block每一個block是4個byte從這邊來看的話我們大概就知道說我們的32/

32除以4我們就可以知道說它總共有8個block從這邊我們就知道它是8個block8個block接著他就問byte 36map到哪一個block，word 36map到哪一個block同學不要急著叫byte word全部都把它寫block 1這樣子大概就是對了一個我們知道說這邊其實就是review一下前面的觀念而已我們知道說這byte address是36我們首先要先把36 byte把它轉成是一個block block address那怎麼轉呢當然就是第一個是36然後它的block是4個byte就是9所以你轉成block address就是9那9再去module你的block number

那9 module你的block number是module 8我們就會得到一個語數是1所以這個就是表示它對應到block number 1那如果是word它一個word本身就已經是4個byte本身就已經是4個byte所以word 36所以其實這個word 36它也就代表了它是一個block address它不是byte address所以36你就直接去module你的这个block numberblock number是多少8

个block我们这边8个block所以你36 module的8呢我们就会得到得到这一个4我们就会得到4那第二个例子呢它说256256 byte的这个cachecache size256 byte那它说它的block呢是32个每一個block是32個byte所以我們知道說它總共有幾個block這邊也是8 對不對這邊也是8這邊也是8所以呢 它說byte

的addressbyte的address 300它會make到哪一個block那又跟前面一樣其實這個問題跟這個問題一樣只是把數據換一下而已所以你300呢首先你要把byte的address變成block address所以我們就是300除以多少除以多少，同學要講一下300要除以多少會變成block edges猜一下， 不然實在是凹不下去了不是你看每一個block

有幾個byte 對不對我們這邊byte address你要把它轉成block address不就是要除以你一個block有幾個byte它就會轉成它的block address所以是多少，它說32個byte per block，所以就是要除以32就好像在這個例子裡面它是4個bytesper block這邊是32個bytesper block，所以300除以32它會得到多少大概是9，所以你9 module 8它還是一樣得到這個number 1就會得到這樣子的一個結果，所以這個只是跟同學強調說同學不要一拿來就把投影片前面的方法就開始算然後都沒有去管它到底是

byte address 還是 word address它們中間隱藏的意義其實是不一樣的，那第二個呢，第二個他提到的就是這些實同學都知道了，就是我們說我們在就是在做 write 的時候或者是說你做 access 的時候，那我們的這個 array你存到 memory 裡面到底是到底是row還是column、row base還是column base那你row base跟column base的這種儲存方式呢，實就決定了你在access你array的時候呢你到底是我們說這個2D的array那xij會說你到底是要for i等於0然後for j等於0這樣子的兩個native loop

還是要for j等於0 for i等於0剛開始寫的時候大家都會覺得這一樣當然一樣這結果當然一樣因為你只是把這個ij對調而已但是實際上如果說我們的我們知道說memory它儲存Array的這個方式rowBase假設它是rowBase它是row先存的話其實我們就要讓我們的Array的access就是要用row的這種

循序的方式去Access一個RowAccess完之後再Access第二個Row再Access第三個Row這樣子才會是跟我們在Cache儲存的機制是一樣的因為它一次抓一個Block連續的位置一抓過來它是先把一個Row抓過來當然它不一定一次抓一個Row如果說你這個Row抓完它連續的它就跳到下一個Row就是這樣子抓所以我們要了解這個是有關聯的

並不是沒有關聯那第二個呢第二個其實他要談的就是說我們的這個我們的這個 multiprocessor我們說我們會有share的這種這個cache那我們知道說我們cache的這個access我們不是有這個set associative就是說定義到一個set裡面，那它的associativity的這個number決定說我這個block對應到這個set之後，它可以擺的位置

到底有多少個。它如果是two-way的話，我們對應到這個set裡面只有兩個位置可以擺，你兩個被人家佔滿了，它就必須要把一個剔掉下一個才能進來所以我們知道說我們的associativity，如果越高的話，我們可以讓進到set裡面它的競爭的激烈度降低，就會避免進到一個set裡面的很快就被後面要進到這個set

的block把它踢掉。所以它進到一個set可以待比較久。我們知道說提高associativity就是這個用意。如果是這樣子的話，我們當然就知道說當我們如果扣數目越多的時候，實際上我們不應該是去降低它的associativity，我是應該要提高associativity為什麼說比較多的code是應該要去提高associativity，因為比較多的code，我們說一個最極端的例子就是說，如果有四個code，那quadcode這四個code，它同時都去它同時就是說都做了一個access，它同時都做了一個access，

比如說，它假設四個code都做了四個不同location的access，但是這四個不同location的access結果，它都對應到cache的同一個set，cache的同一個set它說它是share，它是share這個比如說L2或L3的cache它既然是share cache的話，它對應到同一個set就表示說它四個不同的block必須要搬到同一個set裡面去。如果說這個set它的associativity只有2的話，

它會怎麼樣就是一個進來第二個進來結果屁股還沒有做熱後面第三個進來就有一個要出去然後第四個進來又有一個人要出去。所以，associativity如果數目太少的話，你們call number數目比較多那你都發生到同時access都對應到同一個set就會這麼慘。所以，他這邊就講說，如果你的code數目比較多的話，我們應該是要去增加associativity這樣子才能夠避免當你同時要搬不同location然後都對應到同一個set的時候，

這些資料它才不會有conflict就是因為associativity數目少而有這種conflict的現象。另外一個就是說，我們前面有跟同學提到Average Memory Access TimeAM AT它可以去evaluate，就是我們的這個Memory的這個Performance可是就是說，我們這個東西並沒有辦法說好像你可以去評估它。 valuate這樣子的Performance你要拿這個去evaluate out of order processor或者是說那一種比如說像

non-blocking它不是block它是non-blocking的這個access那這樣會發生什麼事情呢因為我們前面提到non-blocking是它如果有一個miss它除了處理這個miss的後續的事情之外它還可以繼續允許它access它可能miss的處理miss的過程當中它又發生了一個hit它有可能又倒楣又發生了一個miss它有overlap對不對 它有 overlap那既然有 overlap 的話呢其實你用這一種 average memory access time這個去算它的 performance

的話呢其實這個是不準的 它是不準那既然不準的話呢 怎麼辦呢你如果不準 你要去 evaluate 這個 performance你要允許這種 non-blocking 的 access那你大概就是只能透過 simulation simulation 可以解決這一類的問題因為這個東西呢是假設我們剛剛提到的你一個Cache的Access他Complete下一個Access才會過去一個Access Complete他就 Ready換下一個過去miss他就等待他都已經處理完了他就Ready下一個再過去這樣子的一個Model才能夠應用我們前面提到的這種AMAT的方式去算。如果不是的話，你這樣算是不準。必須透過simulation的方式。我們今天就上到這裡.