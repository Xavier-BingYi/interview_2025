undefined
好，那我們今天要比較快地把第五章講完然後進到最重要的第六章。好，那我們上次講到的是這一章的前半段，都是講軟體的——OS啦！ OS Level還是Software Level的Scheduling，所以有什麼Shortest Job等等的這些Scheduling Algorithms，但是大家不要忘記，在Hardware Level其實在CPU或者說在整個主機Computer SystemModel Board這邊，它在運作的時候Hardware Level也有它的Scheduling，這個Decision存在所以其實是分兩層的。那上次我們提到比較重要的部分，應該是

在Processor這邊，其實Scheduling的問題很多，不是只是CPU這件事而已其實還有跟你的Memory Access還有Cache整個系統的運作有很大的關聯性，所以就提到第一個很重要的是這個Affinity的概念，我們很早就提過它的定義就是我們可以把Process執行序，把它給Pinned在或是Bind的到一個特定的Processor或是Processor的Core上面那為什麼要這麼

做？咧最主要的原因就是可以去reuse增加它的cached的熱率，因為其實不同的processor它的cached通常是不share的，就是不共用的對不對，所以我們說，如果有affinity的話，實會影響到schedule的decision可是，它的目的就是希望可以藉此增加你的這個cache line的reuse rate，那你跑起来速度就會更快毕竟cache又比main memory要快對不對所以，有這個affinity這個動作，那另外一個也跟scheduling跟memory access也是息息相關的，就是我們也介紹過了，實際我們的computer architecture在memory architecture上

其實有分成NUMA跟UMA兩種對不對就是它的Memory Access Time是Uniform或是Non-Uniform那我們說，通常Scale比較大比較Powerful的Computer System的話比較多的Processor就會採用這種NUMA，就是Non-Uniform因為它的Memory也可以有Hierarchy大家有一點遺忘的話可能要回去再看一下我們在應該是Chapter 1或Introduction的時候有介紹過，那重點就是你在不同的CPU去access你的memory

根據你的memory是放在你的memory controller ent是放在哪一個memory chip上，它的速度其實是不一樣的，所以在這個情況下你在schedule你的process的時候，你就會希望把它schedule在跟你的memory是相同的位置，這樣子你的memory的access time才會比較短畢竟memory一旦create好對不對一旦被create了之後，它就當然就在那個地方因為，如果你要去migrate你的data，這是cost是比較高的很花時間的嘛，因為在做memory copy對不對可是，processed scheduling本來就是我們知道它每一次這個我們的

OS都可以做rescheduling對不對periodically，你都可以只要有空的core你都可以run那，所以說，如果你的Memory在這邊當初在這邊Create的話，那之後你可能也會希望放在同一個這個Processor上，那這樣你的Memory Access才可以比較的短，所以，在這種NUMA架構下其實，在寫Driver Programming的時候，也是一樣都可以透過一些Flag去給OS或者Computer System一些Hint要求它，你比如說，Memory Location一定要在Local的或者是，

就用剛剛的Affinity的概念你就會把它綁在不一定要同一個Core 可是至少要同一個CPU所以在NUMA 如果大家回去再看的話就會注意到所謂的NUMA是以CPU為單位然後它會有比較近的這個Memory的Chip所以這個CPU上可能就有好幾個CoreRUN在哪一個無所謂因為它們都可以assess到同一個Memory Dank

所以其實這個NUMA Architecture這個對這個Process Scheduling影響也是有存在的也是會嚴重的影響你的執行的效能所以你也看到了就是因為有這種Memory或Data Locality的事情所以說有時候使用者是會想要把它指定在某一個Processor上的但它的tradeofflet就是low balancing就是大家稍微aware就好可以想見的因

為如果你當初因為你當初一開始說prospect schedule在哪一個CPU或是Core上可能就是random你決定的可是一旦在那邊run了你可能就create了data就開始有你的cache那你之後就可能想要綁在上面可是這樣的結果就變成那個Processor或是那個CPU它的loading或是在上面想要執行的process的數量可能

就比別人多啊那自然你的wait time就會久對不對那就是不balance，所以這個locality data access的這邊跟你的整個overall系統的low balancing往往就是一個trade off，那低 balance這邊只是很概要的講，所以這是大家知道啦，就是其實在我們的尤其在hardware levelinternally，一顆CPU它通常一定都會implement一些low balancing的機制，然後讓每一個core可以有差不多的直行的loading，這樣才可以減少大家的wait time那，它怎麼做load balancing呢？我們通常就是會把它分成所謂的push跟pull，那這只是定義啦，所以說push的定義，你可以

看見就是說從loading比較重的人把它push到loading比較輕的，這個我們通稱為所謂的push，也就是你migrate嘛，一定是從高的一個process從loading高到loading低，所以如果是從高到低的，那個高的人主動去通知低的人說我要把我的工作丟給你這就叫push，這樣我就把東西push給你就對了，這個就叫push的model，因為migrate的過程一定有一個source一個destination，所以這兩個人，他們是誰先initiate

這個動作就會分成我們這邊說的兩個Model，那如果是Loading高的人先Initiate他主動的說我要把我的Load交給別人的話，我們就稱之為Push那Pull就是反過來對不對，所以就是Loading低的人，他發現他自己的可能他已經Cue裡面空掉了或甚至於甚至已經到Idle了，那他想要當然知道他就看有沒有人有多的工作可以讓我做對不對，所以他就叫Pull，就是拉過來把工作拉過來

esso這兩個結果其實是一樣，差別只是在有一點implementation上或是design上的差別就是push是從高的人loading高的人先initiate這個動作migration的動作那pull是反過來的，那這兩個差別實際上到底你會怎麼選呢？其實是有一個條件的，就是看你整個系統的loading到底是高還是低，因為你會想到migration他一定要兩個人都同意，就是

一個人loading高一個人loading低嘛然後才會成立這個migration的動作，那每一次的再詢問都是浪費時間的所以其實initial為什麼重要，因為你希望initial的人不要太多不要在wrong time在每一個process每一個processor都說我要做migration然後結果是其實大家 loading都很高不能做migration那就變成浪費時間的一些overhead存在所以結論就是如果

整個系統loading都很高的話那代表什麼意思代表很少人loading低所以很少人loading低的意思就是我們會希望用pool的model因為pool的model說loading低的人去initiate這個動作所以我們就變成少一點的人真的是覺得loading低的人他才会去trigger这个event。如果你用loading很高的然后你用一个push每一个人都说要push結果事实上loading

低的人就只有那几个他们要去找到那些人就很浪費時間對不对所以在loading高的时候我們通常就喜欢implement pool的migration反过来整个系统overall系统loading很低就是大部分的人都没什么工作的话我们就会implement push的model所以只有很少数的人会trigger这个migration的event所以这个是实作上的选择其实是有一个基本的概

念存在就是loading高我们就用pull，loading低我們就用push那這只是migration在实现上面就是兩種選擇然后會看基于系统的特性去做一个比较适合的选择尽量目的就是减少在migration的时候你要去找到適合migrator的對象的那個問題好所以這招知道就好啦，所以比較重要的是affinity還有uma為什麼我們process必須要去bind到某些特定的位置那它的contradict就是這個low balancing上它其實就會比较差所以這兩個其實是有一個tradeoff的存在好那

接下來我們就再進去更深一點，在單一顆CPU可是我們知道一顆CPU它可能就有這個就有這個Multiple Core的存在對不对，那這種系統也是非常常見的我們知道現在基本上都是多核心的CPU了對不对，那在這一層Level上面，在Scheduling上甚至於是單一顆核心一個Core裡面然後你要執行很多個Thread的話，這種更Low Level的時候它要再考慮另外一個問題

就是Memory Store所以大家如果修過了Computer Architecture的時候就知道一點概念知道我們其實在一個Instruction執行的時候是分成好幾個Cycle的對不对，那其中有一個很重要的是去Access的Memory這件事情，但是當你是把是把這個一個單一CPU就有好幾個Core或者一個Core裡面你就想要執行很多Thread的時候它的這個Memory Bus其實是Shared的所以說

不同的instruction有可能它就會撞到它的memory cycle就可能撞到這個memory bus有一個collision那就會有一個store的這個狀況產生，所以就會有這個memory store。意思就是說當有memory store產生的時候，其實我們的CPU，它是沒有在執行instruction的，其實是卡在memory的IO這一塊，所以說就会有我们现在的这种Technology像是Hyper-Threading在Intel的CPU里面或者是到

了GPU在越来越popular的这些Graphic Card或计算上它都会跟你讲说一个Core我就可以有好几个这个Hardware Thread可能可以到10或甚至以上的数量，那为什么可以做到这件事情就为什么你可以有很多的Thread同时在一个Core上面执行速度卻不會變慢就是因為你去utilize這些memory stored的空間，所以這個也是一個scheduling的問題，這當然一定是在hardware level對不对，所以怎麼樣

子在利用這memory stored的空間去schedule另外一個thread插進來這個也是hardware level這邊的scheduling的事情，所以概念上就像這邊看見的。如果我們可以overlap對執行跟Memory的這個Cycle的話，我就有機會塞進兩個Thread，甚至於我可以如果增加一些其他的Register，有可能就像我們說GPU這種比較Specialized的Hardware，它甚至於可以塞進更多的Thread同時執行然後不影響它的執行時間，所以這也只是讓大家稍微知道就好就是Hardware Level這邊一些跟Scheduling相關的

那在剛剛像那樣子的一種technique的這種做法來講，它會有一個基本的簡單的區分，就是畢竟你會我們知道這是Hardware level的Pipeline嘛對不对，所以這已經是到了一個instruction執行Pipeline的過程，那所以說你就會有一個問題是有可能你會有Branch的這種事情會發生对不对，所以Copyright execution也有交互，所以這種時候你甚至有可

能要換掉一些instruction，所以在這邊呢基本上就會分成兩種不同level的怎麼樣去把它flush掉這個pipeline的做法，這個跟我兒子稍微關鍵性少一點，所以大家稍微知道就好，所以會分成所謂的gross-grained跟fine-grained，所以gross-grained意思就是說我會把整個這個我的pipeline給它flush掉，這就是所謂的gross-grained的做法；那如果FindGrain的做法就是因為當

你碰到MemoryStore你就想要換成等於是一個非常在Hardware Level在做Context Switch的事情對不对，所以當你碰到MemoryStore的時候，我想要換到另外一個執行區的時候所謂的FindGrain的做法就是把這些Pipeline上的State全部保留保留的方式當然就是增加RegisterHardware Register所以你就把它Switch到這些Hardware Register上然後讓另外一個人在做執行這就是我們俗稱的fine-grained；所以簡單講說cross-grained它會flush我們的pipeline啦也有這個memory store產生那我們

就換另外一個人去做執行那如果是fine-grained的話我們就保留它在pipeline的state然後去執行沒有memory store的那個thread的執令所以我們提到了滿多相關的你可以看見都跟scheduling有關，但是其實這些我們剛才提的呢就是比較在 hardware level了，所以重點就是說整個 computer system 來講，你會有 software level就是我們 OS 這邊它會去管理這個 process在我們 OS 的 ready queue 的順序然後呢可是到了 hardware level其實還有很多的 scheduling 的存在，那這塊當然我們都是已經依賴到就是 processor 啊或者是 CPU

在製作的時候，他會把這些Hardware Level Scheduling直接做進去了，那對於OS而言他care的可能就只是我現在有多少或者說下面的Hardware跟他講我現在有多少可以執行的Process然後順序是什麼，所以這個是OS這邊負責的好 那接下来我們最后会也会顺便提到比较重要的就是Real Time的Scheduling所以我們之前介绍一些OS的

Scheduling都是用Wait Time或者是这种整个系统的角度，但是其实我们说过有一类型非常特殊的这种Application就是所谓的Real Time的Application，那Real Time的定义再提醒大家一次就是指說必须要在Date Line之前完成那件事情，這叫所謂的 real time而不是越快越好，而是重點是有一個 deadline，所以跟一般的 scheduling 問題不太一樣有一般 scheduling 我們不會知道 deadline 對不對可是 real time 的呢它一定會給你一個 deadline然後目的就是要在那個之前做完那我們之前也介紹過就會有分成所謂的 soft

跟 hard 對不對所以 soft 就是盡量去避免 miss deadline 的事情那 hard 就是指你必須要有一套 algorithm scheduling algorithm它可以 guarantee所以是更嚴謹的那當然這為什麼會有 soft 跟 hard 的差別當然就是你的應用上差別對不對所以一般的這種 media streaming就沒差所以你會看見有時候影像有時候非常清楚的時候不太清楚但是它會盡量的對不對讓你可以看得見它的這個圖

但是hard呢其實應用非常廣泛就是大部分的control system都是hard像是汽車對不對我們說武器或者是核電廠的東西這些當然這些系統都是非常非常重要的對不對你只要一個錯誤你只要 miss the deadline代表意義是就是你可能會有車禍你的車子可能就沒有辦法控制或者是你設的目標就會設偏離那都是很嚴重的所以這些都是所謂的 hard real time的

application好那這一類的問題其實是有很general的方式去描述它的所以對於所謂的real time的這種application它的scheduling的問題我們都會用三個tuple這個tuple裡面有三個這個這個parameter來去描述它第一個是一個ready就像一般的工作我們之前有看到的就是ready time什麼時候這一個Process開始進段

我們的系統開始做執行這部分是一樣的然後有Execution所以Execution就像我們之前看到的CPU Burst是一樣的所以就是它每一次要執行一個CPU Burst它的這個Burst Time是多少那第三個就是Real Time才特別會用的就是Period其實你也可以把它想成就是所謂的Date Line意思就是說多少時間我會

下一次的CPU burst會產生所以對於real-time job而言他要能夠保證他miss deadline的話其實就代表這種job必須要很有規律性根本沒有規律性那基本上你也沒辦法做任何的scheduling因為預測錯誤可能就已經miss deadline所以在這邊的話跟之前不同的是我們的CPU Burst一定會重複的出現而且是假

設它會非常有規律的就是每一次出現每一個Period比如說我們後面這個例子10那就是每10個Time Unit它會出現一次一個Burst然後每一次Burst裡面會有4個Time Unit必須要執行完4個Time Unit那每一次你就是必須要在下一次Burst來之前我要把這件事情做完所以我們的秒數就會像這個樣子好nnScheduled algorithm我們說過因為hard其實是更難的所以realtime其實有非常多的研究然後當然要為了要保證deadlinealgorithm可能會變得非常非常的

複雜而且你可以看見很多可能是theoretic的去分析對不對因為你知道它的pattern等等那我們這邊會介紹的就只能是用在soft的realtime也就是盡量去滿足它的deadline那很常见的两个基本的做法第一个叫做ray monotonic那它的特色就是它是一个其实就是一个static的priority scheduling也就是说它会固定每一个process它的顺序based on什么呢它的period对不对所以就是多快它会有下一个arrival的这个CPU burst那越短的就有点像各位写作一样越短的你可能就觉得它比较

時間給你這個時間越短的通常就代表越急的所以我們就讓他先做那這是一個 static 的 algorithm因為你可以看見他的 priority based on 是 periodperiod 是一個 given 的 constant所以代表他是不會變動的在 runtime 的時候那这个就是有名的所谓的rate monotonic所以rate嘛就是那个periodmonotonic意思就是说我把它sort的时候它就是non

-decreasing就是单一性的就是period越来越长的就是越来越慢就对了另外一个咧更常被用到的它是所谓的dynamic的scheduling的方式叫做earliest deadline firstEDF這個 algorithm 是大家最熟悉的因為各位寫作業我相信都用這個 algorithm 對不對看看 deadline 哪一天剩下三天了我就趕快先做再說因為假設做不完就 fail任何一個作業都是非常 critical 的 對不對那當然是 deadline 最近的我趕快做有時候 period 很長不代表它的 deadline 是最近

因为就像很多作业我们很早announce大家就放在那里了对不对等到发现的时候哇只剩两天来不及了那先做所以这两个是没有关联性的所以Dateline是Depends on目前的状态谁是下一个要Due的工作我就打算先做这就是有名的EDF所以这其实是一个Dynamic Priority Algorithm可以看见跟刚刚的差别

那另外也很有趣的是這個Operation其實可以被Proof去證明說這樣的Operation最少它可以滿足百分之多少的Date Line的Job就是你的Missed Date Line Rate最高最高不會超過多少其實是可以被反而是可以被證明出來的因為它這個其實你可以看見它是一定可以把它Model成一個數學的問題所以EDF其實

並不是一個很糟的 algorithm 事實上是一個蠻不錯的 algorithm而且它有一些 theoretical 的棒在那邊但是它不可能保證不會 miss the line 還是有可能的所以這兩個 algorithm 我們就稍微介紹一下Raymoniconic 所以這邊我們直接看例子就可以了重點就是它其實是一個 fix priority 的 algorithm那就像這邊的這個例子這個arrival time沒寫反正就從零開始啦簡單嘛然後每次這個三個tuple每個這個tuple裡面三個每次大家自己要注意像剛剛前面我們是先寫execution再period

但这边的例子我们先写period再写execution所以稍微仔细看一下当然period一定是比execution长啦对不对所以如果execution大于period那当然missed deadline这没有意义所以这边就假设我们有三个所以这每四个time unit会来一次然后每一次我只要执行一个单位就好那就是五个会来一次可是我每次要执行两个那最后一个是20跟5

那based on這個definition我們就要給一個priority那based on他就是他的period所以我們知道period這三個人剛好就是四五跟二十嘛所以越短越閒所以就代表T1大於T2大於T3好那決定了priority之後其實我們接下來這個algorithm的做法就跟priority scheduling是完全相同也就是我們就先看對不對誰的priority最高T1嘛

第一個 task 排列最高可是它只要一個執行單位所以就執行一秒一個 time unit 就結束了下一個該誰當然是 T2 囉不要忘記一樣我們就只有 ready queue 裡面的所以 T1 這個執行完就代表 4 這一個所以我們下面剛好把它 mark 起來每個顏色就代表那個 task arrive 所以在 4 之前紅色我們做完它就是不會在 ready queue 出現

那所以現在Q裡面剩下的應該就是橘色跟綠色那橘色先嘛對不對T2先所以當然我們就先執行它那就是兩個單位然後呢T3再做執行對不對因為現在這裡面只剩T3了那這個例子我們是用可以PREEMPT的所以不要忘記我們還有PREEMPT跟NON PREEMPTION對不對所以在PREEMPT的狀況下那四道的時候綠色我們才做了一個TIME UNIT

它就会被打断因为这时候红色它又再次出现了对不对那所以红色出现它就是先做就对了那所以就会打断绿色然后一样先做红色然后呢做完红色之后橘色刚好又也出现了所以橘色仍然比绿色的priority高嘛所以我们就再继续做做两个time unit那这时候刚好有一个空位所以就是绿色去做所以没问题

以此類推應該又回到紅色然後這個時候所以模擬的時候自己要小心一點對不對所以這個時候紅色做完其實綠色呢已經在這邊等月就只做了一個兩個time unit對不對可是橘色還沒來所以剛好又有一個空位所以綠色就會先做了所以只有當橘色跟綠色不做的時候橘色跟紅色不做的時候我們才可以做綠色

所以我想後面大家就自己模擬一下稍微這個有一點點常常會交錯所以大家自己模擬的時候要注意一下不過它的原則其實很單純就是priority scheduling然後不要忘記它是以period的倒數來做ranking所以period最低的就先做它其實不管execution time你可以注意到這邊如果今天我們就算改成4它還是一樣或是

綠色它是20可是我們把它改成19那還是一樣它的Priority是最低的因為它只看Period而已好那重點是它是一個Static的所以當然它就有很多的壞其實結果不一定會特別的好那下一個咧就是EDF，所以 EDF其實大家其實算是Dynamic它可能一直在變換更複雜可是其實大家比較容易去想像它执行的过程所以這邊我們假設就只有两个Task而已然后一样当然時間长的就是它的Period然后短的就是它的Execution Time那一样T0的时候

對不對那我們會先做哪一個呢我們並不会看period我們其实只是看的是所谓的Dateline所以对于T1而言它的下一个Dateline就是兩天後對不對另外一个是五天所以兩天比較緊嘛所以我們就先做紅色的部分然後剩下的時間我們就可以去做橘色的部分那一樣橘色做到下一個紅色進來的時候那你就要去思考一下它會不會被打斷的問題對不对

那可以看見對於紅色這個新進來它的Dateline會從2進來所以再加2所以是4那橘色是同一個Task所以它的 Dateline還是5所以4比5比較小所以紅色現在是比較緊的所以我們就會先做紅色的部分那當然這個橘色咧等到紅色做好我們就可以繼續做橘色可是你就可以注意到這邊4所以下一個這個紅色又Arrive的時候我們的Decision就會倒過來剛剛我們紅色進來我們就讓紅色先做可是在4這個時間點

紅色是進來了可是他的Date Line是6那橘色呢卻是5對不對5其實是比較Earliest的Date Line所以其實橘色的Priority是比較高的所以橘色其實會繼續做做完他剩下的因為他一共做2. 3個Time Unit這邊做完1. 1所以當然剩下就是1. 2所以其實比較可以注意到這邊其實超過了4，他繼續做意思就是橘色的Priority，its實是比較高的，

所以這就是所謂的dynamic的priority。前一個時間點紅色的priority高，但下一個時間點卻變成橘色，所以他完全就看當下的狀況誰的deadline比較趕那誰的priority就比較高，所以我想後面就一樣大家可以去自己go through這個例子然後make sure當然尤其在考試的時候要非常小心這個算的長度等等自己要留意一下。但Dynamic這個EDF其實是一個Dynamic的Scheduling Algorithm，所以你每次都要重新決定誰的Priority高然後不要忘記在一個這個Period裡面你只需要做Execution Time的單位而已這個0.

9做完了他就離開Ready Queue就不需要再考慮他不要忘記然後只要一旦有新的Task進到我們的Ready Queue對不對下一個Period到的時候你就要重新再去決定一次到底誰的Party是比較高的，所以這個RemotonicReal-Time的Scheduling這邊大家兩個非常基本的Argorithm應該要稍微知道.