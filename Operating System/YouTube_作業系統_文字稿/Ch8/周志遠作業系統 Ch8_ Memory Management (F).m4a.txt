undefined
好那我們講完這個Page Table怎麼被應用那接下來我們要再講多一點到底他是怎麼被這個implement上面他到底在實際的電腦上implement的時候他用哪些技巧讓他的這個速度可以比較快所以第一簡大家要有的概念是Page table是在Memory裡面沒問題吧因為它是一個Memory structure所以它其實是放在Memory那是OS的MemoryOS的Memory的Space裡面那可是我們說做Translation的人是誰呢是MMUMMU是一個Hardware對不對

所以對於Hardware而言它如果想要去access任何data的話它其實必須要把這些dataload到這個Hardware的register就像CPU一樣對不對所以CPU才會有load的register這件事嘛所以其實在implement該這個機制而且在Hardware運作的上來講的話其實我們必須要把這個memory的contentload到MNU的register然後MNU才能夠幫我們做translation那所以它load的方式

其實是它會需要一個 base address所以會有一個 base register所以這個 page table它到底存在 memory 的什麼位置這個位置其實非常重要，必須要存下來然後呢它其實是一個register，是會漏到 register 裡面去的漏到MMU 的register，所以這個 base address 的這個特殊的 address其實有一個名字叫做這個ptbrpage table 的 base register，它裡面 Supposedly 要去 Load 的字就是這個 Page Table 到底存在 Memory 的什麼位置，在我們的 MMU

才能夠去 Load 的資料，所以當然就是 Physical所以它是 Physical 了，所以這就是我們剛才說的，你隨時要去看到一個Address 你要很清楚，那個Address 到底是 Physical 還是Logical，因為那是不一樣的東西，這邊你會看見是 Physical的原因，是因為是 hardware 去讀資料，所以 hardware沒有人在幫他 translate 那個 address 對不對，hardware 直接就是要讀 physical 的位置，所以這個其實是Physical所以他不需要再做任何 translation，我們的MMU 就可以去取得正確的資料位置，就是這個 table 裡面的 content

啦，簡單講好，所以就像 context 所以那一模一樣啦，所以你可以想見這個 register 值啊，它是存在我们的process的control block里面，所以当我们说context switch在load的一个process的时候其实它也会做一件事情就是它会把这个值load到MAU的register里面去，所以这样才会完成一个context switch所以这样下一支程式它去做translation的时候它就可以用不同的page table对不对，然后用正确的page table那样才不会乱掉

那所以就该说，所以content switch的时候你就會去做這個loading的動作了，所以不只是load你的這些CPU的register實際MMU的register也需要被重新load過的，那我們等一下會有圖你就會發現了，所以当我們說你要去讀一個這個Memory的content的時候其實我們真的去access memory的次數不是1喔，實際是2，因為有一個第一個memory的access實是只是去load你的page table而已，我要去找到你的page table在哪對不对然後我去找到那個page table之後load到我們的

mmu才能夠完成做translation的動作才知道你真正的位置在哪然後才有第二個memory reader去真的把你的資料給讀出來，所以其實是兩步所以說CPU去issue了一個MemoryReader。其實因為Pagetable的關係會變成兩個MemoryReader只是使用者看不到第一個是讀Pagetable第二個是去讀你真實的資料。所以你看本來我要讀一個資料變讀兩個很簡單的道理你就知道你的MemoryAccess的時間是Double

等於是慢了一倍。你本來是每秒好棒喔100GB的Memory的速度，因為Page Table掉到50GB使用者當然很不高興啦對不對花了錢就看到是這樣的Performance。所以咧怎麼辦？所以現在的電腦系統呢為了去解決這個問題都有加入一個機制叫做TLB。我們等一下就會介紹等一下就有圖啦簡單來講它是Cache啦，所以大家對Cache應該有概念對不對。意思就是說我之前讀過的，

我就把它先存起來你不要再幫我translate了，你就直接lookup進去有就有沒有你再去做translation。所以其實就可以去從原來兩個read如果你有cache hidden就可以只要一個就好。所以我們接下來就要介紹這個很重要的TLB。所以Pagetable的使用translation其實是會跟TLB一起混在一起用來做這個加速好，那介紹兩者關係之前我們先看一下

TLB到底是一個什麼樣子的一個怎麼被實作出來的那首先TLB呢它的確是一個Memory因為是Cache嘛所以當然是一個Memory的空間但是這個Memory呢其實是所謂的Associative Memory所謂Associative Memory的定義就是說今天一樣它是一個table嘛所以你可以想見裡面就是cache所以這就是page table裡面你曾經查過的某個page它對到多少frame

的資料查過了我就記在這就好那這個東西很快所以這個TLB它就有點像你就想是像L1 cache L2 cache這種就是比較快的memory啦所以速度是通常都是十倍以上的快跟一般的memory比的話n第二個特色就是它associative意思就是說我們知道這是cash所以它沒有ordering對不對不像我們的page table我可以說第三個page那

就是第四個entry我就直接跳過去order one就找到對不对可是這是cash所以意思就是說你裡面是亂七八糟的這可能是page1 7 5 2對不对任何數字所以當我說請問page3有沒有在我cash你是不是要少過一遍不然你根本不知道有hit還是沒hit對不对可是如果少過一遍那這個page的數量是否不是你的complexity現在大家正在學習的是不是older one了是older n 對不對就很糟所以associate的memory意思就是說

這是specialized memory它的logic hardware logic的設計是你可以同時查詢所有的entry所以它的lookup time是older one這就是我們俗稱的Associative的Memory所以它不是一般的那種Random Access Memory它是這種Memory才可以達到效能上的滿足我們效能的要求就是它Lookup雖然有很多Entry喔但是它Order 1的時間所以不要誤會了它雖然是去Search但是它是Order 1因為它直接可以查所有的Entry這個是TLB這個Memory跟其他Memory完全不同的地方

它當然比較快。 第一點，第二點，它是associate memory所以它的lookout time是old1而不是oldn所以你可以想見它一定是比較貴的而且它的邏輯如果你學過一些螺射就知道它的這個一定是比較複雜的，所以通常這種特殊的memory它的size是沒有辦法太大的就算現在的technology這或許out of date了一點，但是你可以想見可能就是只有幾千的level而已就已經很大了而且它的價錢就一直往上跳

因為這是很特殊比較昂貴的設備所以意思就是說這個Cache不能夠很大你就是一般系統你不可能期望說把所有的Page Table都塞進這個小小的Cache裡面這是不可能的所以就是一般我們俗稱的Cache的特色是一樣的好那知道這個 TLB 之後所以你可以看見我們這個圖為什麼我們會畫一堆箭頭因為它是 associative memory一般的 RAM 我們知道是沒有這回事的嘛大家有寫過 programming那結合在一起使用大家就可以

看見了我們先把這個遮掉那就跟我們原來一樣PD 對不對然後先去看我的 page table找到之後過來然後再去 access那因為這個在Memory所以我們說一個Memory Access會等於兩個Access所以你的速度會慢一倍沒問題那今天我們要加速所以就會出現這個TLB那要注意到這個紅色框框是MMU是Hardware所以這個是

Memory這是MMU那個Hardware所以TLB它就像是L1 Cache L2一樣CPU的L1 L2 Cache的概念是一樣TLB其實就是MMU的Cache所以是在這裡面的所以不僅是因為我們剛才說它的這個因為昂貴所以Entry少另外一點你要注意到的是其實際上每個Process都有自己的Page Table對不對所以

這個有非常非常多多少個Process就有多少Page Table可是TLB是Hardware你只有一個對不對所以大家要共用它所以你絕對不可能把所有東西都塞進去的好那既然它是Cache所以它的意思就是我們剛才說的會發生的事情是假設你今天translate過一個address之後那麼因為是透過mmu嘛他translate完所以他會知道這個P跟

F的關聯性對不对所以他translate完他就把它cache在這裡那當然反正滿了他當然就會剔掉最不常用的把它剔掉啦那當然只是一個簡單policy所以總之就是比較常見的他就會希望盡量的把它cache在裡頭那所以每一個這個Memory as Translation它其實第一步是先去看TLB如果有的話我們稱之為HIT所以你就直接就把這個F就塞過來了然後就出去所以這就是為什麼你的Memory是access的次數變成1維持是1的原因對不对

你只touch到Memory一次而已但如果很不幸它search完但是order 1的時間search完它是miss那你就要回到老的錄了我可以投入那就只好再去查一次然後再做 translation但是這就是一次 memory兩次 memory 所以是兩次 memory access所以這就是為什麼 TLB 是非常重要可以大幅減少我們 access time 的原因了那在這邊我們先看到很簡單我只寫 page number 跟 frame number但是你要注意到我們剛才已經提了其實我有非常多的 page table在我們電腦系統裡

但是只有一個TLB所以當我做context switch的時候如果我只記錄這兩個number那每一個process的page number它都有相同的page number啊對不對可是對到frame number因為不同的table所以只是不一樣也就是說它們不能夠互用不能夠混在一起使用對不對所以說今天如果context switch之後TLB這邊有兩個solution第一個其實是最常電腦系統用的方式Flush我們稱之為Flush TLB

就是他要把它清空因為當你做contact switch其實你的page table換人了所以當初你cache的這些資料全部是沒有辦法使用的所以我們必須要清空不然你就拿到別人的frame啦所以是一定是錯的嘛對不對第二種solution就是這邊提的你可以在後面再加一個欄位上面寫process ID所以對啊，Contact Switch我知道誰是我

現在的process嘛，所以我會除了去我這個entry外，也要找到我的Page Number，要符合之外，我們Process ID也要符合這兩個都符合，我才叫做Hit，這是第二個Solution，一般是Flush，因為其實我們剛才提過，一般程式現在的程式Memory都很大，你會Touch到非常多的Memory的Page，所以說通常都會把DLB塞滿了，所以裡面全部都是現在正在執行的那個人的Page，你就不用再Check了，你乾脆Content Switch你就清掉然後就換另外一個人用，就對了

免得比對那又是一個浪費時間的事情，然後這個昂貴嘛，所以你又要多儲存4個byte，這儲存等於是多一倍的空間喔，对不对原來假設這是4個byte， 4個byte，那你現在變8個byte變12個byte對不对33%的cost所以不太值得，大部分就是Flush掉，所以大家要把我們Contact Switch那邊跟這要結合在一起，不要把兩個章

節分開來讀了，要串在一起，其實Contact Switch Memory這邊要做Load，我們說的base register的事情，所以它可以找到這個table然後TRB要Flush，那一Flush之後問題就來囉，一Flush之後是不是我的接下來的memory assets全部是miss對不對？ 就空了嘛，所以為什麼contact switch其實會讓效能很差，這是一個很主要的原因，因為接下來的Memory Assets全部變兩倍

時間直到你把它填滿，你才可以再加速，不一定要填滿啦，但是就是要出現在裡頭啦，所以說Context Switch會慢不只是那個動作本身花時間，你的Memory的這個Assets時間也會因此被拖長講完這個就好 這個很單純所以剛剛知道怎麼運作的話，我們一直在講效能，效能嘛，所以效能則是什麼呢？我們通常就稱之為Effected Memory Access Time大家就講Memory Access Time就好了，不用那麼長 這也不用特意記啦，看到這個大家就知道意思了，我也不會給你們寫簡寫啦，那誰猜得到嘛 對不對

不過你看到那個意思了，你看到剛剛那個流程，你腦中要有那個picture。我今天给你这简单两个数字就是说TLP的时间通常比较快，所以就是20个Ns那Memory通常就是比较久5倍甚至于更长那从这两个数字你就知道为什么Cache这么重要了，因为如果假设是70%的Heat Rate大家算一下，这算法其实就是想那个它的流程对不对這边指的就是Heat嘛，Heat我们说只要是Memory Access但是20要加上去不要忘了，因为你always要SearchMiss的话，你会Search而且你還會

兩次的asset，所以是220，所以這個很簡單，看剛剛那個流程跑一遍flow就知道為什麼是100 100加20了，那所以就是150，那相較之下，你可以看我們，如果假設提升到98，那我的時間就可以提升到122個，這個這個narrow second，所以其實它跟原來worst case是200，你就可以將近快了一倍，如果是98%的音樂好，那我們下次會告訴你為什麼現在電腦TLB真的可以達到98%的這個原因好，那我們今天就先上到這邊.